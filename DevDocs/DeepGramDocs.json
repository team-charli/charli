[
  {
    "markdown": "Voice Agent\n\nThe `KeepAlive` message is a JSON message that you can use to ensure that the server does not close the connection.\n\n## Purpose\n\nThe `KeepAlive` message is a useful JSON message that helps maintain an open connection with the server, preventing it from being closed due to inactivity. This ensures continuous communication without interruptions during periods when no other data is being transmitted.\n\nUsing `KeepAlive` is not recommended for most agent conversations, because you will typically be sending continuous microphone audio to the agent in case the user has something to say.\n\n## Example Payload\n\nTo send the `KeepAlive` message, you need to send the following JSON message to the server:\n\nThis message should only be used during a period of time when the client is not sending audio. During such a period, the client can send a `KeepAlive` message every `8` seconds to keep the connection open.\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"KeepAlive\"3}\n```\n\nYou will not receive a response back from the server.\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=14702db6-a3f7-42a9-b8e8-b4214798c5a0&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=14e44ad1-93b9-44af-81a1-410de843f1ed&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fagent-keep-alive&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=14702db6-a3f7-42a9-b8e8-b4214798c5a0&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=14e44ad1-93b9-44af-81a1-410de843f1ed&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fagent-keep-alive&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=o53kovizkx2o)",
    "metadata": {
      "ogTitle": "Agent Keep Alive | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Agent Keep Alive | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Send messages ensuring uninterrupted communication for your agent.",
      "description": "Send messages ensuring uninterrupted communication for your agent.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:description": "Send messages ensuring uninterrupted communication for your agent.",
      "language": "en",
      "ogDescription": "Send messages ensuring uninterrupted communication for your agent.",
      "application-name": "Deepgram's Docs",
      "og:title": "Agent Keep Alive | Deepgram's Docs",
      "twitter:card": "summary",
      "title": "Agent Keep Alive | Deepgram's Docs",
      "scrapeId": "d85c093e-6ee1-487e-8ecd-0ed3dda76313",
      "sourceURL": "https://developers.deepgram.com/docs/agent-keep-alive",
      "url": "https://developers.deepgram.com/docs/agent-keep-alive",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide walks you through building a function call for a demo Voice Agent application. For the complete code, see the [code repository](https://github.com/deepgram-devs/flask-agent-function-calling-demo).\n\n## Getting Started\n\nYou’ll create two files:\n\n- **`agent_functions.py`**: Contains async functions and configuration for customer lookups, appointments, and order management.\n- **`agent_templates.py`**: Defines the agent prompt, settings, and the `AgentTemplates` factory class for industry-specific configuration.\n\n### Prerequisites\n\n- Python 3.7+\n- Familiarity with Python\n- An understanding of how to use Python Virtual environments.\n- Familiarity with the [Deepgram Voice Agent API](https://developers.deepgram.com/reference/build-a-voice-agent)\n\n## Create `agent_functions.py`\n\nThis guide doesn’t cover the development of the **business logic** for this application. Please see [business\\_logic.py](https://github.com/deepgram-devs/flask-agent-function-calling-demo/blob/main/common/business_logic.py) for more details.\n\nFirst, create a file called: `agent_functions.py`. Then in `agent_functions.py` set up the dependencies and import the business logic.\n\nPython\n\n```code-block text-sm\n\n1import json2from datetime import datetime, timedelta3import asyncio4from business_logic import (5    get_customer,6    get_customer_appointments,7    get_customer_orders,8    schedule_appointment,9    get_available_appointment_slots,10    prepare_agent_filler_message,11    prepare_farewell_message12)\n```\n\n### Implement the Functions\n\nWe’ll implement the following functions in `agent_functions.py` to handle customer and appointment management:\n\n| Function Name | Purpose |\n| --- | --- |\n| `find_customer` | Lookup by phone, email, or ID; normalizes input |\n| `get_appointments` | Retrieve all appointments for a customer |\n| `get_orders` | Retrieve order history for a customer |\n| `create_appointment` | Schedule a new appointment |\n| `check_availability` | Find available appointment slots |\n| `agent_filler` | Provide conversational filler (requires websocket param) |\n| `end_call` | End the conversation gracefully (requires websocket param) |\n\n### Find Customer\n\nPython\n\n```code-block text-sm\n\n1async def find_customer(params):2    \"\"\"Look up a customer by phone, email, or ID.\"\"\"3    phone = params.get(\"phone\")4    email = params.get(\"email\")5    customer_id = params.get(\"customer_id\")67    result = await get_customer(phone=phone, email=email, customer_id=customer_id)8    return result\n```\n\n### Get Appointments\n\nPython\n\n```code-block text-sm\n\n1async def get_appointments(params):2    \"\"\"Get appointments for a customer.\"\"\"3    customer_id = params.get(\"customer_id\")4    if not customer_id:5        return {\"error\": \"customer_id is required\"}67    result = await get_customer_appointments(customer_id)8    return result\n```\n\n### Get Orders\n\nPython\n\n```code-block text-sm\n\n1async def get_orders(params):2    \"\"\"Get orders for a customer.\"\"\"3    customer_id = params.get(\"customer_id\")4    if not customer_id:5        return {\"error\": \"customer_id is required\"}67    result = await get_customer_orders(customer_id)8    return result\n```\n\n### Create Appointment\n\nPython\n\n```code-block text-sm\n\n1async def create_appointment(params):2    \"\"\"Schedule a new appointment.\"\"\"3    customer_id = params.get(\"customer_id\")4    date = params.get(\"date\")5    service = params.get(\"service\")67    if not all([customer_id, date, service]):8        return {\"error\": \"customer_id, date, and service are required\"}910    result = await schedule_appointment(customer_id, date, service)11    return result\n```\n\n### Check Availability\n\nPython\n\n```code-block text-sm\n\n1async def check_availability(params):2    \"\"\"Check available appointment slots.\"\"\"3    start_date = params.get(\"start_date\")4    end_date = params.get(\"end_date\", (datetime.fromisoformat(start_date) + timedelta(days=7)).isoformat())56    if not start_date:7        return {\"error\": \"start_date is required\"}89    result = await get_available_appointment_slots(start_date, end_date)10    return result\n```\n\n### Agent Filler\n\nPython\n\n```code-block text-sm\n\n1async def agent_filler(websocket, params):2    \"\"\"3    Handle agent filler messages while maintaining proper function call protocol.4    \"\"\"5    result = await prepare_agent_filler_message(websocket, **params)6    return result\n```\n\n### End Call\n\nPython\n\n```code-block text-sm\n\n1async def end_call(websocket, params):2    \"\"\"3    End the conversation and close the connection.4    \"\"\"5    farewell_type = params.get(\"farewell_type\", \"general\")6    result = await prepare_farewell_message(websocket, farewell_type)7    return result\n```\n\n### Create Function Definitions\n\nNext in `agent_functions.py` we’ll setup `FUNCTION_DEFINITIONS` which is an array that defines the API contract for the Voice Agent system. It specifies all available operations, their parameters, and usage guidelines.\n\nEach function definition follows a JSON Schema format with:\n\n- Name\n- Description\n- Parameters specification\n- Required fields\n- Enumerated values where applicable\n\nPython\n\n```code-block text-sm\n\n1# Function definitions that will be sent to the Voice Agent API2FUNCTION_DEFINITIONS = [3    {4        \"name\": \"agent_filler\",5        \"description\": \"\"\"Use this function to provide natural conversational filler before looking up information.6        ALWAYS call this function first with message_type='lookup' when you're about to look up customer information.7        After calling this function, you MUST immediately follow up with the appropriate lookup function (e.g., find_customer).\"\"\",8        \"parameters\": {9            \"type\": \"object\",10            \"properties\": {11                \"message_type\": {12                    \"type\": \"string\",13                    \"description\": \"Type of filler message to use. Use 'lookup' when about to search for information.\",14                    \"enum\": [\"lookup\", \"general\"]15                }16            },17            \"required\": [\"message_type\"]18        }19    },20    {21        \"name\": \"find_customer\",22        \"description\": \"\"\"Look up a customer's account information. Use context clues to determine what type of identifier the user is providing:2324        Customer ID formats:25        - Numbers only (e.g., '169', '42') → Format as 'CUST0169', 'CUST0042'26        - With prefix (e.g., 'CUST169', 'customer 42') → Format as 'CUST0169', 'CUST0042'2728        Phone number recognition:29        - Standard format: '555-123-4567' → Format as '+15551234567'30        - With area code: '(555) 123-4567' → Format as '+15551234567'31        - Spoken naturally: 'five five five, one two three, four five six seven' → Format as '+15551234567'32        - International: '+1 555-123-4567' → Use as is33        - Always add +1 country code if not provided3435        Email address recognition:36        - Spoken naturally: 'my email is john dot smith at example dot com' → Format as '[email protected]'37        - With domain: '[email protected]' → Use as is38        - Spelled out: 'j o h n at example dot com' → Format as '[email protected]'\"\"\",39        \"parameters\": {40            \"type\": \"object\",41            \"properties\": {42                \"customer_id\": {43                    \"type\": \"string\",44                    \"description\": \"Customer's ID. Format as CUSTXXXX where XXXX is the number padded to 4 digits with leading zeros. Example: if user says '42', pass 'CUST0042'\"45                },46                \"phone\": {47                    \"type\": \"string\",48                    \"description\": \"\"\"Phone number with country code. Format as +1XXXXXXXXXX:49                    - Add +1 if not provided50                    - Remove any spaces, dashes, or parentheses51                    - Convert spoken numbers to digits52                    Example: 'five five five one two three four five six seven' → '+15551234567'\"\"\"53                },54                \"email\": {55                    \"type\": \"string\",56                    \"description\": \"\"\"Email address in standard format:57                    - Convert 'dot' to '.'58                    - Convert 'at' to '@'59                    - Remove spaces between spelled out letters60                    Example: 'j dot smith at example dot com' → '[email protected]'\"\"\"61                }62            }63        }64    },65    {66        \"name\": \"get_appointments\",67        \"description\": \"\"\"Retrieve all appointments for a customer. Use this function when:68        - A customer asks about their upcoming appointments69        - A customer wants to know their appointment schedule70        - A customer asks 'When is my next appointment?'7172        Always verify you have the customer's account first using find_customer before checking appointments.\"\"\",73        \"parameters\": {74            \"type\": \"object\",75            \"properties\": {76                \"customer_id\": {77                    \"type\": \"string\",78                    \"description\": \"Customer's ID in CUSTXXXX format. Must be obtained from find_customer first.\"79                }80            },81            \"required\": [\"customer_id\"]82        }83    },84    {85        \"name\": \"get_orders\",86        \"description\": \"\"\"Retrieve order history for a customer. Use this function when:87        - A customer asks about their orders88        - A customer wants to check order status89        - A customer asks questions like 'Where is my order?' or 'What did I order?'9091        Always verify you have the customer's account first using find_customer before checking orders.\"\"\",92        \"parameters\": {93            \"type\": \"object\",94            \"properties\": {95                \"customer_id\": {96                    \"type\": \"string\",97                    \"description\": \"Customer's ID in CUSTXXXX format. Must be obtained from find_customer first.\"98                }99            },100            \"required\": [\"customer_id\"]101        }102    },103    {104        \"name\": \"create_appointment\",105        \"description\": \"\"\"Schedule a new appointment for a customer. Use this function when:106        - A customer wants to book a new appointment107        - A customer asks to schedule a service108109        Before scheduling:110        1. Verify customer account exists using find_customer111        2. Check availability using check_availability112        3. Confirm date/time and service type with customer before booking\"\"\",113        \"parameters\": {114            \"type\": \"object\",115            \"properties\": {116                \"customer_id\": {117                    \"type\": \"string\",118                    \"description\": \"Customer's ID in CUSTXXXX format. Must be obtained from find_customer first.\"119                },120                \"date\": {121                    \"type\": \"string\",122                    \"description\": \"Appointment date and time in ISO format (YYYY-MM-DDTHH:MM:SS). Must be a time slot confirmed as available.\"123                },124                \"service\": {125                    \"type\": \"string\",126                    \"description\": \"Type of service requested. Must be one of the following: Consultation, Follow-up, Review, or Planning\",127                    \"enum\": [\"Consultation\", \"Follow-up\", \"Review\", \"Planning\"]128                }129            },130            \"required\": [\"customer_id\", \"date\", \"service\"]131        }132    },133    {134        \"name\": \"check_availability\",135        \"description\": \"\"\"Check available appointment slots within a date range. Use this function when:136        - A customer wants to know available appointment times137        - Before scheduling a new appointment138        - A customer asks 'When can I come in?' or 'What times are available?'139140        After checking availability, present options to the customer in a natural way, like:141        'I have openings on [date] at [time] or [date] at [time]. Which works better for you?'\"\"\",142        \"parameters\": {143            \"type\": \"object\",144            \"properties\": {145                \"start_date\": {146                    \"type\": \"string\",147                    \"description\": \"Start date in ISO format (YYYY-MM-DDTHH:MM:SS). Usually today's date for immediate availability checks.\"148                },149                \"end_date\": {150                    \"type\": \"string\",151                    \"description\": \"End date in ISO format. Optional - defaults to 7 days after start_date. Use for specific date range requests.\"152                }153            },154            \"required\": [\"start_date\"]155        }156    },157    {158        \"name\": \"end_call\",159        \"description\": \"\"\"End the conversation and close the connection. Call this function when:160        - User says goodbye, thank you, etc.161        - User indicates they're done (\"that's all I need\", \"I'm all set\", etc.)162        - User wants to end the conversation163164        Examples of triggers:165        - \"Thank you, bye!\"166        - \"That's all I needed, thanks\"167        - \"Have a good day\"168        - \"Goodbye\"169        - \"I'm done\"170171        Do not call this function if the user is just saying thanks but continuing the conversation.\"\"\",172        \"parameters\": {173            \"type\": \"object\",174            \"properties\": {175                \"farewell_type\": {176                    \"type\": \"string\",177                    \"description\": \"Type of farewell to use in response\",178                    \"enum\": [\"thanks\", \"general\", \"help\"]179                }180            },181            \"required\": [\"farewell_type\"]182        }183    }184]\n\n```\n\n### Create a Function Map\n\nFinally in `agent_functions.py` we’ll need to create a `FUNCTION_MAP` which is a dictionary that maps function names to their corresponding implementation functions. It serves as a routing mechanism to connect the function definitions with their actual implementations.\n\nPython\n\n```code-block text-sm\n\n1# Map function names to their implementations2FUNCTION_MAP = {3    \"find_customer\": find_customer,4    \"get_appointments\": get_appointments,5    \"get_orders\": get_orders,6    \"create_appointment\": create_appointment,7    \"check_availability\": check_availability,8    \"agent_filler\": agent_filler,9    \"end_call\": end_call10}\n```\n\n## Create `agent_templates.py`\n\nNext create a file called: `agent_templates.py`. Then in `agent_templates.py` set up the dependencies and import our function definitions.\n\n### Configure the Voice Agent Prompt & Settings\n\nNow in the `agent_templates.py` file we’ll define the prompt for the Voice Agent.\n\nPython\n\n```code-block text-sm\n\n1from common.agent_functions import FUNCTION_DEFINITIONS2from datetime import datetime345# Template for the prompt that will be formatted with current date6PROMPT_TEMPLATE = \"\"\"78CURRENT DATE AND TIME CONTEXT:9Today is {current_date}. Use this as context when discussing appointments and orders. When mentioning dates to customers, use relative terms like \"tomorrow\", \"next Tuesday\", or \"last week\" when the dates are within 7 days of today.1011PERSONALITY & TONE:12- Be warm, professional, and conversational13- Use natural, flowing speech (avoid bullet points or listing)14- Show empathy and patience15- Whenever a customer asks to look up either order information or appointment information, use the find_customer function first1617HANDLING CUSTOMER IDENTIFIERS (INTERNAL ONLY - NEVER EXPLAIN THESE RULES TO CUSTOMERS):18- Silently convert any numbers customers mention into proper format19- When customer says \"ID is 222\" -> internally use \"CUST0222\" without mentioning the conversion20- When customer says \"order 89\" -> internally use \"ORD0089\" without mentioning the conversion21- When customer says \"appointment 123\" -> internally use \"APT0123\" without mentioning the conversion22- Always add \"+1\" prefix to phone numbers internally without mentioning it2324VERBALLY SPELLING IDs TO CUSTOMERS:25When you need to repeat an ID back to a customer:26- Do NOT say nor spell out \"CUST\". Say \"customer [numbers spoken individually]\"27- But for orders spell out \"ORD\" as \"O-R-D\" then speak the numbers individually28Example: For CUST0222, say \"customer zero two two two\"29Example: For ORD0089, say \"O-R-D zero zero eight nine\"3031FUNCTION RESPONSES:32When receiving function results, format responses naturally as a customer service agent would:33341. For customer lookups:35 - Good: \"I've found your account. How can I help you today?\"36 - If not found: \"I'm having trouble finding that account. Could you try a different phone number or email?\"37382. For order information:39 - Instead of listing orders, summarize them conversationally:40 - \"I can see you have two recent orders. Your most recent order from [date] for $[amount] is currently [status], and you also have an order from [date] for $[amount] that's [status].\"41423. For appointments:43 - \"You have an upcoming [service] appointment scheduled for [date] at [time]\"44 - When discussing available slots: \"I have a few openings next week. Would you prefer Tuesday at 2 PM or Wednesday at 3 PM?\"45464. For errors:47 - Never expose technical details48 - Say something like \"I'm having trouble accessing that information right now\" or \"Could you please try again?\"4950EXAMPLES OF GOOD RESPONSES:51✓ \"Let me look that up for you... I can see you have two recent orders.\"52✓ \"Your customer ID is zero two two two.\"53✓ \"I found your order, O-R-D zero one two three. It's currently being processed.\"5455EXAMPLES OF BAD RESPONSES (AVOID):56✗ \"I'll convert your ID to the proper format CUST0222\"57✗ \"Let me add the +1 prefix to your phone number\"58✗ \"The system requires IDs to be in a specific format\"5960FILLER PHRASES:61IMPORTANT: Never generate filler phrases (like \"Let me check that\", \"One moment\", etc.) directly in your responses.62Instead, ALWAYS use the agent_filler function when you need to indicate you're about to look something up.6364Examples of what NOT to do:65- Responding with \"Let me look that up for you...\" without a function call66- Saying \"One moment please\" or \"Just a moment\" without a function call67- Adding filler phrases before or after function calls6869Correct pattern to follow:701. When you need to look up information:71 - First call agent_filler with message_type=\"lookup\"72 - Immediately follow with the relevant lookup function (find_customer, get_orders, etc.)732. Only speak again after you have the actual information to share7475Remember: ANY phrase indicating you're about to look something up MUST be done through the agent_filler function, never through direct response text.76\"\"\"\n\n```\n\nNext in the same file we’ll define the settings for the Voice Agent.\n\nPython\n\n```code-block text-sm\n\n1VOICE = \"aura-2-thalia-en\"23# this gets updated by the agent template4FIRST_MESSAGE = \"\"56# audio settings7USER_AUDIO_SAMPLE_RATE = 480008USER_AUDIO_SECS_PER_CHUNK = 0.059USER_AUDIO_SAMPLES_PER_CHUNK = round(USER_AUDIO_SAMPLE_RATE * USER_AUDIO_SECS_PER_CHUNK)1011AGENT_AUDIO_SAMPLE_RATE = 1600012AGENT_AUDIO_BYTES_PER_SEC = 2 * AGENT_AUDIO_SAMPLE_RATE1314VOICE_AGENT_URL = \"wss://agent.deepgram.com/v1/agent/converse\"1516AUDIO_SETTINGS = {17  \"input\": {18      \"encoding\": \"linear16\",19      \"sample_rate\": USER_AUDIO_SAMPLE_RATE,20  },21  \"output\": {22      \"encoding\": \"linear16\",23      \"sample_rate\": AGENT_AUDIO_SAMPLE_RATE,24      \"container\": \"none\",25  },26}2728LISTEN_SETTINGS = {29  \"provider\": {30      \"type\": \"deepgram\",31      \"model\": \"nova-3\",32  }33}3435THINK_SETTINGS = {36  \"provider\": {37      \"type\": \"open_ai\",38      \"model\": \"gpt-4o-mini\",39      \"temperature\": 0.7,40  },41  \"prompt\": PROMPT_TEMPLATE,42  \"functions\": FUNCTION_DEFINITIONS,43}4445SPEAK_SETTINGS = {46  \"provider\": {47      \"type\": \"deepgram\",48      \"model\": VOICE,49  }50}5152AGENT_SETTINGS = {53  \"language\": \"en\",54  \"listen\": LISTEN_SETTINGS,55  \"think\": THINK_SETTINGS,56  \"speak\": SPEAK_SETTINGS,57  \"greeting\": FIRST_MESSAGE,58}5960SETTINGS = {\"type\": \"Settings\", \"audio\": AUDIO_SETTINGS, \"agent\": AGENT_SETTINGS}\n\n```\n\nFinally in the same file we’ll define the factory class `AgentTemplates` which will be used to configure the Voice Agent. This class will be used to configure the Voice Agent for different industries.\n\nPython\n\n```code-block text-sm\n\n1class AgentTemplates:2  PROMPT_TEMPLATE = PROMPT_TEMPLATE34  def __init__(5      self,6      industry=\"tech_support\",7      voiceModel=\"aura-2-thalia-en\",8      voiceName=\"\",9  ):10      self.voiceName = voiceName11      self.voiceModel = voiceModel12      self.personality = \"\"13      self.company = \"\"14      self.first_message = \"\"15      self.capabilities = \"\"1617      self.industry = industry1819      self.prompt = self.PROMPT_TEMPLATE.format(20          current_date=datetime.now().strftime(\"%A, %B %d, %Y\")21      )2223      self.voice_agent_url = VOICE_AGENT_URL24      self.settings = SETTINGS25      self.user_audio_sample_rate = USER_AUDIO_SAMPLE_RATE26      self.user_audio_secs_per_chunk = USER_AUDIO_SECS_PER_CHUNK27      self.user_audio_samples_per_chunk = USER_AUDIO_SAMPLES_PER_CHUNK28      self.agent_audio_sample_rate = AGENT_AUDIO_SAMPLE_RATE29      self.agent_audio_bytes_per_sec = AGENT_AUDIO_BYTES_PER_SEC3031      match self.industry:32          case \"tech_support\":33              self.tech_support()34          case \"healthcare\":35              self.healthcare()36          case \"banking\":37              self.banking()38          case \"pharmaceuticals\":39              self.pharmaceuticals()40          case \"retail\":41              self.retail()4243      self.first_message = f\"Hello! I'm {self.voiceName} from {self.company} customer service. {self.capabilities} How can I help you today?\"4445      self.settings[\"agent\"][\"speak\"][\"provider\"][\"model\"] = self.voiceModel46      self.settings[\"agent\"][\"think\"][\"prompt\"] = self.prompt47      self.settings[\"agent\"][\"greeting\"] = self.first_message4849      self.prompt = self.personality + \"\\n\\n\" + self.prompt5051  def tech_support(52      self, company=\"TechStyle\", agent_voice=\"aura-2-thalia-en\", voiceName=\"\"53  ):54      if voiceName == \"\":55          voiceName = self.get_voice_name_from_model(agent_voice)56      self.voiceName = voiceName57      self.company = company58      self.voiceModel = agent_voice5960      self.personality = f\"You are {self.voiceName}, a friendly and professional customer service representative for {self.company}, an online electronics and accessories retailer. Your role is to assist customers with orders, appointments, and general inquiries.\"6162      self.capabilities = \"I'd love to help you with your order or appointment.\"6364  def healthcare(65      self, company=\"HealthFirst\", agent_voice=\"aura-2-andromeda-en\", voiceName=\"\"66  ):67      if voiceName == \"\":68          voiceName = self.get_voice_name_from_model(agent_voice)69      self.voiceName = voiceName70      self.company = company71      self.voiceModel = agent_voice7273      self.personality = f\"You are {self.voiceName}, a compassionate and knowledgeable healthcare assistant for {self.company}, a leading healthcare provider. Your role is to assist patients with appointments, medical inquiries, and general health information.\"7475      self.capabilities = \"I can help you schedule appointments or answer questions about our services.\"7677  def banking(78      self, company=\"SecureBank\", agent_voice=\"aura-2-apollo-en\", voiceName=\"\"79  ):80      if voiceName == \"\":81          voiceName = self.get_voice_name_from_model(agent_voice)82      self.voiceName = voiceName83      self.company = company84      self.voiceModel = agent_voice8586      self.personality = f\"You are {self.voiceName}, a professional and trustworthy banking representative for {self.company}, a secure financial institution. Your role is to assist customers with account inquiries, transactions, and financial services.\"8788      self.capabilities = (89          \"I can assist you with your account or any banking services you need.\"90      )9192  def pharmaceuticals(93      self, company=\"MedLine\", agent_voice=\"aura-2-helena-en\", voiceName=\"\"94  ):95      if voiceName == \"\":96          voiceName = self.get_voice_name_from_model(agent_voice)97      self.voiceName = voiceName98      self.company = company99      self.voiceModel = agent_voice100101      self.personality = f\"You are {self.voiceName}, a professional and trustworthy pharmaceutical representative for {self.company}, a secure pharmaceutical company. Your role is to assist customers with account inquiries, transactions, and appointments. You MAY NOT provide medical advice.\"102103      self.capabilities = \"I can assist you with your account or appointments.\"104105  def retail(self, company=\"StyleMart\", agent_voice=\"aura-2-aries-en\", voiceName=\"\"):106      if voiceName == \"\":107          voiceName = self.get_voice_name_from_model(agent_voice)108      self.voiceName = voiceName109      self.company = company110      self.voiceModel = agent_voice111112      self.personality = f\"You are {self.voiceName}, a friendly and attentive retail associate for {self.company}, a trendy clothing and accessories store. Your role is to assist customers with product inquiries, orders, and style recommendations.\"113114      self.capabilities = (115          \"I can help you find the perfect item or check on your order status.\"116      )117118  def travel(self, company=\"TravelTech\", agent_voice=\"aura-2-arcas-en\", voiceName=\"\"):119      if voiceName == \"\":120          voiceName = self.get_voice_name_from_model(agent_voice)121      self.voiceName = voiceName122      self.company = company123      self.voiceModel = agent_voice124125      self.personality = f\"You are {self.voiceName}, a friendly and professional customer service representative for {self.company}, a tech-forward travel agency. Your role is to assist customers with travel bookings, appointments, and general inquiries.\"126127      self.capabilities = (128          \"I'd love to help you with your travel bookings or appointments.\"129      )130131  @staticmethod132  def get_available_industries():133      \"\"\"Return a dictionary of available industries with display names\"\"\"134      return {135          \"tech_support\": \"Tech Support\",136          \"healthcare\": \"Healthcare\",137          \"banking\": \"Banking\",138          \"pharmaceuticals\": \"Pharmaceuticals\",139          \"retail\": \"Retail\",140          \"travel\": \"Travel\",141      }142143  def get_voice_name_from_model(self, model):144      return model.split(\"-\")[2].split(\"-\")[0].capitalize()\n\n```\n\n## Call the functions from `client.py`\n\nThis guide doesn’t cover the development of the **client** for this application. Please see [client.py](https://github.com/deepgram-devs/flask-agent-function-calling-demo/blob/main/client.py#L66) for more details.\n\nIn the `client.py` file we’ll need reference `agent_templates.py` which will define the settings for the Voice Agent.\n\nPython\n\n```code-block text-sm\n\n1settings = self.agent_templates.settings\n```\n\n## What’s Next?\n\n- For more ideas and function code samples for using Function Calling with your Agent check out [this repository.](https://github.com/deepgram-devs/voice-agent-function-calling-examples)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=lxyi75im7m4j)",
    "metadata": {
      "ogDescription": "Learn how to build a Function Call to use with your Agent.",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "og:title": "Build A Function Call | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "title": "Build A Function Call | Deepgram's Docs",
      "og:description": "Learn how to build a Function Call to use with your Agent.",
      "twitter:description": "Learn how to build a Function Call to use with your Agent.",
      "twitter:title": "Build A Function Call | Deepgram's Docs",
      "ogTitle": "Build A Function Call | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "description": "Learn how to build a Function Call to use with your Agent.",
      "twitter:card": "summary",
      "scrapeId": "bfdb78a1-23c0-43fb-944e-158aa3d66f06",
      "sourceURL": "https://developers.deepgram.com/docs/build-a-function-call",
      "url": "https://developers.deepgram.com/docs/build-a-function-call",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Integrating Twilio with Deepgram’s Speech-to-Text (STT) and Text-to-Speech (TTS) functionalities allows you to build robust applications capable of real-time transcription and voice synthesis. This guide walks you through setting up a streaming voice agent using Twilio, Deepgram, and OpenAI, while optimizing for low latency.\n\n## Before You Begin\n\nThis guide assumes that you have a basic understanding of JavaScript, Node.js and are familiar with [OpenAI](https://openai.com/), [Twilio](https://www.twilio.com/) and [Ngrok](https://ngrok.com/). It’s also useful if you have general knowledge of how Large Language Models (LLMs) work.\n\nYou can find the final code in The [GitHub Repository](https://github.com/deepgram/deepgram-twilio-streaming-voice-agent).\n\n### Create a Deepgram API Key\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nTo access Deepgram’s API, you’ll need to [create a Deepgram API Key](https://console.deepgram.com/signup?jump=keys). Make note of your API Key; you will need it later.\n\n### Get Twilio Credentials\n\nThis demo uses Twilio Voice to start a phone call that will be recorded and transcribed. Before you can use Twilio’s service, you’ll need to [sign up for a Twilio account](https://twilio.com/).\n\nTo use the sample application, you’ll need a Twilio Account SID and Twilio Auth Token. These can both be found within your [Twilio Admin Dashboard](https://console.twilio.com/).\n\n### Get OpenAI Credentials\n\nThis application uses OpenAI for it’s LLM. Before you can use OpenAI’s service, you’ll need to [sign up for an OpenAI account](https://platform.openai.com/signup/) and obtain an API Key.\n\n## Getting Started\n\nThis is a basic JavaScript server that show cases end to end streaming voice agent with the following components:\n\n- Callable Phone Number\n- Streaming Twilio - Inbound Audio\n- Streaming Deepgram - Speech to Text\n- Streaming OpenAI - LLM\n- Streaming Deepgram - Text to Speech\n- Streaming Twilio - Outbound Audio\n\nThis implementation is a good starting reference to develop your own application logic and isn’t design for scale or production deployments.\n\n## Clone the Repository\n\nEither clone or download the [GitHub repository](https://github.com/DamienDeepgram/deepgram-twilio-streaming-voice-agent) to your local machine in a new directory:\n\nShell\n\n```code-block text-sm\n\n$# Clone this repo>git clone https://github.com/DamienDeepgram/deepgram-twilio-streaming-voice-agent.git>># Move to the created directory>cd deepgram-twilio-streaming-voice-agent\n```\n\n## App sever setup\n\nRefer to the [server.js](https://github.com/deepgram/deepgram-twilio-streaming-voice-agent/blob/main/server.js) file in the GitHub Repository to see the server side implementation.\n\n### Set environment variables\n\nYou will need to set environment variables for your shell session. These environment variables are used to store the API keys required for authentication when accessing the OpenAI and Deepgram APIs.\n\nOpen a Terminal and run:\n\nShell\n\n```code-block text-sm\n\n$export OPENAI_API_KEY=xxx>export DEEPGRAM_API_KEY=xxx\n```\n\nTo verify the environment variables are set, run the following commands in your Terminal:\n\nShell\n\n```code-block text-sm\n\n$echo $OPENAI_API_KEY>echo $DEEPGRAM_API_KEY\n```\n\n### Installation\n\n**Requires Node >= v12.1.0**\n\nRun `npm install`\n\n#### Running the server\n\nStart with `npm run start`\n\n## Demo Setup\n\n### Configure the environment using the Ngrok UI & CLI\n\n1. Install ngrok:\n\n- If on MacOS: `brew install ngrok/ngrok/ngrok`\n- If on Windows/Linux: Follow the [instructions on ngrok’s site](https://ngrok.com/docs/getting-started/)\n\n2. Sign up for a ngrok account:\n\n- If you haven’t already, sign up for an [ngrok account](https://dashboard.ngrok.com/get-started/setup/macos)\n- Copy your ngrok authtoken from your [ngrok dashboard](https://dashboard.ngrok.com/get-started/your-authtoken)\n- Run the following command in your terminal to install the auth token and connect the ngrok agent to your account.\n\nShell\n\n```code-block text-sm\n\n$ngrok config add-authtoken <TOKEN>\n```\n\n### Twilio Phone Number Setup\n\n- You will need to provide a valid phone number from Twilio.\n- You can either use the Twilio CLI ( [see instructions below](https://help.twilio.com/articles/223135247-How-to-Search-for-and-Buy-a-Twilio-Phone-Number-from-Console)) OR the Twilio Admin Dashboard to setup a phone number. (see these [instructions](https://help.twilio.com/articles/223135247-How-to-Search-for-and-Buy-a-Twilio-Phone-Number-from-Console) from Twilio)\n\n### Configure with the Twilio CLI\n\n> Refer to this [Repository](https://github.com/twilio/media-streams/tree/master/node/connect-basic) for more information on this section.\n\n1. Install the [Twilio CLI](https://www.twilio.com/docs/twilio-cli/quickstart) and login to Twilio to run these commands.\n\n2. Find an available phone number\n\n\nShell\n\n```code-block text-sm\n\n$twilio api:core:available-phone-numbers:local:list --country-code=\"US\" --voice-enabled --properties=\"phoneNumber\"`\n```\n\n3. Purchase the phone number (where `+123456789` is a number you found)\n\nShell\n\n```code-block text-sm\n\n$twilio api:core:incoming-phone-numbers:create --phone-number=\"+123456789\"`\n```\n\n### Set the webhook url to your ngrok url\n\n4. Start ngrok\n\nOn a separate terminal (not the one where you have run `npm run start`):\n\nShell\n\n```code-block text-sm\n\n$ngrok http 8080\n```\n\n5. You will see a url under the `Forwarding` row that —> to your localhost. Copy this as the `<ngrok url>`\n6. Edit the [templates/streams](https://github.com/deepgram/deepgram-twilio-streaming-voice-agent/blob/main/templates/streams.xml) file to replace `<ngrok url>` with your ngrok host. Example: `wss://yourdomain.ngrok-free.app/streams`. Remember to use `wss://` and include `/streams` in the URL.\n7. Go to your Twilio dashboard and select the active phone number that you manage. Under the Configure tab, include the `\\<ngrok url` in URL of the “A call comes in” row of the page. If your URL is `wss://yourdomain.ngrok-free.app`, put in `<https://yourdomain.ngrok-free.app/twiml` >\n\nIf you restart your ngrok server your `ngrok url` will change.\n\n### Call the number and chat to your bot.\n\n7. You can call the Twilio phone number directly from your own phone. Alternatively, you can make the call using the following, where `+123456789` is the Twilio number you bought and `+19876543210` is your phone number and `abcdef.ngrok.io` is your ngrok host.\n\nShell\n\n```code-block text-sm\n\n$twilio api:core:calls:create --from=\"+123456789\" --to=\"+19876543210\" --url=\"https://abcdef.ngrok.io/twiml\"\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=w5polwjjlkqm)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Build a Voice Agent with Twilio & OpenAI & Deepgram | Deepgram's Docs",
      "title": "Build a Voice Agent with Twilio & OpenAI & Deepgram | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Build a Voice Agent with Twilio & OpenAI & Deepgram | Deepgram's Docs",
      "twitter:description": "Learn how to build a voice agent application that includes Twilio, OpenAI, Deepgram speech-to-text & text-to-speech, while optimizing for low latency.",
      "og:description": "Learn how to build a voice agent application that includes Twilio, OpenAI, Deepgram speech-to-text & text-to-speech, while optimizing for low latency.",
      "ogDescription": "Learn how to build a voice agent application that includes Twilio, OpenAI, Deepgram speech-to-text & text-to-speech, while optimizing for low latency.",
      "theme-color": "#f5f5f7",
      "description": "Learn how to build a voice agent application that includes Twilio, OpenAI, Deepgram speech-to-text & text-to-speech, while optimizing for low latency.",
      "twitter:card": "summary",
      "twitter:title": "Build a Voice Agent with Twilio & OpenAI & Deepgram | Deepgram's Docs",
      "language": "en",
      "scrapeId": "cb08b638-2b9c-4dd3-8975-07e6603ec4ed",
      "sourceURL": "https://developers.deepgram.com/docs/build-voice-agent-with-twilio-deepgram-openai",
      "url": "https://developers.deepgram.com/docs/build-voice-agent-with-twilio-deepgram-openai",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Analyzing the talk time of participants in a classroom, meeting, or phone call can help you improve participant engagement, sales presentations and support response. Using Deepgram’s speech-to-text API with diarization, you can gather the data you need to make informed decisions about your organization’s interactions.\n\nThe demo code in this guide uses an older version of our Node SDK. A new version of our SDK is now available. [A migration guide is available](https://developers.deepgram.com/docs/js-sdk-v2-to-v3-migration-guide).\n\n## Before You Begin\n\nThe example provided is written in Node.js, and you can [find the code on GitHub](https://github.com/deepgram-devs/talk-time-analytics).\n\nBefore you run the code, you’ll need to do a few things:\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\n### Create a Deepgram API Key\n\nTo access Deepgram’s API, you’ll need to [create a Deepgram API Key](https://developers.deepgram.com/documentation/getting-started/authentication#create-an-api-key). Make note of your API Key; you will need it later.\n\n## Getting Started\n\nYou can run this application by running it on your local computer.\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run successfully. Edit the environment variables ( `.env`) to reflect the settings you want to use:\n\n- `PORT`: The port on which you want to run the application. We generally set this to port 3000.\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n\nOnce these variables are set, the application should run automatically.\n\n### Run on localhost\n\nTo run this project on your local computer you will need to clone the repository, configure the settings, install the dependencies, and start the server.\n\n#### Clone the Repository\n\nEither clone or download the [GitHub repository](https://github.com/deepgram-devs/talk-time-analytics) to your local machine in a new directory:\n\nBash\n\n```code-block text-sm\n\n$# Clone this repo>git clone https://github.com/deepgram-devs/talk-time-analytics.git>># Move to the created directory>cd talk-time-analytics\n```\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run. Copy the `.env-example` file into a new file named `.env`, and edit the new file to reflect the settings you want to use:\n\n- `PORT`: The port on which you want to run the application. You can leave this as port 3000.\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n\n#### Install the Dependencies\n\nIn the directory where you downloaded the code, run the following command to bring in the dependencies needed for this project:\n\nBash\n\n```code-block text-sm\n\n$npm install\n```\n\n#### Start the Server\n\nNow that you have configured your application and put the dependencies in place, your application is ready to go! Run it with:\n\nBash\n\n```code-block text-sm\n\n$npm start\n```\n\nBy default, the application runs on port 3000, which means you can access it at `<http://localhost:3000>`.\n\n## Code Walk-through\n\nThe application is an Express app that uses Chart.js to create a pie chart that displays calculated talk time. The key logic that calculates talk time lives in the `server.js` file.\n\n### Sending Data to the Deepgram API\n\nWhen a user uploads a file, we call the `requestDeepgramAPI` function. This function calls the Deepgram API via an `https` request. The key parameter on this request is `diarize=true`. This parameter tells the Deepgram API to recognize speaker changes. When activated, the Deepgram API will assign a zero-based speaker index to each word in the transcript.\n\nJavaScript\n\n```code-block text-sm\n\n1function requestDeepgramAPI({ res, filename, fileUrl, contentType, payload }) {2  try {3    const deepgram = new Deepgram(DG_KEY)4    let audioObj56    if (typeof payload === 'string') {7      audioObj = { url: fileUrl }8    } else {9      audioObj = { buffer: payload, mimetype: contentType }10    }1112    const transcription = await deepgram.transcription.preRecorded(audioObj, {13      punctuate: true,14      diarize: true,15    })1617    const speakers = computeSpeakingTime(transcription)18    res.render('analytics.ejs', {19      speakers,20      filename,21      fileUrl,22    })23  } catch (err) {24    error(res, err)25  }26}\n\n```\n\n### Calculating Talk Time\n\nOnce the response is returned from the Deepgram API, we pass the transcript data to the `computeSpeakingTime` function. In that function, we create a new `Map<number, number>` named `timePerSpeaker`.\n\nThe Deepgram API specifies the start, end, and duration of each word identifies. That information, paired with the indexed speaker returned by the diarization feature of the API, allows us to iterate through each word calculating the full length of time that speaker spoke.\n\nJavaScript\n\n```code-block text-sm\n\n1function computeSpeakingTime(transcript) {2\tconst words = transcript.results.channels[0].alternatives[0].words;34\tif (words.length === 0) {5\t\treturn [];6\t}78\t// `timePerSpeaker` tracks speaker time. Keys9\t// are speaker ID; values are speaking time.10\tconst timePerSpeaker = new Map();11\tlet wordAtLastSpeakerChange = words.shift();12\tfor (const word of words) {13\t\t// If the speaker changes at this word14\t\tif (wordAtLastSpeakerChange.speaker !== word.speaker) {15\t\t\taddSpeakingTime(wordAtLastSpeakerChange.speaker, word.end - wordAtLastSpeakerChange.start, timePerSpeaker);16\t\t\twordAtLastSpeakerChange = word;17\t\t}18\t}1920\tconst lastWord = words[words.length - 1];21\taddSpeakingTime(wordAtLastSpeakerChange.speaker, lastWord.end - wordAtLastSpeakerChange.start, timePerSpeaker);2223\treturn (24\t\t// Convert the Map into an array25\t\t[...timePerSpeaker.entries()]26\t\t\t// Sort by speaker ID (keys of the Map)27\t\t\t.sort((entryA, entryB) => entryA[0] - entryB[0])28\t\t\t// Only keep the speaking times (the values of the Map)29\t\t\t.map((entry) => entry[1])30\t);31}3233function addSpeakingTime(speaker, duration, timePerSpeaker) {34\tconst currentSpeakerDuration = timePerSpeaker.get(speaker) || 0;35\ttimePerSpeaker.set(speaker, currentSpeakerDuration + duration);36}\n\n```\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=it66n5n559jc)",
    "metadata": {
      "og:description": "Using Deepgram's speech-to-text API with diarization, you can gather the data you need to make informed decisions about your organization's interactions.",
      "og:title": "Calculate Talk Time Analytics | Deepgram's Docs",
      "ogTitle": "Calculate Talk Time Analytics | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Calculate Talk Time Analytics | Deepgram's Docs",
      "title": "Calculate Talk Time Analytics | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "ogDescription": "Using Deepgram's speech-to-text API with diarization, you can gather the data you need to make informed decisions about your organization's interactions.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "description": "Using Deepgram's speech-to-text API with diarization, you can gather the data you need to make informed decisions about your organization's interactions.",
      "language": "en",
      "twitter:description": "Using Deepgram's speech-to-text API with diarization, you can gather the data you need to make informed decisions about your organization's interactions.",
      "scrapeId": "154b60e6-091a-42f7-a6f6-bf2149539beb",
      "sourceURL": "https://developers.deepgram.com/docs/calculate-talk-time-analytics",
      "url": "https://developers.deepgram.com/docs/calculate-talk-time-analytics",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "You will need to migrate to the new _**Voice Agent API V1**_ to continue to use the Voice Agent API. Please refer to the [Voice Agent API Migration Guide](https://developers.deepgram.com/docs/voice-agent-v1-migration) for more information.\n\nTo configure your Voice Agent, you’ll need to send a [Settings](https://developers.deepgram.com/docs/voice-agent-settings) message immediately after connection. This message configures the agent’s behavior, input/output audio formats, and various provider settings.\n\nFor more information on the `Settings` message, see the [Voice Agent API Reference](https://developers.deepgram.com/reference/voice-agent-api/agent)\n\n## Settings Overview\n\nThe `Settings` message is a JSON object that contains the following fields:\n\n### Settings\n\n| Parameter | Type | Description |\n| --- | --- | --- |\n| `type` | String | Must be “Settings” to indicate this is a settings configuration message |\n| `experimental` | Boolean | Enables experimental features. Defaults to `false` |\n\n### Audio\n\n| Parameter | Type | Description |\n| --- | --- | --- |\n| `audio.input` | Object | The speech-to-text audio media input configuration |\n| `audio.input.encoding` | String | The encoding format for the input audio. Defaults to `linear16` |\n| `audio.input.sample_rate` | Integer | The sample rate in Hz for the input audio. Defaults to 16000 |\n| `audio.output` | Object | The text-to-speech audio media output configuration |\n| `audio.output.encoding` | String | The encoding format for the output audio |\n| `audio.output.sample_rate` | Integer | The sample rate in Hz for the output audio |\n| `audio.output.bitrate` | Integer | The bitrate in bits per second for the output audio |\n| `audio.output.container` | String | The container format for the output audio. Defaults to `none` |\n\n### Agent\n\n| Parameter | Type | Description |\n| --- | --- | --- |\n| `agent.language` | String | The language code for the agent. Defaults to `en` |\n| `agent.listen.provider.type` | Object | The speech-to-text provider type. Currently only Deepgram is supported |\n| `agent.listen.provider.model` | String | The [Deepgram speech-to-text model](https://developers.deepgram.com/docs/models-languages-overview) to be used |\n| `agent.listen.provider.keyterms` | Array | The [Keyterms](https://developers.deepgram.com/docs/keyterms) you want increased recognition for |\n| `agent.think.provider.type` | Object | The [LLM Model](https://developers.deepgram.com/docs/voice-agent-llm-models) provider type e.g., `open_ai`, `anthropic`, `x_ai`, `amazon_bedrock` |\n| `agent.think.provider.model` | String | The LLM model to use |\n| `agent.think.provider.temperature` | Number | Controls the randomness of the LLM’s output. Range: 0-2 for OpenAI, 0-1 for Anthropic |\n| `agent.think.endpoint` | Object | Optional if LLM provider is Deepgram. Required for non-Deepgram LLM providers. When present, must include `url` field and `headers` object |\n| `agent.think.functions` | Array | Array of functions the agent can call during the conversation |\n| `agent.think.functions.endpoint` | Object | The Function endpoint to call. if not passed, function is called client-side |\n| `agent.think.prompt` | String | The system prompt that defines the agent’s behavior and personality |\n| `agent.speak.provider.type` | Object | The [TTS Model](https://developers.deepgram.com/docs/voice-agent-tts-models) provider type. e.g., `deepgram`, `eleven_labs`, `cartesia`, `open_ai` |\n| `agent.speak.provider.model` | String | The [TTS Model](https://developers.deepgram.com/docs/voice-agent-tts-models) to use for Deepgram or OpenAI |\n| `agent.speak.provider.model_id` | String | The [TTS Model](https://developers.deepgram.com/docs/voice-agent-tts-models) ID to use for Eleven Labs or Cartesia |\n| `agent.speak.provider.voice` | Object | Voice configuration for Cartesia provider. Requires `model` and `id` |\n| `agent.speak.provider.language` | String | Optional language setting for Cartesia provider |\n| `agent.speak.provider.language_code` | String | Optional language code for Eleven Labs provider |\n| `agent.speak.provider.engine` | String | Optional engine for AWS Polly provider |\n| `agent.speak.provider.credentials` | Object | Optional credentials for AWS Polly provider. When present, must include `type`, `region`, `access_key_id`, `secret_access_key` and `session_token` if STS is used |\n| `agent.speak.endpoint` | Object | Optional if TTS provider is Deepgram. Required for non-Deepgram TTS providers. When present, must include `url` field and `headers` object |\n| `agent.greeting` | String | Optional initial message that the agent will speak when the conversation starts |\n\n## Full Example\n\nBelow is an in-depth example showing all the available fields for `Settings` with all the optional fields for individual provider specific settings.\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"Settings\",3  \"experimental\": false,4  \"mip_opt_out\": false,5  \"audio\": {6    \"input\": {7      \"encoding\": \"linear16\",8      \"sample_rate\": 240009    },10    \"output\": {11      \"encoding\": \"mp3\",12      \"sample_rate\": 24000,13      \"bitrate\": 48000,14      \"container\": \"none\"15    }16  },17  \"agent\": {18    \"language\": \"en\",19    \"listen\": {20      \"provider\": {21        \"type\": \"deepgram\",22        \"model\": \"nova-3\",23        \"keyterms\": [\"hello\", \"goodbye\"]24      }25    },26    \"think\": {27      \"provider\": {28        \"type\": \"open_ai\",29        \"model\": \"gpt-4o-mini\",30        \"temperature\": 0.731      },32      \"endpoint\": { // Optional for non-Deepgram LLM providers. When present, must include url field and headers object33        \"url\": \"https://api.example.com/llm\",34        \"headers\": {35          \"authorization\": \"Bearer {{token}}\"36        }37      },38      \"prompt\": \"You are a helpful AI assistant focused on customer service.\",39      \"functions\": [40        {41          \"name\": \"check_order_status\",42          \"description\": \"Check the status of a customer order\",43          \"parameters\": {44            \"type\": \"object\",45            \"properties\": {46              \"order_id\": {47                \"type\": \"string\",48                \"description\": \"The order ID to check\"49              }50            },51            \"required\": [\"order_id\"]52          },53          \"endpoint\": { // If not provided, function is called client-side54            \"url\": \"https://api.example.com/orders/status\",55            \"method\": \"post\",56            \"headers\": {57              \"authorization\": \"Bearer {{token}}\"58            }59          }60        }61      ]62    },63    \"speak\": {64      \"provider\": {65        \"type\": \"deepgram\",66        \"model\": \"aura-2-thalia-en\", // Optional if TTS provider is Deepgram. Use for OpenAI OR Deepgram67        \"model_id\": \"1234567890\", // Optional if TTS provider is Deepgram. Use for Eleven Labs OR Cartesia68        \"voice\": {69          \"mode\": \"Cartesia mode type\", // Optional if TTS provider is Deepgram. Use for Cartesia70          \"id\": \"voice id\" // Optional if TTS provider is Deepgram. Use for Cartesia or OpenAI71        },72        \"language\": \"en\", // Optional if TTS provider is Deepgram. Use for Cartesia73        \"language_code\": \"en-US\", // Optional if TTS provider is Deepgram. Use for Eleven Labs74        \"engine\": \"standard\", // Optional if TTS provider is Deepgram. Use for AWS Polly75        \"credentials\": { // Optional if TTS provider is Deepgram. Use for AWS Polly76          \"region\": \"us-east-1\",77          \"access_key_id\": \"{{access_key_id}}\",78          \"secret_access_key\": \"{{secret_access_key}}\"79          \"session_token\": \"{{session_token}}\" // Optional if TTS provider is Deepgram. Use for AWS Polly STS80        }81      },82      \"endpoint\": {83        \"url\": \"https://api.example.com/tts\",84        \"headers\": {85          \"authorization\": \"Bearer {{token}}\"86        }87      }88    },89    \"greeting\": \"Hello! How can I help you today?\"90  }91}\n\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=qmn4djy2641z)",
    "metadata": {
      "og:description": "Learn about the voice agent configuration options for the agent, and both input and output audio.",
      "twitter:title": "Configure the Voice Agent | Deepgram's Docs",
      "ogTitle": "Configure the Voice Agent | Deepgram's Docs",
      "title": "Configure the Voice Agent | Deepgram's Docs",
      "ogDescription": "Learn about the voice agent configuration options for the agent, and both input and output audio.",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:description": "Learn about the voice agent configuration options for the agent, and both input and output audio.",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:title": "Configure the Voice Agent | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "language": "en",
      "description": "Learn about the voice agent configuration options for the agent, and both input and output audio.",
      "scrapeId": "797c5622-d55e-4fe3-a47e-2b685e7ae133",
      "sourceURL": "https://developers.deepgram.com/docs/configure-voice-agent",
      "url": "https://developers.deepgram.com/docs/configure-voice-agent",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "API keys are associated with Deepgram [Projects](https://developers.deepgram.com/docs/managing-projects), which organize all of your Deepgram resources and consist of a set of users, a set of API keys, and billing and monitoring settings.\n\nWhen you create an API key, you assign it a Role, which determines which actions it can be used to perform in the associated Project. Deepgram uses a tiered system of access control to provide granular access to its endpoints. To learn more about roles, see [Working with Roles](https://developers.deepgram.com/docs/working-with-roles).\n\nWhen you sign up, we automatically create your 1st Project for you.\n\n### Create an API key using the Deepgram Console\n\nYou must create your first API key using the [Deepgram Console](https://console.deepgram.com/signup?jump=keys). Thereafter, you can continue to add additional API keys using the Console, or you can [create additional API Keys using the Deepgram API](https://developers.deepgram.com/docs/create-additional-api-keys#create-an-api-key-using-the-deepgram-api).\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. Locate the **Projects** drop down on the top-left, select the project to which you want to add an API Key.\n\n3. Select **Settings**.\n\n4. Select the **API Keys** view.\n\n5. Select **Create a New API Key**.\n\n6. Enter settings, and select **Create Key**:\n\n\n\n\n\n\n\n\n\n\n| Name | Description |\n| --- | --- |\n| **Friendly Name (Comment)** | Name or comment to help you identify and differentiate between your keys. |\n| **Permissions** | Role to assign to the API Key. The API Key may perform only the actions allowed by the permissions associated with this role. To learn more about roles, see [Working with Roles](https://developers.deepgram.com/docs/working-with-roles). |\n| **Expiration** | Expiration date to assign to the API Key. You can enter a specific date, select a duration of time to keep the key valid, or set the key to never expire. |\n| **Tag** | Labels to associate with the API Key. Any requests sent using the key will also be tagged with the associated labels. Once set, tags cannot be changed. To learn more about managing multiple projects using tags, see [Using Multiple Projects](https://developers.deepgram.com/docs/using-multiple-projects). |\n\n7. Copy the **key secret** and save it somewhere safe, then select **Got it**. For security reasons, we won’t be able to show you the key again.\n\n\n### Create an API Key using the Deepgram API\n\nOnce you created your first API key using the Deepgram Console you can now use the API to create additional keys as needed.\n\nRefer to the API Reference [Create Key](https://developers.deepgram.com/reference/create-key) for more information.\n\n**Example Request**\n\ncURL\n\n```code-block text-sm\n\n$curl --request POST \\>     --url https://api.deepgram.com/v1/projects/your_project_id/keys \\>     --header 'Authorization: Token YOUR_TOKEN' \\>     --header 'accept: application/json' \\>     --header 'content-type: application/json' \\>     --data '>{>  \"comment\": \"a nice comment\",>  \"scopes\": [>    \"usage:read\",>    \"usage:write\",>    \"keys:write\">  ]>}>'\n```\n\n* * *\n\nWhat’s Next\n\n- [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=7zjemlghn6k)",
    "metadata": {
      "title": "Creating API Keys | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogDescription": "Learn about the fundamentals of creating API keys with the Deepgram Console or the Deepgram API.",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Creating API Keys | Deepgram's Docs",
      "description": "Learn about the fundamentals of creating API keys with the Deepgram Console or the Deepgram API.",
      "og:title": "Creating API Keys | Deepgram's Docs",
      "twitter:description": "Learn about the fundamentals of creating API keys with the Deepgram Console or the Deepgram API.",
      "twitter:title": "Creating API Keys | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Learn about the fundamentals of creating API keys with the Deepgram Console or the Deepgram API.",
      "language": "en",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "theme-color": "#f5f5f7",
      "scrapeId": "6a748efa-1db9-41e3-83ae-203a3cda1d00",
      "sourceURL": "https://developers.deepgram.com/docs/create-additional-api-keys",
      "url": "https://developers.deepgram.com/docs/create-additional-api-keys",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "In this guide, we’ll explain how to spin up the integration in your AWS environment and build a contact flow with real-time transcription\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\n## Before you Begin\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n### Set Up an Amazon Connect Instance\n\nYou’ll also need an Amazon Connect instance that is configured to receive incoming calls. [This guide](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-contact-centers.html) walks you through the process.\n\n## Architecture Overview\n\n![Architecture Overview](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe00f6f2-architecture_overview.png&w=3840&q=75)\n\nThis diagram shows how the integration works at a high level.\n\n1. A customer calls into your Amazon Connect call center.\n2. The customer enters a contact flow.\n3. Within the contact flow, you use a “Start Media Streaming” block to begin sharing call audio with Kinesis Video Streams (KVS).\n4. You set contact attributes to configure Deepgram. These give you access to the full Deepgram streaming API, including features like smart formatting and interim results. This is also where you set the callback URL where you want to receive the transcripts.\n5. The contact flow then invokes a Lambda function, which we call the “trigger Lambda” or `kvs_dg_trigger`.\n6. The Lambda function makes a POST request to a Fargate task, telling it to kick off a session. The Fargate task is called `kvs_dg_integrator`. It is really a cluster of Fargate tasks running on ECS behind a load balancer.\n7. For the duration of the call, the Fargate task pulls the call audio from KVS and passes it along to Deepgram.\n8. Deepgram transcribes the audio and POSTs the transcripts to your callback URL in real-time.\n\nThe core of this integration is a CloudFormation template, which spins up the Lambda function and Fargate cluster in your environment.\n\n## Deploy the Integration\n\n### Prerequisites\n\n1. Install the [Docker CLI](https://docs.docker.com/engine/install/). If you’re on Windows or Mac and run into issues with licensing requirements, [Podman](https://podman.io/docs/installation) can be used as a nearly drop-in replacement.\n2. Install the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html). Make sure it’s configured to use the same region as your Connect instance.\n3. Clone the [integration repo](https://github.com/deepgram/amazon-connect-integration) from GitHub.\n\n### Prepare the Docker Images\n\n1. Create these two ECR repos in your AWS environment:\n\n\n\n\n\n\n\n\n\nShell\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n$aws ecr create-repository --repository-name kvs-dg-trigger>aws ecr create-repository --repository-name kvs-dg-integrator\n```\n\n2. Log in to ECR with the Docker CLI. This will enable you to push images to the repos.\n\n\n\n\n\n\n\n\n\nShell\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n$aws ecr get-login-password --region <YOUR-REGION> | docker login --username AWS --password-stdin <YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com\n```\n\n3. In the `kvs_dg_trigger` folder in the integration repo, build the Docker image for the trigger Lambda:\n\n\n\n\n\n\n\n\n\nShell\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n$docker build --platform linux/amd64 -t <YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-trigger:latest .\n```\n\n4. In the `kvs_dg_integrator` folder, build the Docker image for the integrator task:\n\n\n\n\n\n\n\n\n\nShell\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n$docker build --platform linux/amd64 -t <YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-integrator:latest .\n```\n\n5. Push the new Docker images to ECR:\n\n\n\n\n\n\n\n\n\nShell\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n$docker push <YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-trigger:latest>docker push <YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-integrator:latest\n```\n\n\n### Spin Up the CloudFormation Stack\n\n01. Go to CloudFormation in the AWS Console. Make sure you’re in the same region as your Connect instance, then click **Create stack** \\> **With new resources**.\n\n02. Under **Specify template**, select **Upload a template file**.\n\n03. Click **Choose file** and pick `cloudformation.yaml` from the Git repo you cloned.\n\n04. Give the stack a name such as `deepgram-connect-integration`.\n\n05. If you’re self-hosting Deepgram, change the **Deepgram API** field to the URL where your self-hosted instance is deployed. Otherwise leave it as the default.\n\n06. Paste your API key under **Deepgram API Key**.\n\n07. Select the **VPC ID** and **Subnets** where you want to deploy the integration.\n    1. The subnets need outbound internet access in order to pull the task image from ECR. This means you’ll need to use either public subnets, or private subnets with access to a NAT gateway. Users who want a more isolated setup can edit the CloudFormation template to use [PrivateLink](https://docs.aws.amazon.com/vpc/latest/privatelink/what-is-privatelink.html) to eliminate the need for internet access, but as of today the integration doesn’t support this out-of-the-box.\n08. Under **Trigger Lambda** \\> **Image URI**, paste in the image you just pushed to ECR: `<YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-trigger:latest`.\n\n09. Under **Integrator ECS Service** \\> **Task Image URI**, paste in the other image you pushed: `<YOUR-ACCOUNT-NUMBER>.dkr.ecr.<YOUR-REGION>.amazonaws.com/kvs-dg-integrator:latest`.\n\n10. Adjust **Desired Task Count**, **Task CPU**, and **Task Memory**.\n    1. For testing out the integration, or if you expect minimal load, **Desired Task Count** = `1`, **Task CPU** = `256`, and **Task Memory** = `1024` will work fine. Using [Fargate prices](https://aws.amazon.com/fargate/pricing/) at the time of writing, a task at these settings will cost ~0.015 per hour, or \\\\~10.84 per month.\n    2. For any significant load, you will likely want at least a full vCPU, something like **Task CPU** = `1024`, and **Task Memory** = `4096`, which comes out to ~0.058 per hour, or \\\\~43.35 per month. We’ve found these settings will support up to 200 concurrent calls.\n    3. Whatever values you choose, a good rule of thumb is to keep memory at 4 times CPU in order to utilize both resources to the fullest while avoiding OOMs.\n\nThis integration favors a simple and easy-to-deploy setup, but it is not aggressively optimized for cost. There are a couple of measures you can take to reduce Fargate cost at the expense of some higher complexity:\n\n11. Click through the **Next** buttons and then **Submit** the stack for creation\n12. Once everything completes successfully, the integration is deployed and available for use by your Connect instance.\n\n## Run the Sample Contact Flow\n\nThe GitHub repo also includes an Amazon Connect contact flow that demonstrates how to use the deployed integration. To run the contact flow, follow these steps:\n\n1. Add the newly deployed trigger Lambda to your Amazon Connect instance ( [guide](https://docs.aws.amazon.com/connect/latest/adminguide/connect-lambda-functions.html#add-lambda-function)).\n2. Enable live media streaming in your Amazon Connect instance ( [guide](https://docs.aws.amazon.com/connect/latest/adminguide/enable-live-media-streams.html)). Choosing **No data retention** is fine, unless you plan to load test the integration with the built-in load testing functionality, in which case you should choose a retention period at least as long as your load test duration.\n3. Create a new inbound contact flow and import `sample_contact_flow.json` ( [guide](https://docs.aws.amazon.com/connect/latest/adminguide/contact-flow-import-export.html#how-to-import-export-contact-flows)).\n4. In the **Deepgram Configuration** block, go to **Edit Settings** and update `dg_callback` to a URL where you want to receive the transcripts. The transcripts will be sent as POST requests to the URL you provide. For testing, you can use a site like [Beeceptor](https://beeceptor.com/) to create a URL that will display the contents of the POST requests.\n5. In the **Invoke Trigger Lambda** block, go to **Edit Settings** and select the trigger Lambda function from the **Function ARN** dropdown.\n6. Save and publish the contact flow.\n7. Assign the contact flow to a phone number ( [guide](https://docs.aws.amazon.com/connect/latest/adminguide/associate-claimed-ported-phone-number-to-flow.html)).\n8. Call into the phone number. After it plays the initial message, say something and watch your callback server to make sure your words are being transcribed.\n\n## Configure Deepgram\n\nWhen transcribing Connect calls, you can use any of the features of [Deepgram’s streaming API](https://developers.deepgram.com/reference/streaming). You select features in the streaming API by using a **Set contact attributes** block in the contact flow. These attributes must be set before invoking the trigger Lambda, since they will be passed to the Lambda, which will pass them to the integrator, which will ultimately pass them to Deepgram.\n\nThe sample contact flow described above includes some basic Deepgram configuration. Let’s now look at an example similar to what you will find in the sample flow.\n\n![ Deepgram Contact Attributes](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe465535-dg-config.png&w=3840&q=75)\n\nSetting Deepgram Contact Attributes\n\nThis image shows 3 Deepgram features being set:\n\n- `dg_model` is set to `nova`. This adds `model=nova` to the query parameters of the Deepgram request.\n- `dg_tag` is set to `someTag someOtherTag`. This adds `tag=someTag&tag=someOtherTag` to the query parameters of the Deepgram request.\n- `dg_callback` is set to `https://example.com/{contact-id}`. As you would expect, this adds a `callback` to the query parameters of the Deepgram request—but it also injects the contact ID of the current call. In other words, if a Connect call has contact ID `002f61e1-423e-415d-b086-697186514860`, then the transcripts for that call will be POSTed to `https://example.com/002f61e1-423e-415d-b086-697186514860`. Injecting contact IDs like this is only possible within the `dg_callback` contact attribute. This enables you to associate transcripts with calls.\n\nThere are a few features in the Deepgram streaming API that you should not attempt to set in the contact flow. These are:\n\nThe integrator already knows the `encoding` and `sample_rate`, and we lock `multichannel=true` and `channels=2` so that you can receive transcripts for both sides of the call. If you try to manually set any of these values, the session will fail.\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n![Architecture Overview](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe00f6f2-architecture_overview.png&w=3840&q=75)\n\n![ Deepgram Contact Attributes](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe465535-dg-config.png&w=3840&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=do8o8c1f16hm)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "Amazon Connect and Deepgram | Deepgram's Docs",
      "title": "Amazon Connect and Deepgram | Deepgram's Docs",
      "twitter:description": "Amazon Connect is a popular platform for hosting cloud contact centers. Our integration enables you to transcribe your Connect calls in real-time with Deepgram.",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogDescription": "Amazon Connect is a popular platform for hosting cloud contact centers. Our integration enables you to transcribe your Connect calls in real-time with Deepgram.",
      "twitter:title": "Amazon Connect and Deepgram | Deepgram's Docs",
      "description": "Amazon Connect is a popular platform for hosting cloud contact centers. Our integration enables you to transcribe your Connect calls in real-time with Deepgram.",
      "generator": "https://buildwithfern.com",
      "og:description": "Amazon Connect is a popular platform for hosting cloud contact centers. Our integration enables you to transcribe your Connect calls in real-time with Deepgram.",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "og:title": "Amazon Connect and Deepgram | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "scrapeId": "1cdb382a-2622-4b35-9e20-4497ba55cdcf",
      "sourceURL": "https://developers.deepgram.com/docs/deepgram-with-amazon-connect",
      "url": "https://developers.deepgram.com/docs/deepgram-with-amazon-connect",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram offers the following deployment options:\n\n| **Option** | **Description** |\n| --- | --- |\n| Hosted | A multi-tenant cloud service running on Deepgram’s cloud with standard authentication and customization features. |\n| Self-Hosted | A dedicated service deployed to customer-requisitioned cloud instances, such as Amazon Web Services (AWS) or Google Cloud Platform (GCP), or customer data centers. Self-hosting is available for Premium customers who have unique [business requirements](https://developers.deepgram.com/docs/self-hosted-introduction#why-self-host). |\n\n## Operational Differences\n\n| **Operation** | **Hosted** | **Self-Hosted** |\n| --- | --- | --- |\n| **Deployment Location** | Deepgram’s infrastructure | Customer-requisitioned cloud instance, such as AWS or GCPCustomer data center |\n| **Infrastructure & Backup Responsibility** | Deepgram | Customer |\n| **Updates** | Automatic rolling updates | Deepgram makes regular updates available for customer to apply. In case of critical updates (for example, security patches), Deepgram notifies customer. |\n| **Service & Uptime Reporting** | Monitored by Deepgram | Monitored by customer |\n\n* * *\n\nWhat’s Next\n\n- [Self-Hosted Introduction](https://developers.deepgram.com/docs/self-hosted-introduction)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=zet4i8nwrm19)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "twitter:description": "Learn about the deployment options available for Deepgram services.",
      "ogDescription": "Learn about the deployment options available for Deepgram services.",
      "twitter:card": "summary",
      "title": "Deployment Options | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "og:title": "Deployment Options | Deepgram's Docs",
      "twitter:title": "Deployment Options | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:description": "Learn about the deployment options available for Deepgram services.",
      "ogTitle": "Deployment Options | Deepgram's Docs",
      "description": "Learn about the deployment options available for Deepgram services.",
      "scrapeId": "7c0ea3dc-e185-4aa6-8ee1-9bfdf1ee7096",
      "sourceURL": "https://developers.deepgram.com/docs/deployment-options",
      "url": "https://developers.deepgram.com/docs/deployment-options",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "A record of errors and reasons you will receive them when using the Deepgram API.\n\n## General API errors\n\nErrors that could be returned on any endpoint.\n\n### `400` Invalid JSON submitted\n\nWhen making a `POST` request with JSON data, you must include all required fields. If required filed are missing, or the submitted JSON is invalid, a `400 Bad Request` will be returned. The response will be similar to the below, depending on the endpoint and how the JSON is malformed.\n\n```code-block text-sm\n\n1{2  \"category\": \"INVALID_JSON\",3  \"message\": \"Invalid JSON submitted.\",4  \"details\": \"Json deserialize error: missing field `xxx` at line 7 column 1\",5  \"request_id\": \"uuid\"6}7---8{9  \"err_code\": \"Bad Request\",10  \"err_msg\": \"Content-type was application/json, but we could not process the JSON payload.\",11  \"request_id\": \"uuid\"12}13---14{15  \"category\": \"INVALID_JSON\",16  \"message\": \"Invalid JSON submitted.\",17  \"details\": \"Json deserialize error: expected `:` at line 3 column 13\",18  \"request_id\": \"uuid\"19}\n```\n\n### `400` Unknown request body format\n\nIf you receive the following error:\n\n```code-block text-sm\n\n1{2  \"err_code\": \"Bad Request\",3  \"err_msg\": \"Bad Request: failed to process audio: corrupt or unsupported data\",4  \"request_id\": \"uuid\"5}\n```\n\nOften, this is caused by sending Deepgram a URL to transcribe, but failing to set a `Content-Type: application/json` header. When sending Deepgram a JSON payload containing a URL, the `Content-Type: application/json` must be set in the request.\n\nIf you are sending an audio file and not a URL, you may be sending corrupted audio. You can use tools such as `ffprobe` or Audacity to confirm that your audio file is valid.\n\n### `401` Incorrect API key\n\nProviding an invalid API key will return `401 Unauthorized` with the following error.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"INVALID_AUTH\",3  \"err_msg\": \"Invalid credentials.\",4  \"request_id\": \"uuid\"5}\n```\n\n### `401` Insufficient permissions\n\nMaking a request that you do not have sufficient permissions for will return `401 Unauthorized` with this error.\n\n```code-block text-sm\n\n1{2 \"err_code\":\"INSUFFICIENT_PERMISSIONS\",3 \"err_msg\":\"User does not have sufficient permissions.\",4 \"request_id\":\"uuid\"5}\n```\n\n### `403` Insufficient permissions\n\nMaking a request for a model that you do not have access to will return `403 Forbidden` with this error.\n\n```code-block text-sm\n\n1{2 \"err_code\":\"INSUFFICIENT_PERMISSIONS\",3 \"err_msg\":\"Project does not have access to the requested model.\",4 \"request_id\":\"uuid\"5}\n```\n\n### `404` UUID parsing failed\n\nProviding an invalid Project ID will fail parsing and return `404 Not Found` and this response.\n\n```code-block text-sm\n\nUUID parsing failed: invalid character: expected an optional prefix of `urn:uuid:` followed by [0-9a-zA-Z], found `p` at 1\n```\n\n### `404` Project not found\n\nWhen a project isn’t found it will result in `404 Not Found`. It may be because;\n\n- the Project ID is incorrect\n- the Project ID is for a project that has been deleted\n- the Project ID is not associated with the API key used to make the request\n\n```code-block text-sm\n\n1{2  \"err_code\": \"PROJECT_NOT_FOUND\",3  \"err_msg\": \"Project not found.\"4}\n```\n\n## Speech to Text errors\n\n### `402` Insufficient credits\n\nWhen attempting to transcribe a file, you may not have sufficient funds to complete the request. This will result in a `402 Payment Required` error with this error.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"ASR_PAYMENT_REQUIRED\",3  \"err_msg\": \"Project does not have enough credits for an ASR request and does not have an overage agreement.\",4  \"request_id\": \"uuid\"5}\n```\n\n### `429` Rate limit exceeded\n\nWhen requests are made in excess of Deepgram’s [rate limits](https://developers.deepgram.com/docs/getting-started-with-pre-recorded-audio#rate-limits), a `429 Too Many Requests` is returned with the following error. An [exponential-backoff retry strategy](https://deepgram.com/learn/api-back-off-strategies) is recommended to accommodate rate-limiting when submitting a large volume of concurrent requests.\n\njson\n\n```code-block text-sm\n\n1{2  \"err_code\": \"TOO_MANY_REQUESTS\",3  \"err_msg\": \"Too many requests. Please try again later\",4  \"request_id\": \"uuid\"5}\n```\n\n## Text to Speech Errors\n\n### `400` Unknown Model. Query parameters specify a model that does not exist.\n\nThe model requested is not one of Deepgram’s [voice models](https://developers.deepgram.com/docs/tts-models).\n\n```code-block text-sm\n\n1{2  \"err_code\": \"Bad Request\",3  \"err_msg\": \"Bad Request: No such model/version combination found.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Failure to Parse Query Parameters\n\nThe query parameters were invalid. The `message` can be anything describing a failure to parse an invalid query string.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"INVALID_QUERY_PARAMETER\",3  \"err_msg\": \"Failed to deserialize query parameters: [message]\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Input Text Contained No Characters\n\nThe text payload contained no characters, resulting in Deepgram being unable to synthesize text into audio.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"Bad Request\",3  \"err_msg\": \"Input text contains no characters.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Unsupported Output Audio Format Requested in Query Parameters\n\nThe request provides a query string containing any combination of query parameters that describes an unsupported output audio format.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"INVALID_QUERY_PARAMETER\",3  \"err_msg\": \"Unsupported audio format: [message]\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\nOne or more of the following query parameters is unsupported:\n\n- `encoding=[encoding]`\n- `container=[container]`\n- `sample_rate=[sample_rate]`\n- `bit_rate=[bit_rate]`\n\n`message` may be any one of:\n\n- “ `container` is not applicable when `encoding=[encoding]`”\n- “ `container=[container]` is invalid when `encoding=[encoding]`”\n- “ `sample_rate` is not applicable when `encoding=[encoding]`”\n- “ `sample_rate` must be \\[list of valid sample rates\\] when `encoding=[encoding]`”\n- “ `bit_rate` is not applicable when `encoding=[encoding]`”\n- “ `bit_rate` must be \\[list of valid bit rates\\] when `encoding=[encoding]`”\n\n### `400` Failure to Parse Request Body as JSON\n\nThe request body did not deserialize as JSON successfully. The request body must specify exactly one of `text` or `url` in the body.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"PAYLOAD_ERROR\",3  \"err_msg\": \"Failed to deserialize JSON payload. Please specify exactly one of `text` or `url` in the JSON body.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Failure to Parse Remote Text URL Provide in JSON\n\nThere was a failure to parse a remote text URL provided within the JSON body.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"PAYLOAD_ERROR\",3  \"err_msg\": \"Failed to parse URL in JSON body.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Failure to Fetch Remote Text from URL\n\nThere was a failure to retrieve remote text content from the specified URL.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"REMOTE_CONTENT_ERROR\",3  \"err_msg\": \"[message]\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n`message` may be any of:\n\n- “Failed to deserialize remote text data. Please provide `application/json` with a `text` field or `text/plain`.”\n- “URL for media download must be publicly routable.”\n- “Could not determine if URL for media download is publicly routable.”\n- “Could not parse URL as a URI.”\n- “The remote server hosting the media failed to include a `location` header in its redirect response.”\n- “Could not parse remote media server’s redirect location as a valid UTF-8 string.”\n- “Could not parse remote media server’s redirect location as a URL.”\n- “The remote server hosting the media returned a client error: \\[HTTP status\\].”\n- “The remote server hosting the media failed to return valid data.”\n- “The remote server hosting the media returned too many redirects.”\n\n### `400` Invalid Callback\n\nThe provided callback url was invalid.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"INVALID_QUERY_PARAMETER\",3  \"err_msg\": \"Invalid callback url.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `413` Request Body Exceeded 2MB\n\nThe request body exceeded the 2MB limit, indicating that the payload size is too large to be processed.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"PAYLOAD_TOO_LARGE\",3  \"err_msg\": \"Payload size exceeds limit of 2 MB.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `413` Input Text Exceeded Character Limit\n\nThe text payload contained more than 2400 characters, which is above the character limit for text-to-speech requests.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"Payload Too Large\",3  \"err_msg\": \"Input text exceeds maximum character limit of 2400.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `400` Failure to Decode Request Body as UTF-8\n\nThe payload cannot be decoded because it is not encoded as UTF-8.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"PAYLOAD_ERROR\",3  \"err_msg\": \"Failed to decode payload as UTF-8.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `415` Unsupported Content Type in Request\n\nThe `Content-Type` header in the request is not supported, requiring it to be either `text/plain` or `application/json`.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"UNSUPPORTED_MEDIA_TYPE\",3  \"err_msg\": \"`Content-Type` header is not supported. `Content-Type` must be either `text/plain` or `application/json`.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n### `429` Rate Limit Exceeded\n\nWhen requests are made in excess of Deepgram’s rate limits.\n\n```code-block text-sm\n\n1{2  \"err_code\": \"Too Many Requests\",3  \"err_msg\": \"Please try again later.\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n- Learn about strategies for handling 429 errors in our [Help Center.](https://deepgram.gitbook.io/help-center/faq/how-should-i-handle-429-rate-limit-responses)\n\n### `503` Service Unavailable\n\n```code-block text-sm\n\n1{2  \"error_code\":\"Service Unavailable\",3  \"err_msg\": \"Please try again later\",4  \"request_id\": \"[unique_request_id]\"5}\n```\n\n## Handling HTTP Errors\n\n### Production\n\nSome error codes, such as `400: Bad Request` errors, can be prevented in your production code by careful testing and development. However, others, such as `503: Service Unavailable`, can occur regardless of your implementation.\n\nBelow is a list of HTTP error codes that your production code should handle gracefully. Some of these errors may succeed if retried, while others (such as `414: URI Too Long`) need to be handled by modifying the request.\n\n- **408 Request Timeout**: The server timed out waiting for the request.\n- **411 Length Required**: The server refuses to accept the request without a defined Content-Length.\n- **413 Request Entity Too Large**: The request is larger than the server is willing or able to process.\n- **414 URI Too Long**: The server is refusing to service the request because the request-target is longer than the server is willing to interpret.\n- **429 Too Many Requests**: The user has sent too many requests in a given amount of time.\n- **499 Client Closed Request**: A non-standard status code indicating that the client closed the connection.\n- **500 Internal Server Error**: A generic error message indicating that the server has encountered a situation it doesn’t know how to handle.\n- **502 Bad Gateway**: The server, while acting as a gateway or proxy, received an invalid response from the upstream server it accessed in attempting to fulfill the request.\n- **503 Service Unavailable**: The server is not ready to handle the request. Common causes include a server that is down for maintenance or is overloaded.\n- **504 Gateway Timeout**: The server, while acting as a gateway or proxy, did not receive a timely response from the upstream server or some other auxiliary server it needed to access in order to complete the request.\n\n### Development\n\nThe following errors are more likely to be encountered in a development environment. You may want to add error handling in your production code to gracefully handle these error codes as well.\n\n- **400 Bad Request**: The server could not understand the request due to invalid syntax.\n- **401 Insufficient permissions**: The project does not have permissions to access the requested features or model.\n- **401 Unauthorized**: The API key is invalid or unauthorized.\n- **402 Payment Required**: The project has insufficient funds to complete the request.\n- **403 Forbidden**: The server understood the request but refuses to authorize it.\n- **404 Not Found**: The specified entity ID could not be found.",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "og:title": "Errors | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "ogTitle": "Errors | Deepgram's Docs",
      "description": "Errors you might encounter when making requests to the Deepgram API",
      "ogDescription": "Errors you might encounter when making requests to the Deepgram API",
      "twitter:description": "Errors you might encounter when making requests to the Deepgram API",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "twitter:title": "Errors | Deepgram's Docs",
      "og:description": "Errors you might encounter when making requests to the Deepgram API",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "generator": "https://buildwithfern.com",
      "title": "Errors | Deepgram's Docs",
      "scrapeId": "445075b4-9d2c-42d8-97d1-d185a881f6c1",
      "sourceURL": "https://developers.deepgram.com/docs/errors",
      "url": "https://developers.deepgram.com/docs/errors",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "In this guide, we’ll explain how to configure Deepgram as your transcription engine in Genesys.\n\n## Before you begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n### Set Up a Genesys Cloud Org\n\nYou’ll also need a Genesys Cloud org where you have completed the [initial setup tasks](https://help.mypurecloud.com/articles/new-users-home/) so that your call center can receive calls.\n\n## Install Transcription Connector\n\nIn your Genesys org, follow [the steps to install Transcription Connector](https://help.mypurecloud.com/articles/install-transcription-connector-from-genesys-appfoundry/). The feature is currently in Limited Availability, so you may need to work with Genesys to give your org access.\n\n## Configure Transcription Connector\n\nOnce you’ve installed Transcription Connector, it will appear under **Admin > Integrations** in the Genesys UI.\n\n1. Click the three dots on the **Transcription Connector** row and choose **Edit Integration**.\n\n2. Under **Configuration > Properties**, set **Channel** to `both` and **Connection URI** to `wss://integrations.deepgram.com/genesys`.\n\n3. Under **Configuration > Credentials**, click **Configure** and paste your Deepgram API key into the **API Key** field. Leave the **Client Secret** field blank. Then click **OK**.\n\n\n\n\n\n\n\n\n\n\n\nIf you specify an API key and then change it, it can take a long time for the new API key to propagate through the Genesys system. Give it 30 minutes before you assume that Deepgram is receiving the new API key. If you don’t want to wait, you can delete Transcription Connector from the **Integrations** page, reinstall it, and provide the new API key to the reinstalled Transcription Connector.\n\n\n## Set advanced configuration\n\nUnder **Configuration > Advanced**, provide a JSON object to customize the Deepgram request. For example:\n\nJSON\n\n```code-block text-sm\n\n1{2  \"model\": \"nova-3\",3  \"smart_format\": true,4  \"endpointing\": 500,5  \"tag\": [6    \"sometag1\",7    \"sometag2\"8  ]9}\n```\n\nWithin this JSON object, you have access to [the full suite of features in Deepgram’s streaming API](https://developers.deepgram.com/reference/streaming). However, be careful **NOT** to include any of the following, as they would prevent the integration from working correctly:\n\n- `sample_rate`\n- `encoding`\n- `channels`\n- `multichannel`\n- `callback`\n\nSetting `endpointing` to a high value like `500` is recommended for best transcript accuracy.\n\n## Activate integration\n\nBack in **Admin > Integrations**, flip the switch to activate the integration. Make sure it goes into the blue **Active** state and no errors are displayed.\n\n## Choose where to use the Transcription Connector\n\nFollow [the Genesys docs](https://help.mypurecloud.com/articles/configure-voice-transcription/) to select where your newly configured transcription engine will be used.\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=dfjg6ttdy64)",
    "metadata": {
      "title": "Genesys and Deepgram | Deepgram's Docs",
      "twitter:description": "Genesys is a cloud-based platform used by many organizations to manage their call centers. With our plug-and-play Genesys integration, you can have all of your Genesys calls transcribed by Deepgram.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "og:title": "Genesys and Deepgram | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "ogDescription": "Genesys is a cloud-based platform used by many organizations to manage their call centers. With our plug-and-play Genesys integration, you can have all of your Genesys calls transcribed by Deepgram.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Genesys is a cloud-based platform used by many organizations to manage their call centers. With our plug-and-play Genesys integration, you can have all of your Genesys calls transcribed by Deepgram.",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "twitter:title": "Genesys and Deepgram | Deepgram's Docs",
      "ogTitle": "Genesys and Deepgram | Deepgram's Docs",
      "description": "Genesys is a cloud-based platform used by many organizations to manage their call centers. With our plug-and-play Genesys integration, you can have all of your Genesys calls transcribed by Deepgram.",
      "scrapeId": "f432d550-1c28-47c7-8860-f4fa531bec2a",
      "sourceURL": "https://developers.deepgram.com/docs/genesys-deepgram",
      "url": "https://developers.deepgram.com/docs/genesys-deepgram",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Zoom](https://zoom.us/) is a widely-used cloud-based video communications tool that lets you host virtual one-on-one or team meetings, webinars, and live chats and provides audio, video, screen-sharing, and other collaboration features. Zoom offers enhanced Real-Time Messaging Protocol (RTMP) support, which allows you to extract the audio from your content and stream it to Deepgram to get real-time automatic speech recognition for all of your Zoom calls.\n\nIn this guide, the audio from a Zoom conference call will be streamed to a local server. We will fork the stream to our Python script, which will send the audio to Deepgram, then receive and print transcriptions to the screen.\n\nIn a real implementation, you will likely want to modify the script to provide a callback URL to which transcriptions can be sent.\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n### Create a Zoom Pro Account\n\nBefore you can use Zoom’s live streaming, you’ll need to [create a Zoom Pro account](https://zoom.us/signup). Then:\n\n- [enable livestreaming for meetings and webinars](https://support.zoom.us/hc/en-us/articles/360061534591-Enabling-Allow-livestreaming-of-meetings)\n- [allow livestreaming on a custom service](https://support.zoom.us/hc/en-us/articles/115001777826-Live-streaming-meetings-or-webinars-using-a-custom-service)\n\n### Install Development Dependencies\n\nIn order to run the services required for this integration, you will need:\n\n- [npm](https://www.npmjs.com/)\n- [FFmpeg](https://www.ffmpeg.org/download.html)\n- [ngrok](https://ngrok.com/)\n- [rtmpdump](https://github.com/mstorsjo/rtmpdump)\n\nIf you’re using macOS, we recommend using [Homebrew](https://brew.sh/) to install the above dependencies with `brew install <dependency name>`. On Linux, your OS package manager can be substituted instead.\n\nYou will also need a working Python environment with `Python >= 3.6`. We will install the required Python packages in the section “Download and Configure the Streaming Script”.\n\n### Start the RTMP Server\n\nBecause Zoom supports Real-Time Messaging Protocol streaming, we will use a GitHub project called [Node Media Server](https://github.com/illuspas/Node-Media-Server) to create a simple RTMP server to receive and view the stream data.\n\nTo install and start the Node Media Server, run the following command:\n\n`npm i node-media-server -g && node-media-server`\n\nThat should result in output like:\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F3014887-image.png&w=3840&q=75)\n\nTo visit your new server and verify everything is working, navigate to [http://localhost:8000/admin](http://localhost:8000/admin) and log in with the username `admin` and the password `admin`. You should see the following interface if everything is set up correctly:\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe0da771-image.png&w=3840&q=75)\n\n#### Make the Server Publicly Available\n\nNow that we have confirmed the server is running, we’ll need to make it available over the internet so Zoom can send data to it. To do this, we’ll use Ngrok.\n\nWe’ll tell Ngrok to forward TCP traffic for port 1935 (the default port Node Media Server uses for RTMP) through a public tunnel. Open a new terminal window and run:\n\n`ngrok tcp 1935`\n\nThe output should look like this:\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F3d6e5ee-image.png&w=3840&q=75)\n\nMake sure to save the forwarding URL which in this case is `tcp://2.tcp.ngrok.io:12024`. We’ll need to enter this URL in the next step.\n\nThis environment is designed for development, not production. Using ngrok will impact the latency and bandwidth of your stream. Do not use ngrok when conducting performance or latency testing.\n\n### Download and Configure the Streaming Script\n\nNext, clone our [Deepgram + Zoom repo](https://github.com/deepgram-devs/deepgram-zoom).\n\n#### Install Python Dependencies\n\nNavigate to the location where you cloned the Deepgram + Zoom repo. Then run:\n\n`pip install -r requirements.txt`\n\nThere are a few dependencies required for this code. The [websockets](https://pypi.org/project/websockets/) library is used to send and receive messages from Deepgram. We also need [scipy](https://pypi.org/project/scipy/) (a scientific library we will use to handle WAV files), [streamlink](https://pypi.org/project/streamlink/) (a command-line utility that extracts streams from various services and pipes them into a chosen video player), and [requests](https://pypi.org/project/requests/) (a simple HTTP library).\n\n#### Configure Deepgram Authentication\n\nPrior to running the script, you must replace the authentication with your Deepgram username and password.\n\nOn line 17 of `stream.py`, replace `YOUR_DEEPGRAM_API_KEY` with the API Key you created earlier in this tutorial:\n\nPython\n\n```code-block text-sm\n\n117        'Authorization': 'Token YOUR_DEEPGRAM_API_KEY'\n```\n\n### Set Up Your Zoom Conference Call\n\nNext, you will need to start your Zoom meeting and configure your Zoom live-streaming service:\n\n1. Start your Zoom meeting and join the meeting with computer audio.\n\n![Join Zoom with Computer Audio](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F2d38ff0-integrate-zoom_join-computer-audio.png&w=3840&q=75)\n\n2. Select **More…** and then **Live on Custom Live Streaming Service**.\n\n![Zoom More menu](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe9f93f4-integrate-zoom_more-livestream.png&w=3840&q=75)\n\n3. Configure streaming, and select **Go Live!**.\n\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F27cd0af-image.png&w=3840&q=75)\n\n| Field | Description |\n| --- | --- |\n| **Streaming URL** | URL or IP address to which you would like to send audio. Zoom will stream media to this URL, so that other apps can subscribe to the stream. Use the ngrok URL created in the previous step, plus `/live`. Modify the url to start with `rtmp://` instead of `tcp://`. |\n| **Streaming key** | Unique identifier for your meeting instance. Use any unique ID (such as `DEEPGRAM` or `ZOOM`). Make note of the value you enter because you will need it again later. |\n| **Live streaming page URL** | URL to a front-end where users can view the live stream. In this example, we intend to use our `stream.py` script to display results in the terminal on the same machine that hosts the RTMP server indicated in the Streaming URL, so we won’t have a live streaming page. Use any URL in this field (like `https://deepgram.com`). This field is required by Zoom but not needed for our application. If you modified our example streaming script to use a callback URL, then instead, enter the URL to the page that will process and display the transcripts. |\n\n### Send Streaming Results to Deepgram\n\nWe’re ready to start sending Zoom audio to Deepgram and receiving transcriptions!\n\n#### Configure the Zoom Streaming Key\n\nBecause you could be streaming multiple instances of Zoom at the same time, the script needs to know from which Zoom instance it should get results.\n\nWe’ll use [RTMPDump](https://rtmpdump.mplayerhq.hu/) to fork Zoom’s audio to Deepgram via our `stream.py` script .\n\nTo do this, run `stream_rtmp.sh`, found in our [Deepgram + Zoom repo](https://github.com/deepgram-devs/deepgram-zoom/blob/main/stream_rtmp.sh). The shell script contains the following:\n\nBash\n\n```code-block text-sm\n\n$rtmpdump -r $1/$2 --live -o - | python3 stream.py\n```\n\nHere, `rtmpdump` makes a connection to a specific stream on the specified RTMP server and directs the media content of the stream to our example streaming script ( `stream.py`) for display in your terminal. Parameters include:\n\n| Parameter | Description |\n| --- | --- |\n| −r url | URL of the server and media content. Should be in the form `rtmp[t][e]://hostname[:port][/app[/playpath]]`. In this example, this is the local IP of the RTMP server we are running. When you run the script, you will pass in the **Streaming URL** and **Streaming key** you configured in Zoom, which will replace the `$1` and `$2` variables. |\n| −-live | Specifies that the media is a live stream. You may not resume or seek in live streams. |\n| −o output | Specifies the output file name. In this case, the output is piped to our example streaming script ( `stream.py`) for live display. |\n\n#### Run the Script\n\nTo run the script, from the command line, open a new terminal window. Navigate to the location where you cloned the [Deepgram + Zoom repo](https://github.com/deepgram-devs/deepgram-zoom).\n\nThen, run the following command:\n\nBash\n\n```code-block text-sm\n\n$source stream_rtmp.sh url keyname\n```\n\nReplace `url` with the the **Streaming URL** you entered in Zoom. This will be the ngrok URL created in the previous step, plus `/live`. Remember to modify the URL to start with `rtmp://` instead of `tcp://`.\n\nReplace `keyname` with the **Streaming key** you entered in Zoom.\n\nDepending on your environment, you may need to modify the shell script to use `python` instead of `python3`.\n\n### See Results\n\nStart speaking into your microphone. After a brief delay, you should see results of the audio transcription of your livestreaming Zoom call start to appear on your screen.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F7f67ed9-image.png&w=3840&q=75)\n\nThe speed of returned results depends on both Deepgram and Zoom availability, and the setup of your hosting environment. As mentioned above, using ngrok may introduce additional latency.\n\nBy default, this script does not return interim results, only finalized transcripts. If you require the fastest possible transcripts (with the potential for less accurate transcriptions), modify line 20 in `stream.py` to add the parameter `interim_results=true`.\n\nWhen interim results are turned on, red output represents interim transcripts, while green text represents final transcripts. To learn more about interim and final transcripts, see [Interim Results](https://developers.deepgram.com/docs/interim-results).\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F3014887-image.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe0da771-image.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F3d6e5ee-image.png&w=3840&q=75)\n\n![Join Zoom with Computer Audio](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F2d38ff0-integrate-zoom_join-computer-audio.png&w=3840&q=75)\n\n![Zoom More menu](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fe9f93f4-integrate-zoom_more-livestream.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F27cd0af-image.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F7f67ed9-image.png&w=3840&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=f8w467ysw6o8)",
    "metadata": {
      "description": "Learn how to transcribe Zoom meetings using Deepgram.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogDescription": "Learn how to transcribe Zoom meetings using Deepgram.",
      "og:title": "Zoom and Deepgram | Deepgram's Docs",
      "ogTitle": "Zoom and Deepgram | Deepgram's Docs",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "Learn how to transcribe Zoom meetings using Deepgram.",
      "theme-color": "#f5f5f7",
      "title": "Zoom and Deepgram | Deepgram's Docs",
      "language": "en",
      "og:description": "Learn how to transcribe Zoom meetings using Deepgram.",
      "twitter:title": "Zoom and Deepgram | Deepgram's Docs",
      "scrapeId": "abc57562-3b72-4a5a-a0f4-890a7657da9b",
      "sourceURL": "https://developers.deepgram.com/docs/integrate-deepgram-with-zoom",
      "url": "https://developers.deepgram.com/docs/integrate-deepgram-with-zoom",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Make](https://www.make.com/en) is a visual platform for automating tasks, workflows, and apps without the need for coding.\n\n## Introduction to Make\n\nMake workflows are called scenarios. Scenarios are automated tasks that start with a trigger (an event which sets off the workflow), and then continue on with actions, the other steps of the workflow.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fcc983b5-scenario_example.png&w=3840&q=75)\n\nAn example workflow could be the following:\n\nAdd an audio file to a folder in Dropbox (Trigger) -> Create a shareable URL Link of the file in Dropbox (Action) -> Transcribe the file with Deepgram (Action) -> Add a text file with the transcription to another folder in Dropbox (Action).\n\nCurrently, Deepgram offers these actions in Make:\n\n1. Transcribe a Prerecorded Audio File From URL\n2. Summarize an Audio File\n3. Make an API Call\n\n## How to Build a Workflow in Make\n\n### Create a Scenario\n\nTo create a scenario, click on the “Scenarios” section in the left-side navigation bar and then click on “Create a Scenario”. You will be presented with an empty scenario.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F412813f-make_side_nav.png&w=1200&q=75)\n\n### Add a Trigger\n\nClick on the plus sign to add a trigger. A scenario must start with a trigger. The trigger starts off the workflow with an initial trigger event.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fb86fd4b-new_scenario.png&w=3840&q=75)\n\nPossible triggers with Deepgram actions could be:\n\n| Trigger | Action |\n| --- | --- |\n| A voicemail message is sent with Telegram or WhatsApp | Deepgram transcribes the audio message into text |\n| A new video is added to Vimeo | Deepgram summarizes the content of the video |\n| A meeting takes place in Zoom | Deepgram transcribes the meeting into a text transcript or summarizes the content |\n\nSelect your trigger. You will need to connect the integration you’ve chosen. Integrations may use OAuth to authenticate automatically, or you may have to enter an API key.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Facc839f-trigger_example.png&w=3840&q=75)\n\nOnce your trigger has been set up, you can add actions.\n\n### Add a Deepgram Action\n\nTo add a Deepgram action, click on the “Add another module” button. Type Deepgram and then select the appropriate action. This will bring up all the possible Deepgram actions\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F4b0cbdc-deepgram_actions.png&w=3840&q=75)\n\nNext you will be prompted to connect to Deepgram. Enter your API key to connect your account.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F5100ee2-connect_API.png&w=1920&q=75)\n\nAfter successfully connecting your account, you will select your configuration options in the form. The only required input is the URL; you can leave the rest blank if you do not have a specific configuration in mind. Read more about each of the form options in our [API Reference](https://developers.deepgram.com/reference/pre-recorded).\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fdb5acf0-deepgram_action_form.png&w=1920&q=75)\n\nFor the time being, Deepgram’s Make integration only accepts a URL audio file. If you need to convert raw audio to a URL, we recommend using the [Cloud Convert integration](https://www.make.com/en/integrations/cloudconvert) to convert the audio file.\n\nYou can test the workflow by clicking “Run Once”. This will run the workflow one time so you can then check the outputs of each step. Click on the bubble above the Deepgram integration to see the output of the action. By clicking into the form outputs, you can find the transcription within the “Results” section.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F6045d26-output.png&w=1920&q=75)\n\nIf you add another action after your Deepgram action, you can use the transcript in that following action.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F731e9d3-transcript.png&w=1920&q=75)\n\nChoose `Results: Channels[]` to use the transcript output in this following action.\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fcc983b5-scenario_example.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F412813f-make_side_nav.png&w=1200&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fb86fd4b-new_scenario.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Facc839f-trigger_example.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F4b0cbdc-deepgram_actions.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F5100ee2-connect_API.png&w=1920&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fdb5acf0-deepgram_action_form.png&w=1920&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F6045d26-output.png&w=1920&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F731e9d3-transcript.png&w=1920&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=db9isuiht6yq)",
    "metadata": {
      "twitter:description": "Learn how to use Deepgram in Make.com workflows.",
      "generator": "https://buildwithfern.com",
      "title": "Make.com and Deepgram | Deepgram's Docs",
      "twitter:card": "summary",
      "ogTitle": "Make.com and Deepgram | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:description": "Learn how to use Deepgram in Make.com workflows.",
      "description": "Learn how to use Deepgram in Make.com workflows.",
      "og:title": "Make.com and Deepgram | Deepgram's Docs",
      "twitter:title": "Make.com and Deepgram | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "language": "en",
      "ogDescription": "Learn how to use Deepgram in Make.com workflows.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "85d71c8b-ed0a-480b-8c00-94336aec485e",
      "sourceURL": "https://developers.deepgram.com/docs/makecom-deepgram-integration",
      "url": "https://developers.deepgram.com/docs/makecom-deepgram-integration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Integrate Twilio with Deepgram for real-time automatic speech recognition in Programmable Voice calls.\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n## Solutions\n\nTo help you integrate between Twilio and Deepgram, we provide the following solutions:\n\n- A **starter server** in either Python or Node. A conversation streamed to your Twilio number will be directed to our script, which will send the audio to Deepgram, and receive and print transcriptions to the screen. In a real implementation, you will likely want to provide a callback to which transcriptions can be sent.\n\n- A **Docker image** ( `deepgram/twilio-proxy:beta`) that fully integrates with our self-hosted products using the same robust Rust architecture that our other services use. For access to the Docker image, ask your Account Executive.\n\n\n### Starter Server\n\nThe code for the starter server can be accessed in this [GitHub repo](https://github.com/deepgram/public-code-examples).\n\nFor our starter server, we offer two scripts that can work as proxy servers to help Twilio and Deepgram share data.\n\n- `twilio-proxy-mono`: Runs the proxy server for the inbound Twilio track, which represents the audio Twilio receives from the call. To learn more about Twilio tracks, see [Twilio’s track documentation](https://www.twilio.com/docs/voice/twiml/stream#attributes-track).\n\n- `twilio-proxy-stereo`: Runs the proxy server for both the inbound and outbound Twilio tracks, which represent the audio Twilio received from the call and the audio generated by Twilio to the call. To learn more about Twilio tracks, see [Twilio’s track documentation](https://www.twilio.com/docs/voice/twiml/stream#attributes-track).\n\n\n#### Before You Begin\n\n##### Create a Deepgram Account and Get Your Deepgram API Key\n\nBefore you can use Deepgram products, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). After you’ve signed up for your free account, [create a Deepgram API Key](https://developers.deepgram.com/docs/authenticating#create-an-api-key). Make note of your API Key; you will need it later.\n\n##### Create a Twilio Account\n\nBefore you can use Twilio products, you’ll need to [create a Twilio account](https://www.twilio.com/try-twilio). In addition, if you don’t currently own a Twilio phone number with Voice functionality, you’ll need to purchase one.\n\n##### Configure Environment\n\nWe provide sample scripts in Python and Node format and assume you have already configured a Python (3.6 or greater) or Node development environment.\n\n##### Install Dependencies\n\nFor Python, we use [websockets](https://pypi.org/project/websockets/) and [pydub](https://pypi.org/project/pydub/).\n\nFor Node, we use [ws](https://github.com/websockets/ws).\n\n#### Configure the Scripts\n\nPrior to running the scripts, you must replace the authentication with your Deepgram username and password.\n\nPythonJavaScript\n\n```code-block text-sm\n\n1'Authorization': 'Token YOUR_DEEPGRAM_API_KEY'\n```\n\n#### Run the Scripts\n\nTo run the scripts:\n\n1. [Clone the GitHub repo](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository) to your local machine.\n\n2. From the command line, navigate to the cloned repository.\n\n3. Run the script using one of the following commands:\n\n\n**Mono**\n\nPythonJavaScript\n\n```code-block text-sm\n\n$python3 twilio-proxy-mono.py\n```\n\n**Stereo**\n\nPythonJavaScript\n\n```code-block text-sm\n\n1python3 twilio-proxy-stereo.py\n```\n\n#### Forward Data to Proxy\n\nFinally, you will need to forward data to the proxy scripts. You can do this by configuring Twilio to send WebSockets data to the server running the proxy scripts or by initiating a call between two people and directly forwarding the data to the proxy scripts.\n\n##### Configure Twilio to Use WebSockets\n\nSee the [Start Streaming Audio](https://www.twilio.com/docs/voice/tutorials/consume-real-time-media-stream-using-websockets-python-and-flask#start-streaming-audio) section of Twilio’s tutorial: “Consume a real-time Media Stream using WebSockets, Python, and Flask”. In this tutorial, you will use [TwiML Bins](https://www.twilio.com/docs/runtime/tutorials/twiml-bins), a serverless solution that helps you provide Twilio-hosted instructions to your Twilio applications, to begin streaming your call’s audio.\n\nWhen calling your Twilio number, the call will be forwarded to the number you set in your TwiML Bin. The conversation will then be forked to the `twilio-proxy-mono` or `twilio-proxy-stereo` app, which will send the audio to Deepgram, receive transcriptions, and print the transcriptions to the screen. In a real implementation, you will likely want to provide a callback to which transcriptions can be sent.\n\nSample TwiML Bin files are as follows:\n\n**Mono**\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>2<Response>3    <Start>4        <Stream url=\"wss://my-server-address\" />5     </Start>6     <Dial>my-phone-number</Dial>7</Response>\n```\n\n**Stereo**\n\nFor stereo, an additional `track` parameter exists.\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>2<Response>3    <Start>4        <Stream url=\"wss://my-server-address\" track=\"both_tracks\" />5     </Start>6     <Dial>my-phone-number</Dial>7</Response>\n```\n\n##### Send Call Data to Proxy Scripts\n\nAlternatively, you can initiate a call between two people and forward the call data to the Twilio-Deepgram proxy (as seen in the Twilio + Deepgram demo) using the script in [`twilio/twilio-api-scripts/stream`](https://github.com/deepgram/public-code-examples/blob/master/twilio/python/twilio-api-scripts/stream.py):\n\nPythonJavaScript\n\n```code-block text-sm\n\n1# twilio helper library2from twilio.rest import Client34# other imports5import time6import requests7import json8import os9import uuid1011# your account sid and auth token from twilio.com/console12account_sid = os.environ['TWILIO_ACCOUNT_SID']13auth_token = os.environ['TWILIO_AUTH_TOKEN']14# the twilio client15client = Client(account_sid, auth_token)16# make the outgoing call17call = client.calls.create(18  twiml = '<Response><Start><Stream url=\"wss://url.to.deepgram.twilio.proxy\" track=\"both_tracks\" /></Start><Dial>+11231231234</Dial></Response>', # replace number with person B, replace url19  to = '+11231231234', # person A20  from_ = '+11231231234' # your twilio number21)\n```\n\n- Be sure to replace `TWILIO_ACCOUNT_SID` and `TWILIO_AUTH_TOKEN` with your Twilio account information.\n- Replace the `url` variable with the URL to the Deepgram-Twilio proxy server, and the Dial number with person B’s phone number.\n- Replace the `to` and `from_` variables with person A’s phone number, and your Twilio voice number, respectively.\n\n### Docker Image\n\nWe provide the Docker image `deepgram/twilio-proxy:beta`, which you can request from your Account Executive.\n\nThis solution is for Deepgram’s self-hosted customers. Please [contact us](https://deepgram.com/contact-us) if you would like to learn more about our self-hosted solutions.\n\n#### Before You Begin\n\n##### Create a Deepgram Account\n\nBefore you can use Deepgram products, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys).\n\n##### Create a Twilio Account\n\nBefore you can use Twilio products, you’ll need to [create a Twilio account](https://www.twilio.com/try-twilio). In addition, if you don’t currently own a Twilio phone number with Voice functionality, you’ll need to purchase one.\n\n#### Run the Docker Image\n\nWe recommend running the Twilio-proxy server in a Docker container configured using a Docker Compose file. We provide the following sample Compose files to show you how to do this for a Deepgram API using either our hosted or self-hosted deployment models.\n\n##### Self-Hosted\n\nTo deploy the Twilio proxy server to a self-hosted Deepgram environment using Docker Compose, you can use the following sample Compose file.\n\nThis sample references stubbed out `api` and `engine` sections. Fill in these sections with the template in the [`deepgram-self-hosted` repository](https://github.com/deepgram/self-hosted-resources/blob/main/docker/docker-compose.standard.yml). To learn more, see the [Self-Hosted Introduction](https://developers.deepgram.com/docs/self-hosted-introduction) and other self-hosted guides, or talk to your Account Executive.\n\nThis sample references the `deepgram/actix-ws-echo:beta` Docker image, which is a WebSockets echo server. You can use it to see streaming Deepgram STT responses, or you can configure a callback URL to send Deepgram STT responses elsewhere.\n\nyaml\n\n```code-block text-sm\n\n1services:2  api:3    ...4  engine:5   ...67  proxy:8    image: deepgram/twilio-proxy:beta9    ports:10      - '8080:8080'11    environment:12      - RUST_LOG=TRACE13      - PROXY_URL=0.0.0.0:808014      - STEM_URL=ws://api:8080/v2/listen15      - CALLBACK_URL=ws://echo:8080/16    command: ''1718  echo:19    image: deepgram/actix-ws-echo:beta20    environment:21      - ECHO_URL=0.0.0.0:808022    command: ''\n\n```\n\nThe Docker Compose file references the following environment variables:\n\n| Environment Variable | Description |\n| --- | --- |\n| RUST\\_LOG (optional) | Sets the logging verbosity. Can be `TRACE`, `DEBUG`, `INFO`, `WARN`, or `ERROR`. |\n| PROXY\\_URL | Sets the URL of the `twilio-proxy` server. Should follow the format 0.0.0.0:8080. |\n| STEM\\_URL | Sets the URL of the Deepgram endpoint. |\n| CALLBACK\\_URL (optional) | URL to which Deepgram ASR results should be sent. If not specified, Deepgram ASR results are logged by the `twilio-proxy` server. |\n\n##### Hosted\n\nTo deploy the Twilio proxy server to a Deepgram-Hosted installation using Docker Compose, you can use the following sample Compose file.\n\nThis sample references the `deepgram/actix-ws-echo:beta` Docker image, which is a WebSockets echo server. You can use it to see streaming Deepgram ASR responses, or you can configure a callback URL to send Deepgram ASR responses elsewhere.\n\nyaml\n\n```code-block text-sm\n\n1version: '2.4'23services:4  proxy:5    image: deepgram/twilio-proxy:beta6    ports:7      - '8080:8080'8    environment:9      - RUST_LOG=TRACE10      - PROXY_URL=0.0.0.0:808011      - STEM_URL=wss://api.deepgram.com/v1/listen12      - STEM_BAUTH=YOUR_DEEPGRAM_API_KEY13      - CALLBACK_URL=ws://echo:8080/14      - CALLBACK_BAUTH=base64-encoded-callback-username:password15    command: ''1617  echo:18    image: deepgram/actix-ws-echo:beta19    environment:20      - ECHO_URL=0.0.0.0:808021    command: ''\n```\n\n| Environment Variable | Description |\n| --- | --- |\n| RUST\\_LOG (optional) | Sets the logging verbosity. Can be `TRACE`, `DEBUG`, `INFO`, `WARN`, or `ERROR`. |\n| PROXY\\_URL | Sets the URL of the `twilio-proxy` server. Should follow the format 0.0.0.0:8080. |\n| STEM\\_URL | Sets the URL of the Deepgram endpoint. |\n| STEM\\_BAUTH (optional) | Your Deepgram project’s API Key. This is the value stored in `key`. |\n| CALLBACK\\_URL (optional) | URL to which Deepgram ASR results should be sent. If not specified, Deepgram ASR results are logged by the `twilio-proxy` server. |\n| CALLBACK\\_BAUTH (optional) | If using a callback server to receive Deepgram ASR results, the base64-encoded value of username:password for that server. |\n\n#### Forward Data to Proxy\n\nFinally, you will need to forward data to the Twilio-Deepgram proxy. You can do this by configuring Twilio to send WebSockets data to the server running the Twilio-Deepgram proxy or by initiating a call between two people and directly forwarding the data to the Twilio-Deepgram proxy.\n\n##### Configure Twilio to Use WebSockets\n\nTo user the Docker Image, you must configure Twilio to forward data to the server serving the Rust program. To do this, see the [Start Streaming Audio](https://www.twilio.com/docs/voice/tutorials/consume-real-time-media-stream-using-websockets-python-and-flask#start-streaming-audio) section of Twilio’s tutorial: Consume a real-time Media Stream using WebSockets, Python, and Flask. In this tutorial, you will use [TwiML Bins](https://www.twilio.com/docs/runtime/tutorials/twiml-bins), a serverless solution that helps you provide Twilio-hosted instructions to your Twilio applications, to begin streaming your call’s audio.\n\nWhen calling your Twilio number, the call will be forwarded to the number you set in your TwiML Bin. The conversation will then be forked to the Twilio-Deepgram proxy app, which will send the audio to Deepgram, receive transcriptions, and print the transcriptions to the screen. In a real implementation, you will likely want to provide a callback to which transcriptions can be sent.\n\nSample TwiML Bin files are as follows:\n\n**Mono**\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>2<Response>3    <Start>4        <Stream url=\"wss://my-server-address\" />5     </Start>6     <Dial>my-phone-number</Dial>7</Response>\n```\n\n**Stereo**\n\nFor stereo, an additional `track` parameter exists.\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>2<Response>3    <Start>4        <Stream url=\"wss://my-server-address\" track=\"both_tracks\" />5     </Start>6     <Dial>my-phone-number</Dial>7</Response>\n```\n\n##### Send Call Data to Twilio-Deepgram Proxy\n\nAlternatively, you can initiate a call between two people and forward the call data to the Twilio-Deepgram proxy (as seen in the Twilio + Deepgram demo) using the script in [`twilio/twilio-api-scripts/stream.py`](https://github.com/deepgram/public-code-examples/tree/master/twilio/twilio-api-scripts):\n\nPython\n\n```code-block text-sm\n\n1# twilio helper library2from twilio.rest import Client34# other imports5import time6import requests7import json8import os9import uuid1011# your account sid and auth token from twilio.com/console12account_sid = os.environ['TWILIO_ACCOUNT_SID']13auth_token = os.environ['TWILIO_AUTH_TOKEN']14# the twilio client15client = Client(account_sid, auth_token)16# make the outgoing call17call = client.calls.create(18  twiml = '<Response><Start><Stream url=\"wss://url.to.deepgram.twilio.proxy\" track=\"both_tracks\" /></Start><Dial>+11231231234</Dial></Response>', # replace number with person B, replace url19  to = '+11231231234', # person A20  from_ = '+11231231234' # your twilio number21)\n```\n\n- Be sure to replace `TWILIO_ACCOUNT_SID` and `TWILIO_AUTH_TOKEN` with your Twilio account information.\n- Replace the `url` variable with the URL to the Deepgram-Twilio proxy server, and the Dial number with person B’s phone number.\n- Replace the `to` and `from_` variables with person A’s phone number, and your Twilio voice number, respectively.\n\n* * *\n\nWhat’s Next\n\n- [Transcribe Recorded Calls With Twilio](https://developers.deepgram.com/docs/transcribe-recorded-calls-with-twilio)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=4hdtog4zpdr)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "twitter:title": "Twilio and Deepgram STT | Deepgram's Docs",
      "og:title": "Twilio and Deepgram STT | Deepgram's Docs",
      "ogDescription": "A starter server and a self-hosted solution for integrating speech-to-text with Twilio and Deepgram.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "A starter server and a self-hosted solution for integrating speech-to-text with Twilio and Deepgram.",
      "theme-color": "#f5f5f7",
      "description": "A starter server and a self-hosted solution for integrating speech-to-text with Twilio and Deepgram.",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Twilio and Deepgram STT | Deepgram's Docs",
      "title": "Twilio and Deepgram STT | Deepgram's Docs",
      "language": "en",
      "og:description": "A starter server and a self-hosted solution for integrating speech-to-text with Twilio and Deepgram.",
      "scrapeId": "fce3111f-6bf4-42e9-883c-ff8ef7d9e515",
      "sourceURL": "https://developers.deepgram.com/docs/on-premise-twilio-integration",
      "url": "https://developers.deepgram.com/docs/on-premise-twilio-integration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Deepgram API Playground\\\\\n\\\\\nTry this feature out in our API Playground.](https://playground.deepgram.com/?endpoint=listen)\n\nThis guide will walk you through how to transcribe pre-recorded audio with the Deepgram API. We provide two scenarios to try: transcribe a remote file and transcribe a local file.\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n## CURL\n\nNext, try it with CURL. Add your own API key where it says `YOUR_DEEPGRAM_API_KEY` and then run the following examples in a terminal or your favorite API client.\n\nIf you run the “Local file CURL Example,” be sure to change `@youraudio.wav` to the path/filename of an audio file on your computer. (Read more about supported audio formats [here](https://developers.deepgram.com/docs/supported-audio-formats)).\n\n### Remote File CURL Example\n\n```code-block text-sm\n\n$curl \\>  --request POST \\>  --header 'Authorization: Token YOUR_DEEPGRAM_API_KEY' \\>  --header 'Content-Type: application/json' \\>  --data '{\"url\":\"https://dpgr.am/spacewalk.wav\"}' \\>  --url 'https://api.deepgram.com/v1/listen?model=nova-3&smart_format=true'\n```\n\n### Local File CURL Example\n\n```code-block text-sm\n\n$curl \\>  --request POST \\>  --header 'Authorization: Token YOUR_DEEPGRAM_API_KEY' \\>  --header 'Content-Type: audio/wav' \\>  --data-binary @youraudio.wav \\>  --url 'https://api.deepgram.com/v1/listen?model=nova-3&smart_format=true'\n```\n\nThe above example includes the parameter `model=nova-3`, which tells the API to use Deepgram’s most latest model. Removing this parameter will result in the API using the default model, which is currently `model=base`.\n\nIt also includes Deepgram’s [Smart Formatting](https://developers.deepgram.com/docs/smart-format) feature, `smart_format=true`. This will format currency amounts, phone numbers, email addresses, and more for enhanced transcript readability.\n\n## SDKs\n\nTo transcribe pre-recorded audio using one of Deepgram’s SDKs, follow these steps.\n\n### Install the SDK\n\nOpen your terminal, navigate to the location on your drive where you want to create your project, and install the Deepgram SDK.\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n$# Install the Deepgram JS SDK># https://github.com/deepgram/deepgram-js-sdk>>npm install @deepgram/sdk\n```\n\n### Add Dependencies\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n$# Install dotenv to protect your api key>>npm install dotenv\n```\n\n### Transcribe a Remote File\n\nThis example shows how to analyze a **remote audio file** (a URL that hosts your audio file) using Deepgram’s SDKs. In your terminal, create a new file in your project’s location, and populate it with the code.\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n1# main.py (python example)23import os4import logging5from deepgram.utils import verboselogs67from deepgram import (8    DeepgramClient,9    PrerecordedOptions,10)1112AUDIO_URL = {13    \"url\": \"https://dpgr.am/bueller.wav\"14}1516def main():17    try:18        # STEP 1 Create a Deepgram client using the DEEPGRAM_API_KEY from your environment variables19        deepgram: DeepgramClient = DeepgramClient()2021        # STEP 2 Call the transcribe_url method on the rest class22        options: PrerecordedOptions = PrerecordedOptions(23            model=\"nova-3\",24            smart_format=True,25        )26        response = deepgram.listen.rest.v(\"1\").transcribe_url(AUDIO_URL, options)27        print(f\"response: {response}\\n\\n\")2829    except Exception as e:30        print(f\"Exception: {e}\")3132if __name__ == \"__main__\":33    main()\n\n```\n\n### Transcribe a Local File\n\nThis example shows how to analyze a **local audio file** (an audio file on your computer) using Deepgram’s SDKs. In your terminal, create a new file in your project’s location, and populate it with the code. (Be sure to replace the audio filename with a path/filename of an audio file on your computer.)\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n1# main.py (python example)23import os45from deepgram import (6    DeepgramClient,7    PrerecordedOptions,8    FileSource,9)1011# Path to the audio file12AUDIO_FILE = \"spacewalk.mp3\"1314def main():15    try:16        # STEP 1 Create a Deepgram client using the API key17        deepgram = DeepgramClient()1819        with open(AUDIO_FILE, \"rb\") as file:20            buffer_data = file.read()2122        payload: FileSource = {23            \"buffer\": buffer_data,24        }2526        #STEP 2: Configure Deepgram options for audio analysis27        options = PrerecordedOptions(28            model=\"nova-3\",29            smart_format=True,30        )3132        # STEP 3: Call the transcribe_file method with the text payload and options33        response = deepgram.listen.rest.v(\"1\").transcribe_file(payload, options)3435        # STEP 4: Print the response36        print(response.to_json(indent=4))3738    except Exception as e:39        print(f\"Exception: {e}\")4041if __name__ == \"__main__\":42    main()\n\n```\n\n## Non-SDK Code Examples\n\nIf you would like to try out making a Deepgram speech-to-text request in a specific language (but not using Deepgram’s SDKs), we offer a library of code-samples in this [Github repo](https://github.com/deepgram-devs/code-samples). However, we recommend first trying out our SDKs.\n\n## Results\n\nIn order to see the results from Deepgram, you must run the application. Run your application from the terminal. Your transcripts will appear in your shell.\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n$# Run your application using the file you created in the previous step># Example: node index.js>>node YOUR_PROJECT_NAME.js\n```\n\nDeepgram does not store transcripts, so the Deepgram API response is the only opportunity to retrieve the transcript. Make sure to save output or [return transcriptions to a callback URL for custom processing](https://developers.deepgram.com/docs/callback).\n\n### Analyze the Response\n\nWhen the file is finished processing (often after only a few seconds), you’ll receive a JSON response:\n\nJSON\n\n```code-block text-sm\n\n1{2  \"metadata\": {3    \"transaction_key\": \"deprecated\",4    \"request_id\": \"2479c8c8-8185-40ac-9ac6-f0874419f793\",5    \"sha256\": \"154e291ecfa8be6ab8343560bcc109008fa7853eb5372533e8efdefc9b504c33\",6    \"created\": \"2024-02-06T19:56:16.180Z\",7    \"duration\": 25.933313,8    \"channels\": 1,9    \"models\": [10      \"30089e05-99d1-4376-b32e-c263170674af\"11    ],12    \"model_info\": {13      \"30089e05-99d1-4376-b32e-c263170674af\": {14        \"name\": \"2-general-nova\",15        \"version\": \"2024-01-09.29447\",16        \"arch\": \"nova-3\"17      }18    }19  },20  \"results\": {21    \"channels\": [22      {23        \"alternatives\": [24          {25            \"transcript\": \"Yeah. As as much as, it's worth celebrating, the first, spacewalk, with an all female team, I think many of us are looking forward to it just being normal. And, I think if it signifies anything, It is, to honor the the women who came before us who, were skilled and qualified, and didn't get the the same opportunities that we have today.\",26            \"confidence\": 0.99902344,27            \"words\": [28              {29                \"word\": \"yeah\",30                \"start\": 0.08,31                \"end\": 0.32,32                \"confidence\": 0.9975586,33                \"punctuated_word\": \"Yeah.\"34              },35              {36                \"word\": \"as\",37                \"start\": 0.32,38                \"end\": 0.79999995,39                \"confidence\": 0.9921875,40                \"punctuated_word\": \"As\"41              },42              {43                \"word\": \"as\",44                \"start\": 0.79999995,45                \"end\": 1.04,46                \"confidence\": 0.96777344,47                \"punctuated_word\": \"as\"48              },49              {50                \"word\": \"much\",51                \"start\": 1.04,52                \"end\": 1.28,53                \"confidence\": 1,54                \"punctuated_word\": \"much\"55              },56              {57                \"word\": \"as\",58                \"start\": 1.28,59                \"end\": 1.5999999,60                \"confidence\": 0.9926758,61                \"punctuated_word\": \"as,\"62              },63              {64                \"word\": \"it's\",65                \"start\": 2,66                \"end\": 2.24,\\\n\\\n```\\\n\\\nIn this default response, we see:\\\n\\\n- `transcript`: the transcript for the audio segment being processed.\\\n\\\n- `confidence`: a floating point value between 0 and 1 that indicates overall transcript reliability. Larger values indicate higher confidence.\\\n\\\n- `words`: an object containing each `word` in the transcript, along with its `start` time and `end` time (in seconds) from the beginning of the audio stream, and a `confidence` value.\\\n\\\nBecause we passed the `smart_format: true` option to the `transcription.prerecorded` method, each word object also includes its `punctuated_word` value, which contains the transformed word after punctuation and capitalization are applied.\\\n\\\n\\\nThe `transaction_key` in the `metadata` field can be ignored. The result will always be `\"transaction_key\": \"deprecated\"`.\\\n\\\n## Limits\\\n\\\nThere are a few limits to be aware of when making a pre-recorded speech-to-text request.\\\n\\\n### File Size\\\n\\\n- The maximum file size is limited to 2 GB.\\\n- For large video files, extract the audio stream and upload only the audio to Deepgram. This reduces the file size significantly.\\\n\\\n### Rate Limits\\\n\\\n**Nova, Base, and Enhanced Models:**\\\n\\\n- Maximum of 100 concurrent requests per project.\\\n- For information on Deepgram’s Concurrency Rate Limits, refer to our [API Rate Limits Documentation](https://developers.deepgram.com/reference/api-rate-limits).\\\n\\\n**Whisper Model:**\\\n\\\n- Paid plan: 15 concurrent requests.\\\n- Pay-as-you-go plan: 5 concurrent requests.\\\n\\\nExceeding these limits will result in a 429: Too Many Requests error.\\\n\\\n### Maximum Processing Time\\\n\\\n**Fast Transcription Models (Nova, Base, and Enhanced)**\\\n\\\n- These models offer extremely fast transcription.\\\n- Maximum processing time: 10 minutes.\\\n\\\n**Slower Transcription Model (Whisper)**\\\n\\\n- Whisper transcribes more slowly compared to other models.\\\n- Maximum processing time: 20 minutes.\\\n\\\n**Timeout Policy**\\\n\\\n- If a request exceeds the maximum processing time, it will be canceled.\\\n- In such cases, a 504: Gateway Timeout error will be returned.\\\n\\\n## What’s Next?\\\n\\\nNow that you’ve transcribed pre-recorded audio, enhance your knowledge by exploring the following areas.\\\n\\\n### Read the Feature Guides\\\n\\\nDeepgram’s features help you to customize your transcripts.\\\n\\\n- [Language](https://developers.deepgram.com/docs/language): Learn how to transcribe audio in other languages.\\\n- [Profanity Filtering](https://developers.deepgram.com/docs/language) and [Redaction](https://developers.deepgram.com/docs/redaction): Discover how to remove profanity or redact personal information like credit card numbers.\\\n- [Feature Overview](https://developers.deepgram.com/docs/stt-pre-recorded-feature-overview): Review the list of features available for pre-recorded speech-to-text. Then, dive into individual guides for more details.\\\n\\\n### Explore Use Cases\\\n\\\n- Learn about the different ways you can use Deepgram products to help you meet your business objectives. [Explore Deepgram’s use cases](https://developers.deepgram.com/use-cases).\\\n\\\n### Transcribe Streaming Audio\\\n\\\n- Now that you know how to transcribe pre-recorded audio, check out how you can use Deepgram to transcribe streaming audio in real time. To learn more, see [Getting Started with Streaming Audio](https://developers.deepgram.com/docs/getting-started-with-live-streaming-audio).\\\n\\\n* * *",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogDescription": "An introduction to getting transcription data from pre-recorded audio files.",
      "generator": "https://buildwithfern.com",
      "og:description": "An introduction to getting transcription data from pre-recorded audio files.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "description": "An introduction to getting transcription data from pre-recorded audio files.",
      "twitter:description": "An introduction to getting transcription data from pre-recorded audio files.",
      "ogTitle": "Getting Started | Deepgram's Docs",
      "title": "Getting Started | Deepgram's Docs",
      "twitter:card": "summary",
      "og:title": "Getting Started | Deepgram's Docs",
      "language": "en",
      "twitter:title": "Getting Started | Deepgram's Docs",
      "scrapeId": "da46f8a6-cc4a-4830-bb76-d05bff4f27e9",
      "sourceURL": "https://developers.deepgram.com/docs/pre-recorded-audio",
      "url": "https://developers.deepgram.com/docs/pre-recorded-audio",
      "statusCode": 200,
      "proxyUsed": "basic"
    },
    "warning": "This scrape job was throttled at your current concurrency limit. If you'd like to scrape faster, you can upgrade your plan."
  },
  {
    "markdown": "# Common audio formats\n\nDeepgram can handle nearly all audio formats and encodings available (over 100 + ). Some of the most common audio formats and encodings we support include:\n\n- MP3\n- MP4\n- MP2\n- AAC\n- WAV\n- FLAC\n- PCM\n- M4A\n- Ogg\n- Opus\n- WebM\n\n# Using other audio formats\n\nWe recommend testing small sets of audio when first operating with new audio sources to ensure compatibility.\n\nBecause audio format is largely unconstrained, we always recommend to ensure compatibility by testing small sets of audio when first operating with new audio sources.\n\n# Audio format best practices\n\nGenerally you don’t have to specify the audio format in your API request but if you know the format of your audio, providing it in you API request can help reduce unnecessary computation.\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=shv2hxpfy9yk)",
    "metadata": {
      "description": "Learn about audio formats and encoding supported by Deepgram.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogDescription": "Learn about audio formats and encoding supported by Deepgram.",
      "twitter:description": "Learn about audio formats and encoding supported by Deepgram.",
      "twitter:title": "Supported Audio Formats | Deepgram's Docs",
      "twitter:card": "summary",
      "ogTitle": "Supported Audio Formats | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "og:title": "Supported Audio Formats | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:description": "Learn about audio formats and encoding supported by Deepgram.",
      "title": "Supported Audio Formats | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "theme-color": "#f5f5f7",
      "scrapeId": "d4b50355-799c-4cb3-9e53-b678d4fb802b",
      "sourceURL": "https://developers.deepgram.com/docs/supported-audio-formats",
      "url": "https://developers.deepgram.com/docs/supported-audio-formats",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "In the rapidly advancing field of AI, model improvement partnerships are crucial for the frequent development and continuous improvement of increasingly powerful models that drive intelligent systems. The Deepgram Model Improvement Partnership Program provides transparency and definition for how customer data is handled, stored, and utilized by Deepgram, as well as specifies the many benefits participants enjoy. Chief among these is the opportunity for our customers to shape the future of voice AI. These customers gain early and regular access to more accurate models that perform well for their specific use cases through inclusion of relevant real-world data during the model training process.\n\nAt Deepgram, we take our customers’ data privacy concerns seriously, which is why we have implemented robust data security policies and flexible data retention options that allow our customers to strike the right balance for their individual needs.\n\n# How do we improve our models?\n\nDeepgram utilizes end-to-end deep learning to develop all of our voice AI models. These models are built through an iterative process that learns the inherent relationships in the conversational audio data used for training. This involves hundreds of thousands of hours of conversational data broadly spanning a given language’s vocabulary, as well as inclusion of a wide variety of speaker groups across a large number of dimensions including age, sex, accents, background noise, acoustic environments, etc.\n\nOur in-house DataOps team employs state-of-the-art techniques to curate high quality training data sets and ensure proper balance across the dimensions listed above. Both overrepresentation and underrepresentation of different sample types can have adverse effects on model accuracy. By incorporating some of the data we collect through the Deepgram Model Improvement Partnership Program during training, we are able to produce high quality, in-distribution training data sets that lead to robust model performance both generally and for the specific use cases of interest for our customers.\n\nFor speech-to-text, this results in more accurate models that work better for you and everyone speaking your language through improved recognition of the complex and nuanced aspects of real-world speech (e.g. accents, regional dialects, jargon, slang phrases, differences in sentence structure across different languages, etc.). For text-to-speech, this results in more natural models that better portray your brand through improved pronunciation, expressiveness, and emotion in everyday interactions.\n\nAfter training, a deep learning model for voice AI is essentially a giant mathematical equation that approximates all of the inherent relationships and underlying concepts that comprise human speech (e.g. “‘I’ before ‘E’ except after ‘C’ or when sounded as ‘A’ as in ‘neighbor’ or ‘weigh’”). And the magic of deep learning is that it does this by learning these concepts implicitly from the training data itself instead of being explicitly programmed by humans to do so. Importantly, the model has no rote memory or storage for any of the data used to train it, meaning there is no risk of any data leakage when the model is used in production.\n\n# How do we handle your data and ensure security and privacy?\n\nDeepgram stores fractional increments of data for the continued improvement of our voice AI models and to provide enhanced customer support when needed. The only data we will store and use in future model training is the data that is contractually included through participation in the Deepgram Model Improvement Partnership Program. We will never redistribute data to 3rd parties without our customers’ permission. Your data will never be used to market our services or to create advertising profiles.\n\nDeepgram’s infrastructure, policies, and procedures are designed to meet industry-standard compliance and regulatory frameworks, including SOC-2 Type 2, HIPAA, PCI DSS, GDPR, CCPA, and all applicable local government and legal requirements. MFA, RBAC, and VPNs are used to regulate and secure all employee access to data systems. All data is encrypted in-flight and at-rest with industry-standard encryption, including TLS 1.3 and AES-256.\n\n# Why Participate?\n\nParticipation in this program is voluntary and includes a number of valuable benefits.\n\n- Increased accuracy of our voice AI models for your domain and use case with more frequent, higher impact releases of next-gen models that continue to get better and better.\n- Discounted pricing for program participants that yields significant savings.\n- Better technical support with faster root cause analysis and time to resolution.\n- Preferential placement on early access wait lists for future voice AI models, features, and functionality.\n- Accelerated custom model training timelines for individual customers in need of additional accuracy.\n- Reduced model drift. Language is fluid and constantly changing, with new jargon and slang popping up in daily conversation over time. Our model improvement partnership program ensures our models will evolve along with your customers’ speech patterns.\n- Support for Responsible AI by mitigating model bias and ensuring sufficient representation of underrepresented speaker groups based on age, sex, accents, etc. in our training data sets.\n\n# Need more help?\n\nHave additional questions? [Get in touch](https://deepgram.com/contact-us).\n\n# Want to opt out?\n\nAdd `mip_opt_out=true` as a query parameter of all API requests that you want to be excluded from the Model Improvement Program. By opting out of the Model Improvement Program, customers on Pay as you Go, Growth, or Enterprise plans will forego their 50% discount on the rates listed in your signed contract or on [deepgram.com/pricing](https://deepgram.com/pricing). Data from opted-out requests is retained only for the duration necessary to process the request.\n\n## Speech-to-Text Examples\n\nHere are some examples of opting out for Speech-to-Text requests.\n\nThe SDK examples below use a custom add on parameter. To learn more about using custom add on parameters with our SDKs refer to [the Documentation on using custom add on Parameters](https://developers.deepgram.com/docs/using-custom-parameters-sdks).\n\ncURLJavaScriptPythonGoC#\n\n```code-block text-sm\n\n1#  Install the SDK: pip install deepgram-sdk23import asyncio4import os5from dotenv import load_dotenv67from deepgram import DeepgramClient, PrerecordedOptions89load_dotenv()1011API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")12AUDIO_URL = {13    \"url\": \"https://static.deepgram.com/examples/Bueller-Life-moves-pretty-fast.wav\"14}1516options: PrerecordedOptions = PrerecordedOptions(17    model=\"nova-3\",18)1920# To demonstrate using the custom addon parameters, you could enable it like this21custom_options: dict = {\"mip_opt_out\": \"true\"}2223deepgram: DeepgramClient = DeepgramClient(API_KEY)2425async def transcribe_url():26    url_response = await deepgram.listen.asyncprerecorded.v(\"1\").transcribe_url(27        AUDIO_URL, options, addons=custom_options28    )29    return url_response3031async def main():32    try:33        response = await transcribe_url()34        print(response.to_json(indent=4))35    except Exception as e:36        print(f\"Exception: {e}\")3738if __name__ == \"__main__\":39    asyncio.run(main())\n\n```\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n## Voice Agent Example\n\nHere is an example of opting out for Voice Agent requests using the `Settings` message.\n\njson\n\n```code-block text-sm\n\n${>  \"type\": \"Settings\",>  \"mip_opt_out\": true,>  \"audio\": {>    \"input\": {>      \"encoding\": \"linear16\",>      \"sample_rate\": 24000>    },>    \"output\": {>      \"encoding\": \"linear16\",>      \"sample_rate\": 24000,>      \"container\": \"none\">    }>  },>  \"agent\": {>    \"language\": \"en\",>    \"listen\": {>      \"provider\": {>        \"type\": \"deepgram\",>        \"model\": \"nova-3\">      }>    },>    \"think\": {>      \"provider\": {>        \"type\": \"open_ai\",>        \"model\": \"gpt-4o-mini\",>        \"temperature\": 0.7>      }>    },>    \"speak\": {>      \"provider\": {>        \"type\": \"deepgram\",>        \"model\": \"aura-2-thalia-en\">      }>    }>  }>}\n\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=7q5ychv8z1v6)",
    "metadata": {
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Model Improvement Partnership Program | Deepgram's Docs",
      "ogDescription": "Learn about how Deepgram trains our AI models and how you can opt out of our Model Improvement Program.",
      "ogTitle": "Model Improvement Partnership Program | Deepgram's Docs",
      "description": "Learn about how Deepgram trains our AI models and how you can opt out of our Model Improvement Program.",
      "twitter:description": "Learn about how Deepgram trains our AI models and how you can opt out of our Model Improvement Program.",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "og:description": "Learn about how Deepgram trains our AI models and how you can opt out of our Model Improvement Program.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:title": "Model Improvement Partnership Program | Deepgram's Docs",
      "title": "Model Improvement Partnership Program | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "scrapeId": "2d77ccf0-1e36-4813-812c-c5456101ee45",
      "sourceURL": "https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program",
      "url": "https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Real-time meeting transcription uses advanced voice technology for speech-to-text capture of what is discussed and decided in a meeting. With Deepgram’s API, you can add captions to live videos or display captions in real-time at conferences and events, and analyze spoken words for live content.\n\nThe demo code in this guide uses an older version of our Node SDK. A new version of our SDK is now available. [A migration guide is available](https://developers.deepgram.com/docs/js-sdk-v2-to-v3-migration-guide).\n\n## Before You Begin\n\nYou will learn how to use Deepgram’s API and streaming endpoint to transcribe voice to text in real-time in a small video chat. The example provided is written in Node.js, and you can [find the code on GitHub](https://github.com/deepgram-devs/video-chat).\n\nBefore you run the code, you’ll need to do a few things:\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\n### Create a Deepgram API Key\n\nTo access Deepgram’s API, you’ll need to [create a Deepgram API Key](https://developers.deepgram.com/documentation/getting-started/authentication#create-an-api-key). Make note of your API Key; you will need it later.\n\n## Getting started\n\nYou can run this application on your local computer.\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run successfully. Edit the environment variables ( `.env`) to reflect the settings you want to use:\n\n- `PORT`: The port on which you want to run the application. We generally set this to port 3000.\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n\nOnce these variables are set, the application should run automatically.\n\n### Run on localhost\n\nTo run this project on your local computer you will need to clone the repository, configure the settings, install the dependencies, and start the server.\n\n#### Clone the Repository\n\nEither clone or download the [GitHub repository](https://github.com/deepgram-devs/video-chat) to your local machine in a new directory:\n\nBash\n\n```code-block text-sm\n\n$# Clone this repo>git clone https://github.com/deepgram-devs/video-chat.git>># Move to the created directory>cd video-chat\n```\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run. Copy the `.env-example` file into a new file named `.env`, and edit the new file to reflect the settings you want to use:\n\n- `PORT`: The port on which you want to run the application. You can leave this as port 3000.\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n\n#### Install the Dependencies\n\nIn the directory where you downloaded the code, run the following command to bring in the dependencies needed for this project:\n\nBash\n\n```code-block text-sm\n\n$npm install\n```\n\n#### Start the Server\n\nNow that you have configured your application and put the dependencies in place, your application is ready to go! Run it with:\n\nBash\n\n```code-block text-sm\n\n$npm start\n```\n\nBy default, the application runs on port 3000, which means you can access it at `<http://localhost:3000>`.\n\n## Code Walk-through\n\nThe application is an Express app that uses `public/js/video_chat.js` to build a two-way video call using classic WebRTC technology. It uses an intermediate server ( `server.js`) to establish a peer-to-peer connection between itself and another client.\n\nYour browser records your microphone using the [opus-recorder library](https://github.com/chris-rudmin/opus-recorder), then sends the audio stream to the server. In turn, the server forwards the audio stream to Deepgram’s API, using your Deepgram API Key to authenticate with the [real-time streaming endpoint](https://developers.deepgram.com/api-reference/transcription#transcribe-live-streaming-audio).\n\nWhen the server receives the transcription back from the Deepgram API, it displays the transcription data in the browser. The key logic that connects to Deepgram and forwards any transcriptions it receives to the client application lives in the `server.js` file.\n\nYou could directly connect the browser to Deepgram API, but this would require you to disclose your Deepgram API Key to the browser. This is very insecure and we don’t recommend this.\n\n## Negotiating the Peer Connection\n\nTo negotiate the peer connection, we call the `createAndSetupPeerConnection` function in `public/js/video_chat.js`. This function works with the `setupWebRTCSignaling` function in `server.js` to set up the peer connection using WebRTC, which is a fully peer-to-peer technology for the real-time exchange of audio, video, and data.\n\n## Learn More About WebRTC\n\nWhen using WebRTC, for two devices on different networks to locate each other, a form of discovery and media format negotiation must take place. This process is called signaling and involves both devices connecting to a third, mutually agreed-upon server. Through this third signaling server, the two devices can locate one another and exchange negotiation messages to resolve how to connect them over the internet.\n\nTo negotiate the connection between them, the peers need to exchange Interactive Connectivity Establishment (ICE) candidates, each of which describes a method that the sending peer is able to use to communicate. Each peer sends candidates in the order they’re discovered and keeps sending candidates until it runs out of suggestions, even if media has already started streaming.\n\nThe content of the message going through the signaling server is, in effect, a black box. What matters is that when the ICE subsystem instructs you to send signaling data to the other peer, you do so, and that the other peer knows how to receive this information and deliver it to its own ICE subsystem. All you have to do is channel the information back and forth.\n\njavascript\n\n```code-block text-sm\n\n1function createAndSetupPeerConnection(peerSocketId, localStream, remoteVideoNode, socket, allPeerConnections) {2\t// Create an RTC peer connection and add the connection to `allPeer Connections`.3\tconst peerConnection = new RTCPeerConnection({4\t\ticeServers: [5\t\t\t{6\t\t\t\turls: [\"stun:stun.l.google.com:19302\"],7\t\t\t},8\t\t],9\t});10\tallPeerConnections.set(peerSocketId, peerConnection);1112\t// Add the local stream as outgoing tracks to the peer connection so the13\t// local stream can be sent to the peer.14\tlocalStream.getTracks().forEach((track) => peerConnection.addTrack(track, localStream));1516\t// Forward ICE candidates to the peer through the socket. This is required17\t// by the RTC protocol to make both clients agree on what video/audio18\t// format and quality to use.19\tpeerConnection.onicecandidate = (event) => {20\t\tif (event.candidate) {21\t\t\tsocket.emit(\"ice-candidate\", peerSocketId, event.candidate);22\t\t}23\t};2425\t// Bind the incoming tracks to remoteVideoNode.srcObject, so we26\t// can see the peer's stream.27\tpeerConnection.ontrack = (event) => {28\t\tremoteVideoNode.srcObject = event.streams[0];29\t};3031\treturn peerConnection;32}\n\n```\n\njavascript\n\n```code-block text-sm\n\n1function setupWebRTCSignaling(socket) {2\t// Handle the WebRTC \"signaling\", which means forwarding the necessary data3\t// to establish a peer-to-peer connection.4\tsocket.on(\"video-offer\", (id, message) => {5\t\tsocket.to(id).emit(\"video-offer\", socket.id, message);6\t});78\tsocket.on(\"video-answer\", (id, message) => {9\t\tsocket.to(id).emit(\"video-answer\", socket.id, message);10\t});1112\tsocket.on(\"ice-candidate\", (id, message) => {13\t\tsocket.to(id).emit(\"ice-candidate\", socket.id, message);14\t});15}\n```\n\n### Sending Data to the Deepgram API\n\nWhen your browser sends the audio stream to the server, we call the `setupRealtimeTranscription` function. This function calls the Deepgram API via a `wss` request, which establishes a WebSocket over an encrypted TLS connection. Real-time streaming uses WebSockets, a communications protocol that enables full-duplex communication, which means that you can stream new audio to Deepgram at the same time the latest transcription results are streaming back to you.\n\nWhen connecting to the Deepgram server, you can configure options by appending query string parameters to the URL. To learn more about available options, check out our docs on the [Deepgram Live API](https://developers.deepgram.com/reference/listen-live).\n\njavascript\n\n```code-block text-sm\n\n1const { Deepgram } = require(\"@deepgram/sdk\");2function setupRealtimeTranscription(socket, room) {3\t/** The sampleRate must match what the client uses. */4\tconst sampleRate = 16000;56\tconst deepgram = new Deepgram(DG_KEY);78\tconst dgSocket = deepgram.transcription.live({9\t\tpunctuate: true,10\t});1112\t/** We must receive the very first audio packet from the client because13\t * it contains some header data needed for audio decoding.14\t *15\t * Thus, we send a message to the client when the socket to Deepgram is ready,16\t * so the client knows it can start sending audio data.17\t */18\tdgSocket.addListener(\"open\", () => socket.emit(\"can-open-mic\"));1920\t/**21\t * We forward the audio stream from the client's microphone to Deepgram's server.22\t */23\tsocket.on(\"microphone-stream\", (stream) => {24\t\tif (dgSocket.getReadyState() === WebSocket.OPEN) {25\t\t\tdgSocket.send(stream);26\t\t}27\t});2829\t/** On Deepgram's server message, we forward the response back to all the30\t * clients in the room.31\t */32\tdgSocket.addListener(\"message\", (transcription) => {33\t\tio.to(room).emit(\"transcript-result\", socket.id, transcription);34\t});3536\t/** We close the dsSocket when the client disconnects. */37\tsocket.on(\"disconnect\", () => {38\t\tif (dgSocket.getReadyState() === WebSocket.OPEN) {39\t\t\tdgSocket.finish();40\t\t}41\t});42}\n\n```\n\n## Analyzing Results\n\nWhen analyzing results, understand that real-time streaming returns a series of interim transcripts followed by a final transcript. To learn more about real-time streaming, see [Getting Started with Streaming Audio](https://developers.deepgram.com/documentation/getting-started/streaming). To learn more about interim and final transcripts, see [Interim Results](https://developers.deepgram.com/documentation/features/interim-results).\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=dvtohqvja23i)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "application-name": "Deepgram's Docs",
      "og:description": "With Deepgram’s API, you can add captions to live videos or display captions in real-time at conferences and events, and analyze spoken words for live content.",
      "title": "Transcribe Meetings in Realtime | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "Transcribe Meetings in Realtime | Deepgram's Docs",
      "og:title": "Transcribe Meetings in Realtime | Deepgram's Docs",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "description": "With Deepgram’s API, you can add captions to live videos or display captions in real-time at conferences and events, and analyze spoken words for live content.",
      "twitter:title": "Transcribe Meetings in Realtime | Deepgram's Docs",
      "twitter:description": "With Deepgram’s API, you can add captions to live videos or display captions in real-time at conferences and events, and analyze spoken words for live content.",
      "ogDescription": "With Deepgram’s API, you can add captions to live videos or display captions in real-time at conferences and events, and analyze spoken words for live content.",
      "scrapeId": "3dc97851-1d8b-4c4b-b806-b05b1c6a2e50",
      "sourceURL": "https://developers.deepgram.com/docs/transcribe-meetings-in-realtime",
      "url": "https://developers.deepgram.com/docs/transcribe-meetings-in-realtime",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "The wealth of knowledge in the conversations that happen during your sales and support calls can be left untapped without automatic transcription. Using Deepgram’s Transcription API, you can gather the data you need to make informed decisions about your organization’s interactions.\n\nThe demo code in this guide uses an older version of our Node SDK. A new version of our SDK is now available. [A migration guide is available](https://developers.deepgram.com/docs/js-sdk-v2-to-v3-migration-guide).\n\n## Before You Begin\n\nThe example provided is written in Node.js, and you can find the code on [GitHub](https://github.com/deepgram-devs/video-chat).\n\nBefore you run the code, you’ll need to do a few things:\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\n### Create a Deepgram API Key\n\nTo access Deepgram’s API, you’ll need to [create a Deepgram API Key](https://console.deepgram.com/signup?jump=keys). Make note of your API Key; you will need it later.\n\n### Gather Twilio Credentials\n\nThis application uses Twilio Voice to start a phone call that will be recorded and transcribed. Before you can use Twilio products, you’ll need to [sign up for a Twilio account](https://twilio.com/).\n\nTo use the sample application, you’ll need a Twilio Account SID and Twilio Auth Token. These can both be found within your Twilio account dashboard.\n\n## Getting Started\n\nYou can run this application on your local computer.\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run successfully. Edit the environment variables ( `.env`) to reflect the settings you want to use:\n\n- `YOUR_TWILIO_ACCOUNT_SID`: The Account SID from your Twilio Account Dashboard.\n- `YOUR_TWILIO_AUTH_TOKEN`: The Auth Token from your Twilio Account Dashboard.\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n\nOnce these variables are set, the application should run automatically.\n\n### Run on localhost\n\nTo run this project on your local computer you will need to clone the repository, configure the settings, install the dependencies, and start the server.\n\n#### Clone the Repository\n\nEither clone or download the [GitHub repository](https://github.com/deepgram-devs/recorded-call-transcription) to your local machine in a new directory:\n\nBash\n\n```code-block text-sm\n\n$# Clone this repo>git clone https://github.com/deepgram-devs/recorded-call-transcription.git>># Move to the created directory>cd recorded-call-transcription\n```\n\n#### Configure the Settings\n\nYour application will need to know more about you before it can run. Copy the `.env-example` file into a new file named `.env`, and edit the new file to reflect the settings you want to use:\n\n- `DG_KEY`: The API Key you created earlier in this tutorial.\n- `YOUR_TWILIO_ACCOUNT_SID`: The Account SID from your Twilio Account Dashboard.\n- `YOUR_TWILIO_AUTH_TOKEN`: The Auth Token from your Twilio Account Dashboard.\n\n#### Create a Virtual Environment (optional)\n\nCreate a virtual Python environment to run the server in isolation and prevent version collisions with other projects. (You can skip this part if you don’t mind installing things system-wide.)\n\nBash\n\n```code-block text-sm\n\n$# Create the virtual environment># (Must be run only once.)>python3 -m venv dg-twilio-ve>># Activate the virtual environment># (Must be run every time you open a new terminal.)>source dg-twilio-ve/bin/activate># Your prompt should start with `(dg-twilio-ve)`.>># python3 and pip3 will now run in this virtual environment.># If you want to deactivate this environment, type `deactivate`.\n```\n\n#### Install the Dependencies\n\nIn the directory where you downloaded the code, run the following command to bring in the dependencies needed for this project:\n\nBash\n\n```code-block text-sm\n\n$pip3 install -r requirements.txt\n```\n\n#### Start the Server\n\nNow that you have configured your application and put the dependencies in place, your application is ready to go! Run it with:\n\nBash\n\n```code-block text-sm\n\n$FLASK_APP=server.py FLASK_ENV=development flask run\n```\n\n## Code Walk-through\n\nThe application uses Flask to serve a website that generates a phone call to a phone number you provide. Once the call has concluded, a recording is sent to the Deepgram API for transcription. Once the transcription has been returned, the website displays the results.\n\n### Sending Recordings to the Deepgram API\n\nWhen a call ends, the application calls the `/transcribe/` endpoint, passing a URL that was provided by Twilio to the call’s recording. The server then sends that URL to Deepgram to transcribe. Once the transcription is complete, the application returns it to the front-end as a JSON object.\n\nPython\n\n```code-block text-sm\n\n1@app.route('/transcribe/', methods=['POST'])2def transcribe() -> dict:3    body = json.loads(request.data)4    print(\"got request in transcribe:\", body)5    print('sending recording to deepgram')6    # Submit the recording to Deepgram7    deepgram_req = requests.post(8        'https://api.deepgram.com/v1/listen?punctuate=true',9        headers={'Authorization': 'token ' + DEEPGRAM_API_KEY,10                 \"content-type\": \"application/json\"},11        json={\"url\": body[\"audio_url\"]}12    )13    print('done processing request, sending deepgram response back to client',14          deepgram_req.text)15    return json.loads(deepgram_req.text)\n```\n\n* * *\n\nWhat’s Next\n\n- [Twilio and Deepgram](https://developers.deepgram.com/docs/on-premise-twilio-integration)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=too7z2j4rwrs)",
    "metadata": {
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogDescription": "With Twilio and Deepgram you can record and transcribe your phone calls.",
      "theme-color": "#f5f5f7",
      "twitter:card": "summary",
      "twitter:title": "Transcribe Recorded Calls With Twilio | Deepgram's Docs",
      "title": "Transcribe Recorded Calls With Twilio | Deepgram's Docs",
      "og:title": "Transcribe Recorded Calls With Twilio | Deepgram's Docs",
      "ogTitle": "Transcribe Recorded Calls With Twilio | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "description": "With Twilio and Deepgram you can record and transcribe your phone calls.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:description": "With Twilio and Deepgram you can record and transcribe your phone calls.",
      "twitter:description": "With Twilio and Deepgram you can record and transcribe your phone calls.",
      "scrapeId": "0d3270da-254f-41b4-830c-f1219e25201c",
      "sourceURL": "https://developers.deepgram.com/docs/transcribe-recorded-calls-with-twilio",
      "url": "https://developers.deepgram.com/docs/transcribe-recorded-calls-with-twilio",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Streaming audio from Deepgram Aura Text-to-Speech (TTS) into an ongoing Twilio phone call requires the use of the [Twilio streaming API.](https://www.twilio.com/docs/voice/twiml/stream)\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n## Prerequisites\n\nFor the complete code used in this guide, please [check out this repository](https://github.com/deepgram-devs/deepgram-twilio-streaming-python/tree/nikolawhallon-tts).\n\nYou will need:\n\n- A [free Twilio account](https://www.twilio.com/try-twilio) with a Twilio phone number.\n- [ngrok](https://ngrok.com/) to let Twilio access a local server OR your own hosted server.\n- Understanding of Python and using Python virtual environments.\n\n## TwiML Bin Setup\n\nFirst, you will need to set up a `TwiML Bin`. You can refer to the docs on how to do that in the [Twilio Console](https://www.twilio.com/docs/serverless/twiml-bins).\n\nDeepgram Aura TTS is not available via the [Twilio `<Say>` verb](https://www.twilio.com/docs/voice/twiml/say). Instead you will use a URL.\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>23<Response>4    <Say language=\"en\">\"This call may be monitored or recorded.\"</Say>5    <Connect>6        <Stream url=\"wss://a127-75-172-116-97.ngrok-free.app/twilio\" />7    </Connect>8</Response>\n```\n\nYou should replace the url with wherever you decide to deploy the server we are about to create and ensure `/twilio` is at the end of the url.\n\nIn the `TwiML Bin` example above, ngrok is used to expose the server running locally.\n\n### Using ngrok\n\nngrok is recommended for quick development and testing but shouldn’t be used for production instances.\n\nTo use ngrok see their [documentation](https://ngrok.com/docs/getting-started/).\n\nBe sure to set the port correctly to align with the server code provided by running this command when you start the ngrok server.\n\n```code-block text-sm\n\nngrok http 5000\n```\n\nIf you restart your ngrok server, your URL will change, which will require you to update your `TwiML Bin`\n\n### Connecting a Twilio phone number\n\nYour `TwiML Bin` must then be connected to one of your Twilio phone numbers so that it gets executed whenever someone calls that number. If you need to set up a phone number and connect it to your `TwiML Bin`, refer to the [Twilio Docs](https://www.twilio.com/docs/serverless/twiml-bins/getting-started#wire-your-twiml-bin-up-to-an-incoming-phone-call).\n\nIn your `TwiML Bin` The `<Connect>` verb is required for bi-directional communication, i.e. in order to send audio from Aura TSS to Twilio, you must use this verb.\n\n## Building the Server\n\nCopy the `twilio.py` code from the [repository](https://github.com/deepgram-devs/deepgram-twilio-streaming-python/blob/nikolawhallon-tts/twilio.py) as we will use this in the steps below and save this code locally as with a file name of `twilio.py`.\n\nAt this point you’ll want to start up a virtual environment for Python. Please refer to documentation for how to do that based on your personal Python preferences.\n\nDepending on your situation you may also need to install specific packages used in this code.\n\nPython\n\n```code-block text-sm\n\n1pip install package_name\n```\n\nIf your `TwiML Bin` is setup correctly, you can now navigate to this files location in your terminal and run the server with the following command:\n\nShell\n\n```code-block text-sm\n\n$python twilio.py\n```\n\nOR\n\nShell\n\n```code-block text-sm\n\n$python3 twilio.py\n```\n\nYou can then start making calls to the phone number your `TwiML Bin` is using. Without any further modifications, you should hear Deepgram Aura say simply: “Hello, how are you today?”\n\n## Code Tour\n\nLet’s dive into the code used in the [twilio.py](https://github.com/deepgram-devs/deepgram-twilio-streaming-python/blob/nikolawhallon-tts/twilio.py) file.\n\nFirst, we have some import statements:\n\nPython\n\n```code-block text-sm\n\n1import asyncio2import base643import json4import sys5import websockets6import ssl7import requests\n```\n\n- We are using `asyncio` and `websockets` to build an asynchronous websocket server.\n- We will use `base64` to handle encoding audio from Aura to pass data to Twilio.\n- We will use `json` to deal with parsing text messages from Twilio .\n- We will use `requests` to make HTTP requests to Deepgram’s Aura/TTS endpoint.\n\nNext we have:\n\nPython\n\n```code-block text-sm\n\n1async def twilio_handler(twilio_ws):2    streamsid_queue = asyncio.Queue()\n```\n\n- We will be spinning up asynchronous tasks for receiving messages from, and sending messages to, Twilio.\n- We will use this `streamsid_queue` to pass the stream `sid` from the `twilio_receiver` task to the `twilio_sender` task.\n- We need to specify this stream `sid` to ensure that audio from Deepgram Aura is routed correctly to the corresponding phone call.\n\nThe `twilio_receiver` task is defined next:\n\nPython\n\n```code-block text-sm\n\n1    async def twilio_receiver(twilio_ws):2        async for message in twilio_ws:3            try:4                data = json.loads(message)56                if data['event'] == 'start':7                    streamsid_queue.put_nowait(data['start']['streamSid'])8            except:9                break\n```\n\n- This task simply loops over incoming websocket messages from Twilio and extracts the stream sid when it gets it.\n\nNext we have the `twilio_sender` task:\n\nPython\n\n```code-block text-sm\n\n1    async def twilio_sender(twilio_ws):2        print('twilio_sender started')34        # wait to receive the streamsid for this connection from one of Twilio's messages5        streamsid = await streamsid_queue.get()\n```\n\n- We first wait to receive the stream sid.\n\nPython\n\n```code-block text-sm\n\n1        # make a Deepgram Aura TTS request specifying that we want raw mulaw audio as the output2        url = 'https://api.deepgram.com/v1/speak?model=aura-2-thalia-en&encoding=mulaw&sample_rate=8000&container=none'3        headers = {4            'Authorization': 'Token YOUR_DEEPGRAM_API_KEY',5            'Content-Type': 'application/json'6        }7        payload = {8            'text': 'Hello, how are you today?'9        }10        tts_response = requests.post(url, headers=headers, json=payload)\n```\n\n- Then we make a request to Deepgram Aura TTS to say “Hello, how are you today?” specifying an audio format of raw, 8000 Hz, mulaw.\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\nNext we have:\n\nPython\n\n```code-block text-sm\n\n1        if tts_response.status_code == 200:2            raw_mulaw = tts_response.content34            # construct a Twilio media message with the raw mulaw (see https://www.twilio.com/docs/voice/twiml/stream#websocket-messages---to-twilio)5            media_message = {6                'event': 'media',7                'streamSid': streamsid,8                'media': {9                    'payload': base64.b64encode(raw_mulaw).decode('ascii')10                }11            }1213            # send the TTS audio to the attached phonecall14            await twilio_ws.send(json.dumps(media_message))\n```\n\n- Here we package up the Deepgram Aura TTS audio in the format Twilio expects.\n- We specify the stream `sid`.\n- We send that audio back to Twilio via the websocket connection.\n- To better understand what is occurring at this step please refer to the [Twilio docs](https://www.twilio.com/docs/voice/twiml/stream#websocket-messages---to-twilio) for more details.\n\nAdditionally, if your application requires the bot to stop speaking at any point, you can do that simply by sending a “clear” message to Twilio.\n\nPython\n\n```code-block text-sm\n\n1await twilio_ws.send(json.dumps({\"event\": \"clear\", \"streamSid\": streamsid}))\n```\n\nTo close out our websocket handler, we run these two asynchronous tasks with `asyncio`:\n\nPython\n\n```code-block text-sm\n\n1    await asyncio.wait([2        asyncio.ensure_future(twilio_receiver(twilio_ws)),3        asyncio.ensure_future(twilio_sender(twilio_ws))4    ])56    await twilio_ws.close()\n```\n\nFinally, for some scaffolding to spin up the server and pointing requests to get handled by the above function, we have:\n\nPython\n\n```code-block text-sm\n\n1async def router(websocket, path):2    if path == '/twilio':3        print('twilio connection incoming')4        await twilio_handler(websocket)56def main():7    # use this if using ssl8#\tssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)9#\tssl_context.load_cert_chain('cert.pem', 'key.pem')10#\tserver = websockets.serve(router, '0.0.0.0', 443, ssl=ssl_context)1112    # use this if not using ssl13    server = websockets.serve(router, 'localhost', 5000)1415    asyncio.get_event_loop().run_until_complete(server)16    asyncio.get_event_loop().run_forever()1718if __name__ == '__main__':19    sys.exit(main() or 0)\n```\n\nTo learn more about sending Twilio phone call audio to Deepgram for Speech-to-Text (STT) see [the following guide.](https://developers.deepgram.com/docs/twilio-and-deepgram-tts)\n\n* * *\n\nWhat’s Next\n\n- [Twilio and Deepgram STT](https://developers.deepgram.com/docs/on-premise-twilio-integration)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=bx17olqkiwbp)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "description": "Learn how to use Twilio with Deepgram Aura TTS.",
      "application-name": "Deepgram's Docs",
      "twitter:title": "Twilio and Deepgram TTS | Deepgram's Docs",
      "title": "Twilio and Deepgram TTS | Deepgram's Docs",
      "og:title": "Twilio and Deepgram TTS | Deepgram's Docs",
      "twitter:card": "summary",
      "ogDescription": "Learn how to use Twilio with Deepgram Aura TTS.",
      "og:description": "Learn how to use Twilio with Deepgram Aura TTS.",
      "twitter:description": "Learn how to use Twilio with Deepgram Aura TTS.",
      "language": "en",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "Twilio and Deepgram TTS | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "scrapeId": "eb79fd23-5376-4673-8308-33f9b1a4bcbf",
      "sourceURL": "https://developers.deepgram.com/docs/twilio-and-deepgram-tts",
      "url": "https://developers.deepgram.com/docs/twilio-and-deepgram-tts",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram Voice Agent can integrate with the [Twilio streaming API](https://www.twilio.com/docs/voice/twiml/stream) to enable dynamic interactions between callers and voice agents or bots. This guide will walk you through how to setup a Twilio phone number that can interact with [Deepgram’s Voice Agent API](https://developers.deepgram.com/reference/build-a-voice-agent), allowing callers to engage with a voice agent in real-time.\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n## Prerequisites\n\nFor the complete code used in this guide, please [check out this repository](https://github.com/deepgram-devs/sts-twilio).\n\nYou will need:\n\n- A [free Twilio account](https://www.twilio.com/try-twilio) with a Twilio phone number.\n- [ngrok](https://ngrok.com/) to let Twilio access a local server OR your own hosted server.\n- Understanding of Python and using Python virtual environments.\n\n## TwiML Bin Setup\n\nFirst, you will need to set up a `TwiML Bin`. You can refer to the docs on how to do that in the [Twilio Console](https://www.twilio.com/docs/serverless/twiml-bins).\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>23<Response>4    <Say language=\"en\">\"This call may be monitored or recorded.\"</Say>5    <Connect>6        <Stream url=\"wss://a127-75-172-116-97.ngrok-free.app/twilio\" />7    </Connect>8</Response>\n```\n\n- You should replace the url with wherever you decide to deploy the server we are about to create and ensure `/twilio` is at the end of the url.\n- In the `TwiML Bin` example above, ngrok is used to expose the server running locally.\n- Be sure to use the ngrok URL provided as your WSS endpoint: In your `Twilio Bin` configuration you will need to replace `http://` with `wss://`.\n\n### Using ngrok\n\nngrok is recommended for quick development and testing but shouldn’t be used for production instances. To use ngrok see their [documentation](https://ngrok.com/docs/getting-started/).\n\nBe sure to set the port correctly to `5000` to align with the server code provided by running this command when you start the ngrok server.\n\n```code-block text-sm\n\nngrok http 5000\n```\n\nIf you restart your ngrok server, your URL will change, which will require you to update your `TwiML Bin`.\n\n### Connecting a Twilio phone number\n\nYour `TwiML Bin` must then be connected to one of your Twilio phone numbers so that it gets executed whenever someone calls that number. If you need to set up a new phone number and connect it to your `TwiML Bin`, refer to the [Twilio Docs](https://www.twilio.com/docs/serverless/twiml-bins/getting-started#wire-your-twiml-bin-up-to-an-incoming-phone-call).\n\nIn your `TwiML Bin` The `<Connect>` verb is required for bi-directional communication, i.e. in order to send audio from the Deepgram Agent to Twilio, you must use this verb.\n\n## Building the Server\n\nCopy the server code from the [repository](https://github.com/deepgram-devs/sts-twilio/blob/main/server.py) as we will use this in the steps below and save this code locally as with a file name of `server.py`.\n\nAt this point you’ll want to start up a virtual environment for Python. Please refer to documentation for how to do that based on your personal Python preferences.\n\nDepending on your situation you may also need to install specific packages used in this code. You can install the packages you need manually or use the `requirements.txt` file.\n\nPython\n\n```code-block text-sm\n\n1pip install -r requirements.txt\n```\n\nYou can set your Deepgram API key for the `sts_connect` function to run the server by running the following command in your terminal:\n\nBash\n\n```code-block text-sm\n\n$export DEEPGRAM_API_KEY=\"your_deepgram_api_key\"\n```\n\nIf your `TwiML Bin` is setup correctly, you can now navigate to the correct file location in your terminal and run the server with the following command:\n\nShell\n\n```code-block text-sm\n\n$python server.py\n```\n\nOR\n\nShell\n\n```code-block text-sm\n\n$python3 server.py\n```\n\n## Make a test call\n\nYou can now start making calls to the phone number your `TwiML Bin` is using. Without any further code modifications, you should hear Deepgram Aura say simply: “Hello, how are you today?”\n\n## Code Tour\n\nLet’s dive into the code used in the [server.py](https://github.com/deepgram-devs/sts-twilio/blob/main/server.py) file.\n\nFirst, we have some `import` statements:\n\nPython\n\n```code-block text-sm\n\n1import asyncio2import base643import json4import sys5import websockets6import ssl\n```\n\n- We are using `asyncio` and `websockets` to build an asynchronous websocket server.\n- We will use `base64` to handle encoding audio from Aura to pass data to Twilio.\n- We will use `json` to deal with parsing text messages from Twilio .\n- We will use `sys` to provides access to some variables and functions used or maintained by the Python interpreter.\n- We will use `ssl`(optional) to create secure encrypted connections between client and server.\n\n* * *\n\nThe next block of code `sts_connect` defines a function that establishes a WebSocket connection to Deepgram’s agent service.\n\nPython\n\n```code-block text-sm\n\n1def sts_connect():2  # you can run export DEEPGRAM_API_KEY=\"your key\" in your terminal to set your API key.3  api_key = os.getenv('DEEPGRAM_API_KEY')4  if not api_key:5      raise ValueError(\"DEEPGRAM_API_KEY environment variable is not set\")67  sts_ws = websockets.connect(8      \"wss://agent.deepgram.com/v1/agent/converse\",9      subprotocols=[\"token\", api_key]10  )11  return sts_ws\n```\n\nLet’s break it down:\n\n**Connection Setup:**\n\n- Creates a secure WebSocket connection to `wss://agent.deepgram.com/agent`\n- Includes authentication via subprotocols\n\n**Authentication Method:**\n\n- Uses Deepgram’s token-based authentication\n- Requires replacing “YOUR\\_DEEPGRAM\\_API\\_KEY” with an actual Deepgram API key\n\n* * *\n\nThe next block of code, `twilio_handler` does several things:\n\nIn this first code block, we set up an asynchronous function to handle WebSocket messages from Twilio. We define additional asynchronous functions to manage messages received from Twilio, messages sent to Deepgram, and responses from Deepgram. To facilitate data sharing between tasks, we use two queues: one for audio from Twilio and another for Twilio’s stream SID ( _a unique identifier_).\n\nPython\n\n```code-block text-sm\n\n1async def twilio_handler(twilio_ws):2    audio_queue = asyncio.Queue()3    streamsid_queue = asyncio.Queue()\n```\n\nAlso included in `twilio_handler` is the [Setting Configuration](https://developers.deepgram.com/docs/voice-agent-settings-configuration) for our Agent. The most important thing to note here is the audio format we are using `8000 Hz`, raw, un-containerized `mulaw`. This is the format Twilio will be sending, and the format we will need to send back to Twilio including some base64 encoding/decoding.\n\nTo learn more about supported media inputs and outputs for the Voice Agent [review the documentation.](https://developers.deepgram.com/docs/voice-agent-media-inputs-outputs)\n\nPython\n\n```code-block text-sm\n\n1 async with sts_connect() as sts_ws:2      config_message = {3          \"type\": \"Settings\",4          \"audio\": {5              \"input\": {6                  \"encoding\": \"mulaw\",7                  \"sample_rate\": 8000,8              },9              \"output\": {10                  \"encoding\": \"mulaw\",11                  \"sample_rate\": 8000,12                  \"container\": \"none\",13              },14          },15          \"agent\": {16              \"language\": \"en\",17              \"listen\": {18                  \"provider\": {19                      \"type\": \"deepgram\",20                      \"model\": \"nova-3\",21                      \"keyterms\": [\"hello\", \"goodbye\"]22                  }23              },24              \"think\": {25                  \"provider\": {26                      \"type\": \"open_ai\",27                      \"model\": \"gpt-4o-mini\",28                      \"temperature\": 0.729                  },30                  \"prompt\": \"You are a helpful AI assistant focused on customer service.\"31              },32              \"speak\": {33                  \"provider\": {34                      \"type\": \"deepgram\",35                      \"model\": \"aura-2-thalia-en\"36                  }37              },38              \"greeting\": \"Hello! How can I help you today?\"39          }40      }\n\n```\n\nThe next block of code is `sts_sender`. This function waits for audio from Twilio ( _via the audio queue)_ and continuously reads audio chunks from the queue forwarding the chunks to the Deepgram Voice Agent API.\n\nPython\n\n```code-block text-sm\n\n1async def sts_sender(sts_ws):2            print(\"sts_sender started\")3            while True:4                chunk = await audio_queue.get()5                await sts_ws.send(chunk)\n```\n\nNext is `sts_receiver` which waits until it has received a stream SID from Twilio, and then loops over messages received from the Deepgram Voice Agent API. If we receive a text message, we check to ensure that the user has started speaking. If they have, we treat this as barge-in and have Twilio clear the agent audio on the call using the stream SID.\n\nOther audio messages should be binary messages containing the text-to-speech (TTS) output of the Deepgram Voice Agen API. We pack all of this up into valid Twilio messages _(using the stream SID again),_ and send them to Twilio to be played back on the phone for the caller to here.\n\nFor more information about streaming audio to Twilio, see the following [Documentation.](https://www.twilio.com/docs/voice/twiml/stream#websocket-messages---to-twilio)\n\nPython\n\n```code-block text-sm\n\n1async def sts_receiver(sts_ws):2            print(\"sts_receiver started\")3            # we will wait until the twilio ws connection figures out the streamsid4            streamsid = await streamsid_queue.get()5            # for each sts result received, forward it on to the call6            async for message in sts_ws:7                if type(message) is str:8                    print(message)9                    # handle barge-in10                    decoded = json.loads(message)11                    if decoded['type'] == 'UserStartedSpeaking':12                        clear_message = {13                            \"event\": \"clear\",14                            \"streamSid\": streamsid15                        }16                        await twilio_ws.send(json.dumps(clear_message))1718                    continue1920                print(type(message))21                raw_mulaw = message2223                # construct a Twilio media message with the raw mulaw (see https://www.twilio.com/docs/voice/twiml/stream#websocket-messages---to-twilio)24                media_message = {25                    \"event\": \"media\",26                    \"streamSid\": streamsid,27                    \"media\": {\"payload\": base64.b64encode(raw_mulaw).decode(\"ascii\")},28                }2930                # send the TTS audio to the attached phonecall31                await twilio_ws.send(json.dumps(media_message))\n\n```\n\nThe next block of code is `twilio_reciever` and loops over messages Twilio is sending our server. If we receive a “start” message, we can extract the stream SID, and send it to our other async task which needs it. If we receive a “media” message, we decode the audio from it, append it to a running buffer, and send it to the async task which forwards it to Deepgram when it’s of a reasonable size.\n\nBe aware there can be throughput issues when sending lots of tiny chunks, so that’s why we are doing this buffering approach.\n\nPython\n\n```code-block text-sm\n\n1  async def twilio_receiver(twilio_ws):2            print(\"twilio_receiver started\")3            # twilio sends audio data as 160 byte messages containing 20ms of audio each4            # we will buffer 20 twilio messages corresponding to 0.4 seconds of audio to improve throughput performance5            BUFFER_SIZE = 20 * 16067            inbuffer = bytearray(b\"\")8            async for message in twilio_ws:9                try:10                    data = json.loads(message)11                    if data[\"event\"] == \"start\":12                        print(\"got our streamsid\")13                        start = data[\"start\"]14                        streamsid = start[\"streamSid\"]15                        streamsid_queue.put_nowait(streamsid)16                    if data[\"event\"] == \"connected\":17                        continue18                    if data[\"event\"] == \"media\":19                        media = data[\"media\"]20                        chunk = base64.b64decode(media[\"payload\"])21                        if media[\"track\"] == \"inbound\":22                            inbuffer.extend(chunk)23                    if data[\"event\"] == \"stop\":24                        break2526                    # check if our buffer is ready to send to our audio_queue (and, thus, then to sts)27                    while len(inbuffer) >= BUFFER_SIZE:28                        chunk = inbuffer[:BUFFER_SIZE]29                        audio_queue.put_nowait(chunk)30                        inbuffer = inbuffer[BUFFER_SIZE:]31                except:32                    break\n\n```\n\nThe next block of code runs the asynchronous tasks defined in `twilio_reciever`.\n\n```code-block text-sm\n\nawait asyncio.wait(            [                asyncio.ensure_future(sts_sender(sts_ws)),                asyncio.ensure_future(sts_receiver(sts_ws)),                asyncio.ensure_future(twilio_receiver(twilio_ws)),            ]        )        await twilio_ws.close()\n```\n\nFinally the last block of code sets up and runs the server, making sure all incoming websocket connections get handled by `twilio_handler`.\n\nPython\n\n```code-block text-sm\n\n1async def router(websocket, path):2    print(f\"Incoming connection on path: {path}\")3    if path == \"/twilio\":4        print(\"Starting Twilio handler\")5        await twilio_handler(websocket)67def main():8    # use this if using ssl9    # ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)10    # ssl_context.load_cert_chain('cert.pem', 'key.pem')11    # server = websockets.serve(router, '0.0.0.0', 443, ssl=ssl_context)1213    # use this if not using ssl14    server = websockets.serve(router, \"localhost\", 5000)15    print(\"Server starting on ws://localhost:5000\")1617    asyncio.get_event_loop().run_until_complete(server)18    asyncio.get_event_loop().run_forever()1920if __name__ == \"__main__\":21    sys.exit(main() or 0)\n```\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=mr13lovlfg3p)",
    "metadata": {
      "title": "Twilio and Deepgram Voice Agent | Deepgram's Docs",
      "language": "en",
      "og:description": "Learn how to use Twilio with Deepgram Voice Agent API.",
      "twitter:description": "Learn how to use Twilio with Deepgram Voice Agent API.",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Twilio and Deepgram Voice Agent | Deepgram's Docs",
      "twitter:title": "Twilio and Deepgram Voice Agent | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "description": "Learn how to use Twilio with Deepgram Voice Agent API.",
      "ogTitle": "Twilio and Deepgram Voice Agent | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogDescription": "Learn how to use Twilio with Deepgram Voice Agent API.",
      "scrapeId": "d9aab21f-0687-4864-95a9-52e23854f0bc",
      "sourceURL": "https://developers.deepgram.com/docs/twilio-and-deepgram-voice-agent",
      "url": "https://developers.deepgram.com/docs/twilio-and-deepgram-voice-agent",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "In this guide, we’ll explain how to talk to a Dialogflow CX agent using Deepgram for transcription and text-to-speech. We’ll do this by walking through Deepgram’s [Dialogflow Example](https://github.com/deepgram/dialogflow-example) repo on GitHub.\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n## Create a Dialogflow CX Agent\n\nYou’ll also need a Dialogflow agent to talk to. If you don’t already have one, the easiest approach is to create a [prebuilt agent](https://cloud.google.com/dialogflow/cx/docs/concept/agents-prebuilt).\n\n## Try Out the Demo\n\nClone the [Dialogflow Example](https://github.com/deepgram/dialogflow-example) repo and follow the instructions in `README.md`. You’ll need to provide your Deepgram API key and your Dialogflow agent information. The [video](https://github.com/deepgram/dialogflow-example#demo) in the README shows how the demo should work.\n\n# High-Level Architecture\n\nDialogflow agents can accept user input in the form of audio or text. If you send audio to an agent, Google will transcribe it with their own speech-to-text engine. In order to use Deepgram’s transcription, we need to transcribe the audio outside of Dialogflow and send the resulting text to our agent. If we also want to use Deepgram’s text-to-speech for the bot’s voice, we must configure Dialogflow to return agent responses as text. This diagram depicts the full process:\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fc213cc7-dialogflow-architecture-tts.png&w=2048&q=75)\n\n1. The user speaks into their microphone.\n2. The integration continuously streams the user’s speech to Deepgram.\n3. Deepgram streams back transcripts.\n4. The integration analyzes the transcripts to determine when the user has completed a thought ( [“utterance segmentation”](https://deepgram.com/learn/building-a-conversational-ai-flow-with-deepgram)). When it finds a complete utterance, it sends it to the Dialogflow agent as text.\n5. The agent replies with its response, also in the form of text.\n6. The agent’s response is sent to Deepgram’s text-to-speech engine.\n7. Deepgram returns the response as audio.\n8. The audio is played to the user.\n9. The process repeats until the conversation is finished.\n\n# Deeper Look\n\nAt any given time, `server.js` is in one of two states. In the **awaiting utterance** state, it is collecting transcripts from Deepgram and looking for an indication that the user has finished their thought. In the **awaiting bot reply** state, it is discarding transcripts because we’ve already sent the utterance to Dialogflow and it is now the bot’s turn to speak.\n\nThis is the code that runs when `server.js` receives a transcription result from Deepgram (note the two states):\n\nJavaScript\n\n```code-block text-sm\n\n1function handleDgResults(start, duration, isFinal, speechFinal, transcript, words) {2  switch (voicebotState) {3    case STATES.AwaitingUtterance:4      // Update `finalizedTranscript` and `unfinalizedTranscript` in light of the new result5      updateTranscriptState(transcript, isFinal);67      // Update `latestTimeSeen` and `latestFinalizedWordEnd` in light of the new result8      updateSilenceDetectionState(start, duration, words, isFinal);910      if (finalizedTranscript === \"\") {11        return;12      }1314      let silenceDetected = 15          unfinalizedTranscript === \"\" && latestTimeSeen - latestFinalizedWordEnd > 1.25;1617      if (silenceDetected || speechFinal) {18        changeVoicebotState(STATES.AwaitingBotReply);19        20        // Send the completed utterance to Dialogflow21        sendUtteranceDownstream(finalizedTranscript); 22      }2324      break;25    case STATES.AwaitingBotReply:26      // Discard the transcript; do nothing27      break;28  }29}\n\n```\n\n`finalizedTranscript` is all of the concatenated `is_final=true` results that we’ve received since the start of the current utterance. `unfinalizedTranscript` is the most recent `is_final=false` result for which we have not yet seen an `is_final=true`. (If these concepts are unfamiliar, have a look at the documentation on [interim results](https://developers.deepgram.com/docs/interim-results).)\n\nWhen we detect that the current `finalizedTranscript` contains a full utterance, we send it off to Dialogflow and await the agent’s reply.\n\nThis detection happens when there is a sufficient period of silence after the transcript. That is, when either of these conditions is met:\n\n1. We’ve reached an [endpoint](https://developers.deepgram.com/docs/endpointing) ( `speech_final=true`), or\n2. The transcripts reveal a 1.25 second silence after the last finalized word.\n\n# Options for Customizing Utterance Segmentation\n\nThe approach described above is a solid starting point for detecting end of utterance, but depending on your needs you may want to explore various customizations. For example, you can adjust the `endpointing` and silence detection values (currently set to `500ms` and `1.25s`, respectively). Below are some additional modifications you might consider.\n\n## Update Dialogflow with Resumed Utterances\n\nYou may want to send tentative utterances to Dialogflow. Then if the user resumes speaking before the agent has replied, you can cancel the original Dialogflow operation and send the new, full utterance to Dialogflow instead. This comes with a couple of advantages:\n\n- **Lower latency**. For example, you can set endpointing to a snappy `10ms` and send the utterance to Dialogflow right away at an endpoint. Then you get the agent reply and hold it until you verify that the user has really stopped speaking, at which point you send it to the user immediately.\n- **Last-minute interjections**. With this approach the user is able to add to their utterance right until the bot reply is sent to them.\n\nIf you go this route, make sure that any actions taken by the Dialogflow agent on the tentative utterance are indeed reversible in the event of a replacement utterance. It is possible to rewind the state of the agent itself (see the parameters [here](https://cloud.google.com/dialogflow/cx/docs/reference/rest/v3/QueryParameters)), but the agent can’t uncall any webhooks that it called while fulfilling the user’s request.\n\n## Don’t Segment on Endpoints\n\nEndpointing is sometimes said to be a poor indicator of end of utterance. On one hand, an `endpointing` value that is too low can lead to false positives. On the other hand, an `endpointing` value that is too high may simply [not fire due to background noise](https://developers.deepgram.com/docs/understanding-end-of-speech-detection-while-streaming#limitations-of-endpointing). So you can try leaving `endpointing` at its default value of `10ms` (for rapid finalization of transcripts) and only doing utterance segmentation based on word timing analysis.\n\n## Replace Word Timing Logic with `utterance_end_ms`\n\nFinally, you may choose to use Deepgram’s [UtteranceEnd](https://developers.deepgram.com/docs/understanding-end-of-speech-detection-while-streaming#introducing-the-utteranceend-feature) feature in place of the word timing logic. This is really a matter of preference; do you prefer the conciseness of the built-in `UtteranceEnd` message, or the clarity and flexibility of the explicit word timing logic?\n\n# AudioCodes as an Alternative\n\nDeepgram’s partner AudioCodes offers a managed solution called [VoiceAI Connect](https://voiceaiconnect.audiocodes.com/google-dialogflow), which enables you to pair Deepgram’s speech-to-text with many different bot frameworks, including Dialogflow CX. Read more about our integration with AudioCodes [here](https://deepgram.com/learn/audiocodes-voicebots-integration).\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=8e6igj5oigle)",
    "metadata": {
      "twitter:title": "Google Dialogflow CX and Deepgram | Deepgram's Docs",
      "title": "Google Dialogflow CX and Deepgram | Deepgram's Docs",
      "ogDescription": "Dialogflow CX is a framework for building virtual agents. Learn how to incorporate Deepgram's transcription and text-to-speech for improved accuracy.",
      "og:description": "Dialogflow CX is a framework for building virtual agents. Learn how to incorporate Deepgram's transcription and text-to-speech for improved accuracy.",
      "theme-color": "#f5f5f7",
      "og:title": "Google Dialogflow CX and Deepgram | Deepgram's Docs",
      "language": "en",
      "description": "Dialogflow CX is a framework for building virtual agents. Learn how to incorporate Deepgram's transcription and text-to-speech for improved accuracy.",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:description": "Dialogflow CX is a framework for building virtual agents. Learn how to incorporate Deepgram's transcription and text-to-speech for improved accuracy.",
      "ogTitle": "Google Dialogflow CX and Deepgram | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "scrapeId": "17ab7203-79b0-40df-a572-9940cd0babf2",
      "sourceURL": "https://developers.deepgram.com/docs/use-deepgram-with-dialogflow-cx",
      "url": "https://developers.deepgram.com/docs/use-deepgram-with-dialogflow-cx",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Your audio data may contain sensitive information and it’s critical that your data stays private. AWS S3’s presigned URLs can be leveraged to securely send audio data to Deepgram and securely receive transcripts from Deepgram.\n\n## What are Presigned URLs?\n\nIn this guide we’ll walk you through how to leverage presigned URLs to 1) send audio data from S3 to Deepgram and 2) upload transcripts generated by Deepgram directly to S3.\n\nBut first of all, what is a presigned URL?\n\nA presigned URL is a time-limited URL that provides temporary access to an object stored in an S3 bucket. Presigned URLs provide a flexible and secure way to grant temporary access to S3 objects without compromising the security of your AWS credentials or making the object publicly accessible. Presigned URLs are commonly used in scenarios where you want to grant temporary access to private S3 objects to specific individuals or applications, which makes them a perfect fit for sharing audio data with Deepgram.\n\n## Before you Begin\n\nBefore you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n### Create an AWS Account, an S3 Bucket, and Upload an Audio File\n\nIf you don’t already have an AWS account, you can create one on the [AWS Console](http://console.aws.amazon.com/console/home).\n\nOnce you’re logged into AWS, [create a bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html) in S3 [here](https://s3.console.aws.amazon.com/s3/home?region=us-east-1). Note that bucket names must be globally unique, so you may need to create a bucket with a long name, such `deepgram-audio-and-transcripts-<your-name>`. You can use the default bucket configurations when creating the bucket.\n\nNext, upload an audio file to your bucket. We recommend creating two folders, one called `audio` and another called `transcripts`, then uploading your audio files into the `audio` folder. [Here](https://res.cloudinary.com/deepgram/video/upload/v1663090406/dg-audio/NASA-EXP61_EVA_n5zazi.m4a) is the sample audio file we are using in this guide.\n\n### Setup the AWS Python SDK\n\n#### Enable Programmatic Access to AWS\n\nIf you already have AWS credentials in your `~/.aws/credentials` file, you can skip this step.\n\nYou will need to enable programmatic access to AWS to use the AWS SDKs. After logging into the AWS Console, follow the steps below:\n\n1. Click on IAM → Users → select your user → Security Credentials → Access Keys → Create Access Key → Application running outside AWS → Next → Create access key. Do not close the web page until you complete Step 4!\n\n2. Create or open the shared AWS `credentials` file. This file is `~/.aws/credentials` on Linux and macOS, and `%USERPROFILE%\\\\.aws\\\\credentials` on Windows. For more information, see AWS’s [Configuration and credential file settings](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html).\n\n3. Add the following text to the shared `credentials` file.\n\n\n\n\n\n\n\n\n\nmarkdown\n\n\n\n\n\n\n\n\n\n```code-block text-sm\n\n\n\n\n[default]aws_access_key_id = AKIAIOSFODNN7EXAMPLEaws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n```\n\n4. Replace the `aws_access_key_id` and `aws_secret_access_key` with the values created in Step 1.\n\n\nNow, when the AWS SDK is loaded, your user’s programmatic access will be used by default.\n\n#### Install the AWS Python SDK\n\nThe AWS Python SDK is called `boto3`. You can find the docs [here](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\n\nTo install `boto3`, run `pip install boto3`.\n\n## Sending Audio Data to Deepgram Using a Presigned URL\n\nOnce you have an audio file uploaded to one of your S3 buckets, you can generate a presigned URL very easily from the AWS S3 website: Click on your audio file, then going to “Object actions” in the top-right corner, and click “Share with a presigned URL”.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F855c249-create-presigned-url-ui.png&w=828&q=75)\n\nThe presigned URL will be copied to your clipboard, and if you paste it into your browser’s URL bar the file will be downloaded to your computer. If you carefully inspect the URL, you will notice query parameters such as `Amz-Security-Token` and `X-Amz-Expires`. These query parameters contain the credentials for secure access to your files.\n\nWe will use the [AWS Python SDK](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) (installed via `pip install boto3`) to programmatically create presigned URLs. The below code creates a presigned URL that retrieves a file from S3:\n\nPython\n\n```code-block text-sm\n\n1from botocore.client import Config2import boto334# Initialize the AWS SDK with an S3 client5BUCKET_NAME = \"presigned-url-example-bucket\"  # Your S3 bucket6BUCKET_REGION = \"us-east-1\"  # The region your S3 bucket is in (visible in the `Properties` tab)7s3_client = boto3.client(\"s3\", config=Config(signature_version=\"s3v4\", region_name=BUCKET_REGION))89AUDIO_FILE_PATH_IN_S3 = \"audio/NASA-first-all-female-space-walk.mp3\"10EXPIRATION_TIME_IN_SECONDS = 10 * 60  # 10 minutes11# Create a presigned GET URL12get_url = s3_client.generate_presigned_url(13    ClientMethod=\"get_object\",14    Params={\"Bucket\": BUCKET_NAME, \"Key\": AUDIO_FILE_PATH_IN_S3},15    ExpiresIn=EXPIRATION_TIME_IN_SECONDS,16)\n```\n\nYou can download the NASA audio file [here](https://deepgram.com/wp-content/uploads/2022/11/NASA-EXP61_EVA-v2.mp3).\n\nNice work! Now you can include the `get_url` in your Deepgram API call to send the audio to Deepgram. Since the presigned URL contains the relevant security credentials, your data is safe from prying eyes.\n\n## Uploading Transcripts Directly to S3\n\nTo programmatically create a presigned URL that uploads a file to S3, use the code below:\n\nPython\n\n```code-block text-sm\n\n1TRANSCRIPT_FILE_PATH_IN_S3 = \"transcripts/NASA-first-all-female-space-walk.json\"2EXPIRATION_TIME_IN_SECONDS = 10 * 60  # 10 minutes3# Create a presigned PUT URL4put_url = s3_client.generate_presigned_url(5    ClientMethod=\"put_object\",6    Params={7        \"Bucket\": BUCKET_NAME,8        \"Key\": TRANSCRIPT_FILE_PATH_IN_S3,9        \"ContentType\": \"application/json\",10    },11    ExpiresIn=EXPIRATION_TIME_IN_SECONDS,12)\n```\n\nThe presigned URL generated by this code allows any file to be uploaded to the S3 path specified by `TRANSCRIPT_FILE_PATH_IN_S3`. We will pass this URL to Deepgram via the `callback` query parameter. Note that this URL requires the requester to make a `PUT` request.\n\nThe presigned `PUT` URL’s expiration time must take into account the time it takes for the audio to be transcribed, which is why a default value of 10 minutes is used in this guide. Longer audio files will require longer expiration times for the `PUT` URL. You may need to find an expiration time that fits your use case.\n\nFinally, you can combine the GET and PUT URLs in an API request to Deepgram to perform the transcription:\n\nPython\n\n```code-block text-sm\n\n1import os23DEEPGRAM_API_KEY = os.environ[\"DEEPGRAM_API_KEY\"]  # Your Deepgram API Key4deepgram = Deepgram(DEEPGRAM_API_KEY)56def transcribe_audio(get_url: str, put_url: str):7    options = {8        \"smart_format\": True,9        \"model\": \"nova-3\",10        \"callback\": put_url,11        \"callback_method\": \"put\",12    }13    source = {\"url\": get_url}14    deepgram.transcription.sync_prerecorded(source, options)\n```\n\nPresigned URLs that upload files to S3 can use either the `PUT` or `POST` HTTP method. It is critical that the `PUT` HTTP method is used when communicating with Deepgram. Presigned `POST` URLs move the credential information from the URL’s query parameters into the request body, and since a `callback`’s request body cannot be set via the Deepgram API the `PUT` method is required.\n\n## Putting It All Together\n\nBelow is the full code for 1) generating presigned URLs, 2) sending your audio data to Deepgram, and 3) uploading transcripts directly into S3:\n\nPython\n\n```code-block text-sm\n\n1from typing import Tuple2from botocore.client import Config3from deepgram import Deepgram4import boto35import os67DEEPGRAM_API_KEY = os.environ[\"DEEPGRAM_API_KEY\"]  # Your Deepgram API Key8deepgram = Deepgram(DEEPGRAM_API_KEY)910BUCKET_NAME = \"deepgram-presigned-url-example-bucket\"  # Your S3 bucket11BUCKET_REGION = \"us-east-1\"  # The region your S3 bucket is in (visible in the `Properties` tab)12s3_client = boto3.client(\"s3\", config=Config(signature_version=\"s3v4\", region_name=BUCKET_REGION))1314def get_presigned_urls(audio_file_key: str, destination_transcript_key: str, expiration_time) -> Tuple[str, str]:15    get_url = s3_client.generate_presigned_url(16        ClientMethod=\"get_object\",17        Params={\"Bucket\": BUCKET_NAME, \"Key\": audio_file_key},18        ExpiresIn=expiration_time,19    )20    put_url = s3_client.generate_presigned_url(21        ClientMethod=\"put_object\",22        Params={23            \"Bucket\": BUCKET_NAME,24            \"Key\": destination_transcript_key,25            \"ContentType\": \"application/json\",26        },27        ExpiresIn=expiration_time,28    )29    return get_url, put_url3031def transcribe_audio(get_url: str, put_url: str):32    options = {33        \"smart_format\": True,34        \"model\": \"nova-3\",35        \"callback\": put_url,36        \"callback_method\": \"put\",37    }38    source = {\"url\": get_url}39    deepgram.transcription.sync_prerecorded(source, options)4041def main():42    # The name of the audio file that Deepgram will pull from your bucket to be transcribed43    audio_file = \"audio/NASA-first-all-female-space-walk.mp3\"4445    # The name of the file that Deepgram will upload to the bucket with your transcription results46    dest_file = \"transcripts/NASA-first-all-female-space-walk.json\"4748    # Time in seconds that the generated URLs will be valid49    expiration_time = 10 * 60  # 10 minutes5051    get_url, put_url = get_presigned_urls(52        audio_file_key=audio_file,53        destination_transcript_key=dest_file,54        expiration_time=expiration_time,55    )56    transcribe_audio(57        get_url=get_url,58        put_url=put_url,59    )6061if __name__ == \"__main__\":62    main()\n\n```\n\n## Serverless Workflow with Lambda Functions and S3 Event Notifications\n\nAWS Lambda functions are popular in serverless architectures and integrate seamlessly with the presigned URL workflow explained in this guide. There are a few nuances to using presigned URLs and accessing Deepgram in a Lambda function, so if you’re using a Lambda function then keep reading!\n\n### Allow Lambda Functions to Generate Presigned URLs\n\nIf you are using a serverless infrastructure, you may want to use AWS Lambda functions to generate presigned URLs. Make sure the Lambda’s Execution Role contains permissions for the `S3:PutObject` and `S3:GetObject` actions. Below is an example policy statement:\n\nJSON\n\n```code-block text-sm\n\n1{2\t\"Sid\": \"allow-presigned-url-access\",3\t\"Effect\": \"Allow\",4\t\"Action\": [5\t\t\"s3:PutObject\",6\t\t\"s3:GetObject\",7\t],8\t\"Resource\": [9\t\t\"arn:aws:s3:::deepgram-presigned-url-example-bucket/transcript/*\",10\t\t\"arn:aws:s3:::deepgram-presigned-url-example-bucket/audio/\",11\t]12}\n```\n\n### Accessing Deepgram from AWS Lambda\n\nAWS Lambda functions do not have access to most Python packages, including the Deepgram SDK. To use the Deepgram SDK, you can upload a Lambda Layer.\n\nAlternatively, if you just need to make simple requests to Deepgram, you can use the `requests` package to make calls to Deepgram. Below is the full code that can be used in a Lambda function (using Python 3.10).\n\nPython\n\n```code-block text-sm\n\n1import pip._vendor.requests as requests  # Import a pre-installed `requests` module2from botocore.client import Config3from typing import Tuple4import urllib.parse5import boto36import json78DEEPGRAM_API_KEY = \"YOUR_DEEPGRAM_API_KEY\"910BUCKET_NAME = \"deepgram-presigned-url-example-bucket\"  # Your S3 bucket11BUCKET_REGION = \"us-east-1\"  # The region your S3 bucket is in (visible in the `Properties` tab)12s3_client = boto3.client(\"s3\", config=Config(signature_version=\"s3v4\", region_name=BUCKET_REGION))1314def get_presigned_urls(audio_file_key: str, destination_transcript_key: str, expiration_time) -> Tuple[str, str]:15    get_url = s3_client.generate_presigned_url(16        ClientMethod=\"get_object\",17        Params={\"Bucket\": BUCKET_NAME, \"Key\": audio_file_key},18        ExpiresIn=expiration_time,19    )20    put_url = s3_client.generate_presigned_url(21        ClientMethod=\"put_object\",22        Params={23            \"Bucket\": BUCKET_NAME,24            \"Key\": destination_transcript_key,25            \"ContentType\": \"application/json\",26        },27        ExpiresIn=expiration_time,28    )29    return get_url, put_url3031def transcribe_audio(get_url: str, put_url: str):32    source = {\"url\": get_url}33    headers = {\"Authorization\": f\"Token {DEEPGRAM_API_KEY}\", \"Content-Type\": \"application/json\"}3435    options = {36        \"model\": \"nova-3\",37        \"smart_format\": \"true\",38        \"callback\": put_url,39        \"callback_method\": \"put\"40    }41    params = urllib.parse.urlencode(options)42    url = f\"https://api.deepgram.com/v1/listen?{params}\"43    response = requests.post(url, headers=headers, data=json.dumps(source))44    data = response.json()45    return data4647def lambda_handler(event, context):48    # The name of the audio file that Deepgram will pull from your bucket to be transcribed49    audio_file = \"audio/NASA-first-all-female-space-walk.mp3\"5051    # The name of the file that Deepgram will upload to the bucket with your transcription results52    dest_file = \"transcripts/NASA-first-all-female-space-walk.json\"5354    # Time in seconds that the generated URLs will be valid55    expiration_time = 10 * 60  # 10 minutes5657    get_url, put_url = get_presigned_urls(58        audio_file_key=audio_file,59        destination_transcript_key=dest_file,60        expiration_time=expiration_time,61    )62    r = transcribe_audio(63        get_url=get_url,64        put_url=put_url,65    )6667    return {68        'statusCode': 200,69        'body': json.dumps(r)70    }\n\n```\n\n### Responding to Transcript Completion using S3 Event Notifications\n\nOnce a transcript is uploaded to S3, it’s important for your application to know the transcription is complete. AWS has a feature called “S3 Event Notifications” that can trigger events in other AWS services when a file is uploaded to a certain bucket/location.\n\nTo enable event notifications for your S3 bucket, go to the `Properties` tab and scroll down to the “Event Notifications” section. You can set up event notifications to be triggered when an object is `put` into a specific directory in your S3 bucket, defined by a `prefix`.\n\nEvent notifications can trigger a Lambda function, and the event notification will include the full key/filename of the transcript that was uploaded to S3. Your serverless backend can then load the transcript and provide it to your users. If you do not wish to load the transcript into the Lambda’s memory, you can create _another_ presigned `GET` URL to allow the client-side application to load the transcript directly in a safe and secure way!\n\n## Troubleshooting\n\nIf you are receiving `AccessDenied` messages such as the one below, it’s likely the presigned URL has expired. Try setting a longer expiration time when creating the URL. Note that the presigned `PUT` URL’s expiration time must take into account the time it takes for the audio to be transcribed.\n\nXML\n\n```code-block text-sm\n\n1<?xml version=\"1.0\" encoding=\"UTF-8\"?>2<Error>3    <Code>AccessDenied</Code>4    <Message>Request has expired</Message>5    <X-Amz-Expires>120</X-Amz-Expires>6    <Expires>2023-06-06T21:28:06Z</Expires>7    <ServerTime>2023-06-07T19:52:03Z</ServerTime>8    <RequestId>ZK1CA2Z9FH9N7E49</RequestId>9    <HostId>J48F/Rz5bayiqj6FQ3kRIZ/5zNLfzPDlWdX8v6EsLITgTMb7wbEJIEC2l2QvNrIw86jl/fkGM+U=</HostId>10</Error>\n```\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F9f93eca-presigned-url-error-message-1.png&w=1920&q=75)\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F855c249-create-presigned-url-ui.png&w=828&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F9f93eca-presigned-url-error-message-1.png&w=1920&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=5jf54ecsh5ry)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "ogDescription": "Use S3 to send audio data to Deepgram and store transcripts from Deepgram directly in S3.",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "title": "AWS S3 Presigned URLs and Deepgram | Deepgram's Docs",
      "ogTitle": "AWS S3 Presigned URLs and Deepgram | Deepgram's Docs",
      "twitter:title": "AWS S3 Presigned URLs and Deepgram | Deepgram's Docs",
      "language": "en",
      "twitter:card": "summary",
      "description": "Use S3 to send audio data to Deepgram and store transcripts from Deepgram directly in S3.",
      "twitter:description": "Use S3 to send audio data to Deepgram and store transcripts from Deepgram directly in S3.",
      "og:title": "AWS S3 Presigned URLs and Deepgram | Deepgram's Docs",
      "og:description": "Use S3 to send audio data to Deepgram and store transcripts from Deepgram directly in S3.",
      "scrapeId": "4ac7d740-3a81-49d8-b1a8-ea3c4fe3588f",
      "sourceURL": "https://developers.deepgram.com/docs/using-aws-s3-presigned-urls-with-the-deepgram-api",
      "url": "https://developers.deepgram.com/docs/using-aws-s3-presigned-urls-with-the-deepgram-api",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "You can obtain up to 90 days of log usage data from Deepgram. If you need log usage data for a longer period of time you can use our [Usage API](https://developers.deepgram.com/reference/get-all-requests) to programmatically fetch usage data on an interval and store it for retrieval as needed.\n\n# Using Console Logs & Usage\n\nWithin the [Deepgram Console](https://console.deepgram.com/) you can view your API usage and API log activity of all your requests.\n\n### To view your Summarized Usage\n\n> Not limited to 90 days.\n\n1. Login to the [Deepgram Console](https://console.deepgram.com/)\n2. Click on the Usage Tab in the left navigation panel.\n3. On the Overview Tab, select your filter options.\n4. View the results.\n\n### To view your Logs\n\n> Limited to 90 days.\n\n1. Login to the [Deepgram Console](https://console.deepgram.com/)\n2. Click on the Usage Tab in the left navigation panel.\n3. On the Logs Tab, select your filter options.\n4. View the results.\n\n# Obtaining Usage via the API\n\nYou can use the Deepgram API to programmatically fetch usage data. Please refer to our [API documentation](https://developers.deepgram.com/reference/get-all-requests) for more details.\n\nThis also enables exporting and reporting on your usage, which can be imported into other tools of your choosing, such as Tableau, Grafana, or Datadog.\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n### Get All Requests\n\nReplace `YOUR_PROJECT_ID` with your Deepgram project id.\n\ncURL\n\n```code-block text-sm\n\n$curl --request GET \\>     --url 'https://api.deepgram.com/v1/projects/YOUR_PROJECT_ID/requests?start=2023-10-01&end=2023-10-05&status=succeeded' \\>     --header 'Authorization: Token YOUR_DEEPGRAM_API_KEY' \\>     --header 'accept: application/json'\n```\n\nA response will be returned as such:\n\nJSON\n\n```code-block text-sm\n\n1{2    \"page\": 0,3    \"limit\": 1,4    \"requests\": [5        {6            \"request_id\": \"a758d58d-e3ec-xxx\",7            \"created\": \"2023-10-05T22:49:03.509654Z\",8            \"path\": \"/v1/listen?-xxx\",9            \"api_key_id\": \"f54158f4-xxx-xxx\",10            \"response\": null,11            \"callback\": null12        }13    ]14}\n```\n\n### Summarize Usage\n\nSummarized usage data is not limited to 90 days.\n\nReplace `YOUR_PROJECT_ID` with your Deepgram project id.\n\ncURL\n\n```code-block text-sm\n\n$curl --request GET \\>     --url 'https://api.deepgram.com/v1/projects/YOUR_PROJECT_ID/usage?start=2023-10-01&end=2023-10-05' \\>     --header 'Authorization: Token YOUR_DEEPGRAM_API_KEY' \\>     --header 'accept: application/json'\n```\n\nA response will be returned:\n\nJSON\n\n```code-block text-sm\n\n1{2    \"start\": \"2023-10-01\",3    \"end\": \"2023-10-05\",4    \"resolution\": {5        \"units\": \"day\",6        \"amount\": 17    },8    \"results\": [9        {10            \"start\": \"2023-10-01\",11            \"end\": \"2023-10-01\",12            \"hours\": 865.7331186111111,13            \"total_hours\": 867.6975186111111,14            \"requests\": 5410515        },16        {17            \"start\": \"2023-10-02\",18            \"end\": \"2023-10-02\",19            \"hours\": 1188.9926763888889,20            \"total_hours\": 1191.5563763888888,21            \"requests\": 5608122        },23        {24            \"start\": \"2023-10-03\",25            \"end\": \"2023-10-03\",26            \"hours\": 1473.9747994444444,27            \"total_hours\": 1477.5771794444445,28            \"requests\": 5645629        },30        {31            \"start\": \"2023-10-04\",32            \"end\": \"2023-10-04\",33            \"hours\": 999.2419933333333,34            \"total_hours\": 1001.2063933333334,35            \"requests\": 5454836        },37        {38            \"start\": \"2023-10-05\",39            \"end\": \"2023-10-05\",40            \"hours\": 11447.164485833333,41            \"total_hours\": 11449.0443075,42            \"requests\": 19620943        }44    ]45}\n```\n\n## Understanding Console Usage Log States\n\nWithin the [Deepgram Console](https://console.deepgram.com/) you can view usage request logs and you may see requests in different states. Below is an explanation of what those states mean and a recommended resolution.\n\n| State | Meaning | Recommended Resolution |\n| --- | --- | --- |\n| Pending | Data on the response hasn’t been recorded yet. | Give the request time to process. |\n| Unknown | We haven’t confirmed the resolution of this request yet. | Wait for the request to transition to Lost, Error, or Success. |\n| Lost | The resolution for this request was never logged. You won’t be charged for this request. | Contact [Support](https://developers.deepgram.com/docs/support) for assistance. |\n| Error | This request had an error. | Retry the request. |\n\n* * *\n\nWhat’s Next\n\n- [API Rate Limits](https://developers.deepgram.com/reference/api-rate-limits)",
    "metadata": {
      "ogTitle": "Logs & Usage Data | Deepgram's Docs",
      "ogDescription": "Learn how to use Deepgram's Log and Usage features.",
      "generator": "https://buildwithfern.com",
      "og:title": "Logs & Usage Data | Deepgram's Docs",
      "language": "en",
      "og:description": "Learn how to use Deepgram's Log and Usage features.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "theme-color": [
        "#f5f5f7",
        "#0b0b0c",
        "#f5f5f7"
      ],
      "description": "Learn how to use Deepgram's Log and Usage features.",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:description": "Learn how to use Deepgram's Log and Usage features.",
      "title": "Logs & Usage Data | Deepgram's Docs",
      "twitter:title": "Logs & Usage Data | Deepgram's Docs",
      "scrapeId": "2c719932-1830-4506-9031-a89c6e1d17b1",
      "sourceURL": "https://developers.deepgram.com/docs/using-logs-usage",
      "url": "https://developers.deepgram.com/docs/using-logs-usage",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Overview\n\nThe `Sec-WebSocket-Protocol` header plays a crucial role in WebSocket communications by enabling the client and server to agree on a specific subprotocol. Subprotocols define a higher-level protocol that runs over the WebSocket connection, specifying the format and semantics of the exchanged messages. This guide aims to provide a comprehensive understanding of how to use this header with Deepgram’s Listen WebSocket and and Speak WebSocket endpoint to facilitate seamless , secure and structured communication.\n\nThe use of this header is only required when making “client side” connections to Deepgram, where custom `Authorization` headers are prohibited by security measures in apps, including web apps, mobile apps and certain desktop apps.\n\n## Risks of Use\n\nWhen utilizing custom subprotocols in WebSocket communications, several security considerations must be addressed to ensure safe and reliable connections. Failure to do so can expose both the client and server to various risks, including unauthorized access, data breaches, and denial-of-service attacks.\n\n## Key Considerations\n\n01. **Authentication and Authorization**:\n    - Verify client identities and ensure proper permissions for actions.\n02. **Data Encryption**:\n    - Use TLS (wss://) to encrypt connections and consider end-to-end encryption for data payloads.\n03. **Input Validation and Sanitization**:\n    - Rigorously validate and sanitize all incoming data to prevent injection attacks.\n04. **Rate Limiting and Throttling**:\n    - Implement mechanisms to prevent abuse and denial-of-service (DoS) attacks.\n05. **Message Integrity**:\n    - Use integrity checks to ensure messages are untampered during transit.\n06. **Session Management**:\n    - Securely manage and expire sessions to prevent hijacking.\n07. **Error Handling**:\n    - Handle errors gracefully without exposing internal details.\n08. **Protection Against Common Attacks**:\n    - Mitigate risks from attacks like Cross-Site WebSocket Hijacking, XSS, and CSRF.\n09. **Custom Subprotocol Security**:\n    - Design secure subprotocols and regularly review their implementation for vulnerabilities.\n10. **Compliance and Best Practices**:\n\n\n- Ensure compliance with relevant security standards and follow industry best practices for secure WebSocket communication.\n\n## STT WebSocket Example\n\nTo use the `Sec-WebSocket-Protocol` header with [Deepgram’s Listen WebSocket endpoint,](https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming) follow this example:\n\nhttp\n\n```code-block text-sm\n\nGET /listen HTTP/1.1Host: wss://api.deepgram.com/Upgrade: websocketConnection: UpgradeSec-WebSocket-Key: <calculated at runtime>Sec-WebSocket-Version: 13Sec-WebSocket-Protocol: token, YOUR_DEEPGRAM_API_KEY\n```\n\nIn this example, the `Sec-WebSocket-Protocol` header specifies two subprotocols: `token` and a valid Deepgram API Key. During the WebSocket handshake, the server will select one of these subprotocols for the communication and authentication.\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n## TTS WebSocket Example\n\nTo use the `Sec-WebSocket-Protocol` header with [Deepgram’s Speak WebSocket endpoint](https://developers.deepgram.com/reference/text-to-speech-api/speak-streaming), follow this example:\n\nhttp\n\n```code-block text-sm\n\nGET /speak HTTP/1.1Host: wss://api.deepgram.com/Upgrade: websocketConnection: UpgradeSec-WebSocket-Key: <calculated at runtime>Sec-WebSocket-Version: 13Sec-WebSocket-Protocol: token, YOUR_DEEPGRAM_API_KEY\n```\n\nIn this example, the `Sec-WebSocket-Protocol` header specifies two subprotocols: `token` and a valid Deepgram API Key. During the WebSocket handshake, the server will select one of these subprotocols for the communication and authentication.\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n## Conclusion\n\nSecuring custom subprotocols in WebSocket communications involves ensuring authentication, encryption, input validation, rate limiting, and protection against common attacks. By implementing these measures, you can enhance the security and reliability of your WebSocket connections. The `Sec-WebSocket-Protocol` header is an essential component in this regard, facilitating the agreement on a subprotocol and enabling structured communication between the client and server.\n\n* * *\n\nWhat’s Next\n\n- [Authentication](https://developers.deepgram.com/reference/authentication)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=po19wr7k9v6f)",
    "metadata": {
      "description": "Learn how to to use the Sec-WebSocket-Protocol with Deepgram APIs to send secure client side requests via web sockets.",
      "title": "Using the Sec-WebSocket-Protocol | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "twitter:card": "summary",
      "twitter:title": "Using the Sec-WebSocket-Protocol | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:description": "Learn how to to use the Sec-WebSocket-Protocol with Deepgram APIs to send secure client side requests via web sockets.",
      "ogTitle": "Using the Sec-WebSocket-Protocol | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogDescription": "Learn how to to use the Sec-WebSocket-Protocol with Deepgram APIs to send secure client side requests via web sockets.",
      "og:title": "Using the Sec-WebSocket-Protocol | Deepgram's Docs",
      "og:description": "Learn how to to use the Sec-WebSocket-Protocol with Deepgram APIs to send secure client side requests via web sockets.",
      "language": "en",
      "scrapeId": "422200e4-a15a-4a09-ac1f-999acaccb21a",
      "sourceURL": "https://developers.deepgram.com/docs/using-the-sec-websocket-protocol",
      "url": "https://developers.deepgram.com/docs/using-the-sec-websocket-protocol",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "You will need to migrate to the new _**Voice Agent API V1**_ to continue to use the Voice Agent API. Please refer to the [Voice Agent API Migration Guide](https://developers.deepgram.com/docs/voice-agent-v1-migration) for more information.\n\n## Voice Selection\n\n| Voice Selection |\n| --- |\n| [Deepgram TTS Voice Models](https://developers.deepgram.com/docs/tts-models) |\n| [Third Party TTS Voice Models](https://developers.deepgram.com/docs/voice-agent-tts-models) |\n\n## Supported LLM Models\n\n| Models |\n| --- |\n| [LLM Models](https://developers.deepgram.com/docs/voice-agent-llm-models) |\n\n## Inputs: Client Messages\n\n| Feature |\n| --- |\n| [Settings](https://developers.deepgram.com/docs/voice-agent-settings) |\n| [Update Speak](https://developers.deepgram.com/docs/voice-agent-update-speak) |\n| [Inject Agent Message](https://developers.deepgram.com/docs/voice-agent-inject-agent-message) |\n| [Agent Keep Alive](https://developers.deepgram.com/docs/agent-keep-alive) |\n\n## Outputs: Server Events\n\n| Feature |\n| --- |\n| [Welcome](https://developers.deepgram.com/docs/voice-agent-welcome-message) |\n| [Settings Applied](https://developers.deepgram.com/docs/voice-agent-setting-applied-message) |\n| [Conversation Text](https://developers.deepgram.com/docs/voice-agent-conversation-text) |\n| [User Started Speaking](https://developers.deepgram.com/docs/voice-agent-user-started-speaking) |\n| [Agent Thinking](https://developers.deepgram.com/docs/voice-agent-agent-thinking) |\n| [Prompt Updated](https://developers.deepgram.com/docs/voice-agent-prompt-updated) |\n| [Speak Updated](https://developers.deepgram.com/docs/voice-agent-speak-updated) |\n| [Agent Audio Done](https://developers.deepgram.com/docs/voice-agent-agent-audio-done) |\n| [Agent Errors](https://developers.deepgram.com/docs/voice-agent-errors) |\n| [Agent Warnings](https://developers.deepgram.com/docs/voice-agent-warning) |\n\n## Input / Output Events\n\n| Feature |\n| --- |\n| [Function Call Request](https://developers.deepgram.com/docs/voice-agent-function-call-request) |\n| [Function Call Response](https://developers.deepgram.com/docs/voice-agent-function-call-response) |\n\n## Rate Limits\n\nFor information on Deepgram’s Concurrency Rate Limits, refer to our [API Rate Limits Documentation](https://developers.deepgram.com/reference/api-rate-limits).\n\n## Deepgram Self-Hosted\n\nHaving challenges with performance and latency? Check out Deepgram’s [Self-Hosted Solution](https://developers.deepgram.com/docs/self-hosted-introduction) to get the benefits of running your own hosted instance of Deepgram.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=kxvdo6chmwcc)",
    "metadata": {
      "twitter:description": "Below is a matrix of Deepgram's Voice Agent API features. Please refer to the corresponding documentation for more details.",
      "twitter:card": "summary",
      "twitter:title": "Feature Overview | Deepgram's Docs",
      "og:description": "Below is a matrix of Deepgram's Voice Agent API features. Please refer to the corresponding documentation for more details.",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "description": "Below is a matrix of Deepgram's Voice Agent API features. Please refer to the corresponding documentation for more details.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Feature Overview | Deepgram's Docs",
      "ogTitle": "Feature Overview | Deepgram's Docs",
      "ogDescription": "Below is a matrix of Deepgram's Voice Agent API features. Please refer to the corresponding documentation for more details.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": "Feature Overview | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "scrapeId": "530e34a9-2688-4ff8-bfc2-eda4e9c2fadb",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-feature-overview",
      "url": "https://developers.deepgram.com/docs/voice-agent-feature-overview",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `FunctionCallRequest` message is sent by the Voice Agent server to request a function call. The handling of this call—whether the server executes it or expects the client to—depends on the `client_side` flag.\n\n## Purpose\n\nThis message is used to trigger either a built-in server-side function or a custom function defined by the client.\n\n- When `client_side` is `false`, the server will handle the function using built-in logic.\n- When `client_side` is `true`, the client must handle the function and respond with a [`FunctionCallResponse`](https://developers.deepgram.com/docs/voice-agent-function-call-response).\n\n## Handling the message\n\nThe `client_side` property is set by the server to indicate where the function should be executed.\n\nWhen your client receives a `FunctionCallRequest`:\n\n1. Check the `client_side` field.\n2. If it’s `true`, call the appropriate client-defined function.\n3. Return a `FunctionCallResponse` message with the function result.\n4. If it’s `false`, no client action is needed; the server will handle it internally.\n\n## Example payload\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallRequest\",3  \"functions\": [4    {5      \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",6      \"name\": \"get_weather\",7      \"arguments\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\"}\",8      \"client_side\": true9    }10  ]11}\n```\n\nIn this example, the server is requesting that the client execute a function named `get_weather` with the given arguments.\n\n## Related messages\n\n- [`FunctionCallResponse`](https://developers.deepgram.com/docs/voice-agent-function-call-response): The expected response from the client when `client_side` is `true`.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=2wl01gwbcqpr)",
    "metadata": {
      "title": "Function Call Request | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "ogTitle": "Function Call Request | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "language": "en",
      "application-name": "Deepgram's Docs",
      "og:title": "Function Call Request | Deepgram's Docs",
      "ogDescription": "Server-initiated message requesting a function call, to be handled by either client or server",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Function Call Request | Deepgram's Docs",
      "twitter:description": "Server-initiated message requesting a function call, to be handled by either client or server",
      "generator": "https://buildwithfern.com",
      "og:description": "Server-initiated message requesting a function call, to be handled by either client or server",
      "description": "Server-initiated message requesting a function call, to be handled by either client or server",
      "scrapeId": "8dac0be2-55fa-4ecf-bbf8-e91025aa614e",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-function-call-request",
      "url": "https://developers.deepgram.com/docs/voice-agent-function-call-request",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `FunctionCallResponse` message contains the result of a function call. It is usually sent by the client in response to a `FunctionCallRequest`, but may also be sent by the server if the function was handled internally (When a request contained `client_side: false`).\n\n## Purpose\n\nThis message completes a function call flow. It provides the output of the function to the agent, regardless of where it was executed.\n\n- If the [request](https://developers.deepgram.com/docs/voice-agent-function-call-request) was marked `client_side: true`, the client sends the `FunctionCallResponse`.\n- If the request had `client_side: false`, the server sends this message after processing the function.\n\n## Fields\n\n- `type`: Always `\"FunctionCallResponse\"`.\n- `id`: The ID of the original function call (optional but recommended for traceability).\n- `name`: The name of the function that was called.\n- `content`: A text summary or result of the function’s output. This is often passed to the next step in the conversation, or parsed if it contains encoded text (i.e. JSON).\n\n## Example payload\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallResponse\",3  \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",4  \"name\": \"get_weather\",5  \"content\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\", \\\"temperature_c\\\": 21, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 40, \\\"wind_kph\\\": 14}\"6}\n```\n\nIn this example, the client (or server) returns the result of calling the `get_weather` function.\n\n## Related messages\n\n- [`FunctionCallRequest`](https://developers.deepgram.com/docs/voice-agent-function-call-request): The message that triggers a function to be called.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=u47qyu8t4cm1)",
    "metadata": {
      "twitter:card": "summary",
      "ogTitle": "Function Call Response | Deepgram's Docs",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "description": "Message containing the result of a function call, sent by client or server",
      "og:description": "Message containing the result of a function call, sent by client or server",
      "theme-color": "#f5f5f7",
      "title": "Function Call Response | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "twitter:description": "Message containing the result of a function call, sent by client or server",
      "generator": "https://buildwithfern.com",
      "og:title": "Function Call Response | Deepgram's Docs",
      "twitter:title": "Function Call Response | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogDescription": "Message containing the result of a function call, sent by client or server",
      "scrapeId": "034393aa-3ad3-44ec-adfd-69f563d28269",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-function-call-response",
      "url": "https://developers.deepgram.com/docs/voice-agent-function-call-response",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `InjectAgentMessage` message is a JSON message you can send to immediately trigger an agent statement.\n\n## Purpose\n\nThe `InjectAgentMessage` message provides a way to immediately trigger an agent response during a conversation. However, it must be carefully timed, as the request will be ignored if the user is speaking or if the agent is already responding. To ensure successful injection, the client should only attempt it during silent moments, avoiding interruptions and potential `InjectionRefused` errors.\n\nThe client should only try to inject agent messages during silent portions of the conversation.\n\n## Example Payloads\n\nTo send the `InjectAgentMessage` message, you need to send the following JSON message to the server:\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"InjectAgentMessage\",3  \"message\": \"\" // The statement the agent should say4}\n```\n\nAfter completing the agent’s speech audio transmission, the server sends an [`AgentAudioDone`](https://developers.deepgram.com/docs/voice-agent-agent-audio-done) message.\n\nJSON\n\n```code-block text-sm\n\n1{2    \"type\": \"AgentAudioDone\"3}\n```\n\nThe server will send an `InjectionRefused` message when an `InjectAgentMessage` request is ignored because it arrived while the user was speaking or while the server was sending audio for an agent response.\n\nJSON\n\n```code-block text-sm\n\n1{2    \"type\": \"InjectionRefused\"3}\n```\n\n## Use Cases\n\nSome common ways to use the `injectAgentMessage` are:\n\n- Informing the user that the agent is working on a lengthy function call (“Hold on while I look that up for you”)\n- Prompting the user to continue if the user hasn’t spoken for a while (“Are you still on the line?”)\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=7ef80305-2d84-4c42-90ef-577b5baa54bc&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=bf94550d-022f-49c5-9c80-45d42e65fdd7&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fvoice-agent-inject-agent-message&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=7ef80305-2d84-4c42-90ef-577b5baa54bc&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=bf94550d-022f-49c5-9c80-45d42e65fdd7&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fvoice-agent-inject-agent-message&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=vz8vili3y7f5)",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "title": "Inject Agent | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "og:description": "Send a message to immediately trigger an Agent statement.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "description": "Send a message to immediately trigger an Agent statement.",
      "og:title": "Inject Agent | Deepgram's Docs",
      "twitter:title": "Inject Agent | Deepgram's Docs",
      "language": "en",
      "ogTitle": "Inject Agent | Deepgram's Docs",
      "ogDescription": "Send a message to immediately trigger an Agent statement.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "Send a message to immediately trigger an Agent statement.",
      "twitter:card": "summary",
      "generator": "https://buildwithfern.com",
      "scrapeId": "32c28566-50c9-4644-9eaf-bba7cd5b0149",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-inject-agent-message",
      "url": "https://developers.deepgram.com/docs/voice-agent-inject-agent-message",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Client Messages are JSON-formatted commands that the client sends to the Deepgram server over the WebSocket connection during a voice agent interaction. These messages allow the client to control various aspects of the conversation, configure the agent, and provide necessary information.\n\n## List of Client Messages\n\n- [`Settings`](https://developers.deepgram.com/docs/voice-agent-settings): Initializes the voice agent and sets up audio transmission formats before any voice data is exchanged.\n- [`Update Speak`](https://developers.deepgram.com/docs/voice-agent-update-speak): Enables changing the Speak model during the conversation.\n- [`Inject Agent Message`](https://developers.deepgram.com/docs/voice-agent-inject-agent-message): Triggers an immediate statement from the agent.\n- [`Function Call Response`](https://developers.deepgram.com/docs/voice-agent-function-call-response): Sends the result of a function call back to the server.\n- [`Agent Keep Alive`](https://developers.deepgram.com/docs/agent-keep-alive): Maintains the connection to prevent timeouts.\n\nFor more detailed information on the format and usage of each message, refer to the individual documentation pages for each message.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=2uyboclrgugv)",
    "metadata": {
      "language": "en",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Inputs: Client Messages | Deepgram's Docs",
      "title": "Inputs: Client Messages | Deepgram's Docs",
      "ogTitle": "Inputs: Client Messages | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:description": "Client messages you can send to the server to control the Voice Agent.",
      "description": "Client messages you can send to the server to control the Voice Agent.",
      "ogDescription": "Client messages you can send to the server to control the Voice Agent.",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Inputs: Client Messages | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:description": "Client messages you can send to the server to control the Voice Agent.",
      "scrapeId": "fc14a494-90be-4d8a-95ee-ea03d5f65866",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-inputs",
      "url": "https://developers.deepgram.com/docs/voice-agent-inputs",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Server Events are messages sent from the Deepgram server to the client over the WebSocket connection during a voice agent interaction. These events provide real-time updates about the conversation’s status, including user and agent actions, as well as any processing that’s occurring.\n\n## List of Server Events\n\n- [`Welcome`](https://developers.deepgram.com/docs/voice-agent-welcome-message): Confirms that the WebSocket has opened successfully.\n- [`Settings Applied`](https://developers.deepgram.com/docs/voice-agent-setting-applied-message): Confirms that the configuration settings have been applied.\n- [`Conversation Text`](https://developers.deepgram.com/docs/voice-agent-conversation-text): Provides the text of what was spoken by either the user or the agent.\n- [`User Started Speaking`](https://developers.deepgram.com/docs/voice-agent-user-started-speaking): Notifies that the user has begun speaking.\n- [`Agent Thinking`](https://developers.deepgram.com/docs/voice-agent-agent-thinking): Informs the client that the agent is processing information.\n- [`Function Call Request`](https://developers.deepgram.com/docs/voice-agent-function-call-request): Sent when the agent needs to make a function call.\n- [`Function Call Response`](https://developers.deepgram.com/docs/voice-agent-function-call-response): Sent to provide information about a function call.\n- [`Prompt Updated`](https://developers.deepgram.com/docs/voice-agent-prompt-updated): Confirms that a Prompt Configuration change has been applied.\n- [`Speak Updated`](https://developers.deepgram.com/docs/voice-agent-speak-updated): Confirms that a Speak Configuration change has been applied.\n- [`Agent Audio Done`](https://developers.deepgram.com/docs/voice-agent-agent-audio-done): Indicates that the server has finished sending the final audio segment to the client.\n- [`Agent Errors`](https://developers.deepgram.com/docs/voice-agent-errors): Notifies the client if an error has occurred on the server side.\n- [`Agent Warnings`](https://developers.deepgram.com/docs/voice-agent-warning): Notifies the client if a warning has occurred on the server side.\n\nEach of these events serves a specific purpose in managing the flow of the conversation and keeping the client informed about the state of the interaction. They allow for a dynamic and responsive experience when using Deepgram’s Voice Agent API.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=bszjsixg4xdk)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:description": "Server messages you will receive from the Agent server.",
      "twitter:description": "Server messages you will receive from the Agent server.",
      "description": "Server messages you will receive from the Agent server.",
      "ogDescription": "Server messages you will receive from the Agent server.",
      "language": "en",
      "twitter:card": "summary",
      "title": "Outputs: Server Events | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "og:title": "Outputs: Server Events | Deepgram's Docs",
      "twitter:title": "Outputs: Server Events | Deepgram's Docs",
      "ogTitle": "Outputs: Server Events | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "scrapeId": "ace99fc0-6591-4923-b576-6e5cc6606026",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-outputs",
      "url": "https://developers.deepgram.com/docs/voice-agent-outputs",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `Settings` message is a JSON command that serves as an initialization step, setting up both the behavior of the voice agent.\n\n## Purpose\n\nThe `Settings` message is an initialization command that establishes both the behavior of the voice agent and the audio transmission formats before voice data is exchanged. The client should send a `Settings` message immediately after opening the websocket and before sending any audio.\n\nFor a detailed explanation of all the options available for the `Settings` message, see our documentation on how to [Configure the Voice Agent](https://developers.deepgram.com/docs/configure-voice-agent).\n\n## Example Payloads\n\nThis example uses a very basic `Settings` to establish a connection. To send the `Settings` message, you need to send the following JSON message to the server:\n\nJSON\n\n```code-block text-sm\n\n1{2\"type\": \"Settings\",3\"audio\": {4  \"input\": {5    \"encoding\": \"linear16\",6    \"sample_rate\": 240007  },8  \"output\": {9    \"encoding\": \"linear16\",10    \"sample_rate\": 24000,11    \"container\": \"none\"12    // ... additional output options: bitrate13  }14},15\"agent\": {16  \"language\": \"en\",17  \"listen\": {18    \"provider\": {19      \"type\": \"deepgram\",20      \"model\": \"nova-3\"21      // ... additional provider options: keyterms (nova-3 'en' only)22    }23  },24  \"think\": {25    \"provider\": {26      \"type\": \"open_ai\",27      \"model\": \"gpt-4o-mini\",28      \"temperature\": 0.729      // ... additional provider options: endpoint (for non-deepgram providers)30    },31    // ... additional think options: prompt, functions, endpoint32  },33  \"speak\": {34    \"provider\": {35      \"type\": \"deepgram\",36      \"model\": \"aura-2-thalia-en\"37      // ... additional provider options based on type:38      // - eleven_labs: model_id, language_code39      // - cartesia: model_id, voice (mode, id), language40      // - open_ai: voice41      // - aws_polly: engine, credentials, language_code, voice42    }43    // ... additional speak options: endpoint (for non-deepgram providers)44  }45  // ... additional agent options: greeting46}47// ... additional top-level options: experimental48}\n\n```\n\nUpon receiving the `Settings` message, the server will process all remaining audio data and return the following [`SettingsApplied`](https://developers.deepgram.com/docs/voice-agent-setting-applied-message) message.\n\nJSON\n\n```code-block text-sm\n\n1{2    \"type\": \"SettingsApplied\"3}\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=297yo046eykb)",
    "metadata": {
      "twitter:description": "Send a Settings message to configure the voice agent's behavior, audio formats, and provider configurations before starting the conversation.",
      "og:description": "Send a Settings message to configure the voice agent's behavior, audio formats, and provider configurations before starting the conversation.",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "description": "Send a Settings message to configure the voice agent's behavior, audio formats, and provider configurations before starting the conversation.",
      "language": "en",
      "title": "Settings | Deepgram's Docs",
      "twitter:title": "Settings | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Settings | Deepgram's Docs",
      "ogDescription": "Send a Settings message to configure the voice agent's behavior, audio formats, and provider configurations before starting the conversation.",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "og:title": "Settings | Deepgram's Docs",
      "scrapeId": "62456b3c-fbad-41cf-86ca-4eda6e944229",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-settings",
      "url": "https://developers.deepgram.com/docs/voice-agent-settings",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `UpdatePrompt` message is a JSON message that you can use to update the system prompt of the agent.\n\n## Purpose\n\nThe `UpdatePrompt` message is a JSON message that allows you to update the system prompt of the agent. This flexibility enables real-time adjustments to the agent’s behavior, ensuring a more dynamic and responsive interaction tailored to the evolving needs of the conversation.\n\n## Example Payloads\n\nTo send the `UpdatePrompt` message, you need to send the following JSON message to the server:\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"UpdatePrompt\",3  \"prompt\": \"\" // The new system prompt4}\n```\n\nUpon receiving the `UpdatePrompt` message, the server will process all remaining audio data and return a [`PromptUpdated`](https://developers.deepgram.com/docs/voice-agent-prompt-updated) message.\n\nJSON\n\n```code-block text-sm\n\n1{2    \"type\": \"PromptUpdated\"3}\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=dvo13glrc6v8)",
    "metadata": {
      "language": "en",
      "ogDescription": "Send a message to update the system prompt of the agent.",
      "generator": "https://buildwithfern.com",
      "og:description": "Send a message to update the system prompt of the agent.",
      "twitter:title": "Update Prompt | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "application-name": "Deepgram's Docs",
      "title": "Update Prompt | Deepgram's Docs",
      "description": "Send a message to update the system prompt of the agent.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "Update Prompt | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:description": "Send a message to update the system prompt of the agent.",
      "og:title": "Update Prompt | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "3c8a27ad-474a-4df3-b28c-c9e90ce341fe",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-update-prompt",
      "url": "https://developers.deepgram.com/docs/voice-agent-update-prompt",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nThe `UpdateSpeak` message is a JSON message that you can use to change the Speak model in the middle of a conversation.\n\n## Purpose\n\nThe `UpdateSpeak` message is a JSON message that allows you to switch the Speak model during a conversation. This flexibility enables real-time adjustments to the agent’s voice output, ensuring a more dynamic and responsive interaction tailored to the evolving needs of the conversation.\n\n## Example Payloads\n\nTo send the `UpdateSpeak` message, you need to send the following JSON message to the server:\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"UpdateSpeak\",3  \"model\": \"\" // The new Speak model4}\n```\n\nUpon receiving the `UpdateSpeak` message, the server will process all remaining audio data and return a [`SpeakUpdated`](https://developers.deepgram.com/docs/voice-agent-speak-updated) message.\n\nJSON\n\n```code-block text-sm\n\n1{2    \"type\": \"SpeakUpdated\"3}\n```",
    "metadata": {
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "ogDescription": "Send a message to change the Speak model in the middle of a conversation.",
      "twitter:title": "Update Speak | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "title": "Update Speak | Deepgram's Docs",
      "og:title": "Update Speak | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "ogTitle": "Update Speak | Deepgram's Docs",
      "og:description": "Send a message to change the Speak model in the middle of a conversation.",
      "twitter:description": "Send a message to change the Speak model in the middle of a conversation.",
      "description": "Send a message to change the Speak model in the middle of a conversation.",
      "language": "en",
      "scrapeId": "21842406-910e-4292-b51d-0e7b2716c9c9",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-update-speak",
      "url": "https://developers.deepgram.com/docs/voice-agent-update-speak",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide helps developers migrate from the early access version of the Deepgram Voice Agent API to the official V1 release.\n\nThe [Deepgram API Spec](https://github.com/deepgram/deepgram-api-specs) and [Voice Agent API Reference](https://developers.deepgram.com/reference/voice-agent-api/agent) have more details on the new Voice Agent API.\n\n## Endpoint Changes\n\n| Early Access | V1 |\n| --- | --- |\n| `wss://agent.deepgram.com/agent` | `wss://agent.deepgram.com/v1/agent/converse` |\n\n## Message Type Changes\n\n### Removed Message Types\n\nThe following message types from early access have been removed in V1:\n\n| Message Type | Description |\n| --- | --- |\n| `UpdateInstructions` | Now handled through the more flexible `Settings` structure |\n| `FunctionCalling` | Function calling status is now handled differently |\n\n### New Message Types\n\nHere is a list of all-new message types in V1:\n\n| Message Type | Description |\n| --- | --- |\n| `PromptUpdated` | Confirmation that a prompt update has been applied |\n| `SpeakUpdated` | Confirmation that a speak configuration update has been applied |\n| `Warning` | Non-fatal errors or warnings |\n| `AgentThinking` | Notification that the agent is thinking |\n| `UserStartedSpeaking` | Notification that the user has started speaking |\n\n### `Welcome` Message Changes\n\nThe welcome message has had the `session_id` field renamed to `request_id` to better align with other products.\n\n#### Early Access: `Welcome`\n\n```code-block text-sm\n\n1{2  \"type\": \"Welcome\",3  \"session_id\": \"fc553ec9-5874-49ca-a47c-b670d525a4b1\"4}\n```\n\n#### V1: `Welcome`\n\n```code-block text-sm\n\n1{2  \"type\": \"Welcome\",3  \"request_id\": \"fc553ec9-5874-49ca-a47c-b670d525a4b1\"4}\n```\n\n### `SettingsConfiguration` Becomes `Settings`\n\nThe most significant change is to the configuration message:\n\n#### Early Access: `SettingsConfiguration`\n\n```code-block text-sm\n\n1{2  \"type\": \"SettingsConfiguration\",3  \"audio\": {4    \"input\": { \"encoding\": \"linear16\", \"sample_rate\": 16000 },5    \"output\": { \"encoding\": \"linear16\", \"sample_rate\": 24000 }6  },7  \"agent\": {8    \"instructions\": \"You are a helpful AI assistant. Keep responses concise.\",9    \"listen_model\": \"nova\",10    \"think_model\": \"gpt-4\",11    \"speak_model\": \"aura\"12  }13}\n```\n\n#### V1: `Settings`\n\n```code-block text-sm\n\n1{2  \"type\": \"Settings\",3  \"audio\": {4    \"input\": { \"encoding\": \"linear16\", \"sample_rate\": 16000 },5    \"output\": { \"encoding\": \"linear16\", \"sample_rate\": 24000 }6  },7  \"agent\": {8    \"listen\": { \"provider\": { \"model\": \"nova-3\" } },9    \"think\": {10      \"provider\": { \"model\": \"gpt-4o-mini\" },11      \"prompt\": \"You are a helpful AI assistant. Keep responses concise.\"12    },13    \"speak\": { \"provider\": { \"model\": \"aura-2-andromeda-en\" } }14  }15}\n```\n\nFor more details on all the possible settings available in the new `Settings` message, check out the [Configure the Voice Agent](https://developers.deepgram.com/docs/configure-voice-agent) guide.\n\nKey differences:\n\n1. Message type changed from `SettingsConfiguration` to `Settings`\n2. Added fields: `mip_opt_out` and `experimental`\n3. Introduced provider-based structure for listen, think, and speak capabilities\n4. `instructions` field renamed to `prompt` in the think configuration\n5. Added `container` field to audio output configuration\n6. Added optional `greeting` field\n7. Added support for custom endpoints via the `endpoint` object for non-Deepgram providers\n\n### `UpdateSpeak` Changes\n\nThe `UpdateSpeak` message has been restructured to use the provider pattern:\n\n#### Early Access: `UpdateSpeak`\n\n```code-block text-sm\n\n1{2  \"type\": \"UpdateSpeak\",3  \"model\": \"aura-asteria-en\"4}\n```\n\n#### V1: `UpdateSpeak`\n\n```code-block text-sm\n\n1{2  \"type\": \"UpdateSpeak\",3  \"speak\": {4    \"provider\": {5      \"type\": \"deepgram\",6      \"model\": \"aura-2-thalia-en\"7    }8  }9}\n```\n\n### `InjectAgentMessage` Changes\n\nThe `InjectAgentMessage` message has a field rename:\n\n#### Early Access: `InjectAgentMessage`\n\n```code-block text-sm\n\n1{2  \"type\": \"InjectAgentMessage\",3  \"message\": \"I apologize, but I need to correct my previous statement...\"4}\n```\n\n#### V1: `InjectAgentMessage`\n\n```code-block text-sm\n\n1{2  \"type\": \"InjectAgentMessage\",3  \"content\": \"I apologize, but I need to correct my previous statement...\"4}\n```\n\n### Function Calling Changes\n\nThe function calling interface has significant changes:\n\n#### Early Access: `FunctionCallRequest`\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallRequest\",3  \"function_name\": \"get_weather\",4  \"function_call_id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",5  \"input\": {6    \"location\": \"Fremont, CA 94539\"7  }8}\n```\n\n#### V1: `FunctionCallRequest`\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallRequest\",3  \"functions\": [4    {5      \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",6      \"name\": \"get_weather\",7      \"arguments\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\"}\",8      \"client_side\": true9    }10  ]11}\n```\n\n#### Early Access: `FunctionCallResponse`\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallResponse\",3  \"function_call_id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",4  \"output\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\", \\\"temperature_c\\\": 21, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 40, \\\"wind_kph\\\": 14}\"5}\n```\n\n#### V1: `FunctionCallResponse`\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallResponse\",3  \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",4  \"name\": \"get_weather\",5  \"content\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\", \\\"temperature_c\\\": 21, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 40, \\\"wind_kph\\\": 14}\"6}\n```\n\n### `Error` Response Changes\n\nThe `Error` message structure has been updated:\n\n#### Early Access: `Error`\n\n```code-block text-sm\n\n1{2  \"type\": \"Error\",3  \"message\": \"Failed to process audio input: Invalid audio format\"4}\n```\n\n#### V1: `Error`\n\n```code-block text-sm\n\n1{2  \"type\": \"Error\",3  \"description\": \"Failed to process audio input: Invalid audio format\",4  \"code\": \"INVALID_AUDIO_FORMAT\"5}\n```\n\n## Function Call Handling in V1\n\nThe function calling system in V1 has been significantly improved with a clearer client-side vs. internal server-side execution model.\n\n### FunctionCallRequest\n\nIn V1, the `FunctionCallRequest` message includes a `client_side` flag that explicitly indicates where the function should be executed:\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallRequest\",3  \"functions\": [4    {5      \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",6      \"name\": \"get_weather\",7      \"arguments\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\"}\",8      \"client_side\": true9    }10  ]11}\n```\n\nWhen handling a `FunctionCallRequest`:\n\n1. Check the `client_side` flag in each function\n2. If `client_side` is `true`, your client code must:\n   - Execute the specified function with the provided arguments\n   - Send a `FunctionCallResponse` back to the server\n3. If `client_side` is `false`, no client action is needed as the server will handle it internally\n\n### FunctionCallResponse\n\nThe `FunctionCallResponse` message has been updated to include the function name and uses clearer field names:\n\n```code-block text-sm\n\n1{2  \"type\": \"FunctionCallResponse\",3  \"id\": \"fc_12345678-90ab-cdef-1234-567890abcdef\",4  \"name\": \"get_weather\",5  \"content\": \"{\\\"location\\\": \\\"Fremont, CA 94539\\\", \\\"temperature_c\\\": 21, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 40, \\\"wind_kph\\\": 14}\"6}\n```\n\nKey points about `FunctionCallResponse`:\n\n1. It can be sent by either the client or the server depending on where the function was executed\n2. The `id` field links the response to the original request\n3. The `name` field identifies which function was called\n4. The `content` field contains the function result, often in JSON format\n\n### Implementation Tips\n\nWhen migrating your function calling implementation:\n\n1. Update your client code to check the `client_side` flag\n2. Only respond to functions where `client_side` is `true`\n3. Use the `id` field to track which request you’re responding to\n4. Include both the function `name` and `content` in your response\n5. Expect the server to send you `FunctionCallResponse` messages for functions with `client_side: false`\n\n## Migration Checklist\n\n1. ✅ Update WebSocket endpoint URL\n2. ✅ Update configuration message format\n   - Rename `SettingsConfiguration` to `Settings`\n   - Add provider objects for listen, think, and speak\n   - Change `instructions` to `prompt`\n   - Use specific model identifiers\n3. ✅ Update function calling implementation\n   - Adapt to new request/response formats\n   - Implement client\\_side flag handling\n4. ✅ Handle error messages with new format\n   - Use `description` instead of `message`\n   - Process error codes\n5. ✅ Implement support for new message types\n   - Handle `PromptUpdated` and `SpeakUpdated` confirmations\n   - Process `Warning` messages\n6. ✅ Update the `InjectAgentMessage` format\n   - Change `message` field to `content`\n7. ✅ Handle welcome messages with `request_id` instead of `session_id`\n\n## Common Migration Issues\n\n1. **Configuration not accepted**: Make sure you’ve updated to the provider-based structure for capabilities\n2. **Function calls not working**: Update both the request and response formats to match V1 specifications\n3. **Error handling failures**: Update error handling to use `description` instead of `message`\n4. **Cannot inject messages**: Use `content` instead of `message` in `InjectAgentMessage`\n5. **Missing confirmation messages**: Implement handlers for the new confirmation message types\n\n## New Capabilities in V1\n\n1. **Multi-provider support**: Configure different providers for listen, think, and speak capabilities\n2. **Greeting messages**: Set an initial greeting via the `greeting` field\n3. **Improved error handling**: Structured errors with codes for better diagnostics\n4. **Client-side function execution**: Control whether functions run client-side or server-side\n5. **Warnings**: Non-fatal issues are now reported via Warning messages\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=yp75tyyw0frz)",
    "metadata": {
      "description": "Guide for migrating from Voice Agent API Early Access to V1.",
      "title": "Voice Agent API Migration Guide | Deepgram's Docs",
      "og:description": "Guide for migrating from Voice Agent API Early Access to V1.",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "theme-color": "#f5f5f7",
      "ogTitle": "Voice Agent API Migration Guide | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "ogDescription": "Guide for migrating from Voice Agent API Early Access to V1.",
      "generator": "https://buildwithfern.com",
      "og:title": "Voice Agent API Migration Guide | Deepgram's Docs",
      "twitter:title": "Voice Agent API Migration Guide | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "Guide for migrating from Voice Agent API Early Access to V1.",
      "scrapeId": "d4f6288b-8c10-4ba1-ac88-27d5b7ce85fa",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent-v1-migration",
      "url": "https://developers.deepgram.com/docs/voice-agent-v1-migration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Deepgram API Playground\\\\\n\\\\\nTry this feature out in our API Playground.](https://playground.deepgram.com/?endpoint=agent)\n\nIn this guide, you’ll learn how to create a very basic voice agent using Deepgram’s Agent API. Visit the [API Reference](https://developers.deepgram.com/reference/build-a-voice-agent) for more details on how to use the Agent API.\n\nYou will need to migrate to the new _**Voice Agent API V1**_ to continue to use the Voice Agent API. Please refer to the [Voice Agent API Migration Guide](https://developers.deepgram.com/docs/voice-agent-v1-migration) for more information.\n\n## Build a Basic Voice Agent\n\nBefore you start, you’ll need to follow the steps in the [Make Your First API Request](https://developers.deepgram.com/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.\n\n### 1\\. Set up your environment\n\nIn the steps below, you’ll use the Terminal to:\n\n1. Create a new directory for your project\n2. Create a new file for your code\n3. Export your Deepgram API key to the environment so you can use it in your code\n4. Run any additional commands to initialize your project\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n$mkdir deepgram-agent-demo>cd deepgram-agent-demo>touch index.py>export DEEPGRAM_API_KEY=\"your_Deepgram_API_key_here\">@TODO other Python commands\n```\n\n### 2\\. Install the Deepgram SDK\n\nDeepgram has several [SDKs](https://developers.deepgram.com/docs/deepgram-sdks) that can make it easier to build a Voice Agent. Follow these steps below to use one of our SDKs to make your first Deepgram Voice Agent request.\n\nIn your terminal, navigate to the location on your drive where you created your project above, and install the Deepgram SDK and any other dependencies.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n$pip install deepgram-sdk\n```\n\n### 3\\. Import dependencies and set up the main function\n\nNext, import the necessary dependencies and set up your main application function.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1# Import dependencies and set up the main function2import requests3import wave4import io5import time6import os7import json8import threading9from datetime import datetime1011from deepgram import (12  DeepgramClient,13  DeepgramClientOptions,14  AgentWebSocketEvents,15  AgentKeepAlive,16)17from deepgram.clients.agent.v1.websocket.options import SettingsOptions\n```\n\n### 4\\. Initialize the Voice Agent\n\nNow you can initialize the voice agent by creating an empty audio buffer to store incoming audio data, setting up a counter for output file naming, and defining a sample audio file URL. You can then establish a connection to Deepgram and set up a welcome handler to log when the connection is successfully established.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1def main():2  try:3      # Initialize the Voice Agent4      api_key = os.getenv(\"DEEPGRAM_API_KEY\")5      if not api_key:6          raise ValueError(\"DEEPGRAM_API_KEY environment variable is not set\")7      print(f\"API Key found:\")89      # Initialize Deepgram client10      config = DeepgramClientOptions(11          options={12              \"keepalive\": \"true\",13          },14      )15      deepgram = DeepgramClient(api_key, config)16      connection = deepgram.agent.websocket.v(\"1\")17      print(\"Created WebSocket connection...\")1819      # The code in the following steps will go here\n```\n\n### 5\\. Configure the Agent\n\nNext you will need to set up a very simplified version of the [Settings](https://developers.deepgram.com/docs/voice-agent-settings) message to configure your Agent’s behavior and set the required settings options for your Agent.\n\nTo learn more about all settings options available for an Agent, refer to the [Configure the Voice Agent](https://developers.deepgram.com/docs/configure-voice-agent) documentation.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1  # Configure the Agent2      options = SettingsOptions()3      # Audio input configuration4      options.audio.input.encoding = \"linear16\"5      options.audio.input.sample_rate = 240006      # Audio output configuration7      options.audio.output.encoding = \"linear16\"8      options.audio.output.sample_rate = 240009      options.audio.output.container = \"wav\"10      # Agent configuration11      options.agent.language = \"en\"12      options.agent.listen.provider.type = \"deepgram\"13      options.agent.listen.model = \"nova-3\"14      options.agent.think.provider.type = \"open_ai\"15      options.agent.think.model = \"gpt-4o-mini\"16      options.agent.think.prompt = \"You are a friendly AI assistant.\"17      options.agent.speak.provider.type = \"deepgram\"18      options.agent.speak.model = \"aura-2-thalia-en\"19      options.agent.greeting = \"Hello! How can I help you today?\"\n```\n\n### 6\\. Send Keep Alive messages\n\nNext you will send a keep-alive signal every 5 seconds to maintain the WebSocket connection. This prevents the connection from timing out during long audio processing. You will also fetch an audio file from the specified URL [spacewalk.wav](https://dpgr.am/spacewalk.wav) and stream the audio data in chunks to the Agent. Each chunk is sent as it becomes available in the readable stream.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1    # Send Keep Alive messages2      def send_keep_alive():3          while True:4              time.sleep(5)5              print(\"Keep alive!\")6              connection.send(str(AgentKeepAlive()))78      # Start keep-alive in a separate thread9      keep_alive_thread = threading.Thread(target=send_keep_alive, daemon=True)10      keep_alive_thread.start()\n```\n\n### 7\\. Setup Event Handlers and Other Functions\n\nNext you will use this code to set up event handlers for the voice agent to manage the entire conversation lifecycle, from connection opening to closing. It handles audio processing by collecting chunks into a buffer and saving completed responses as WAV files, while also managing interruptions, logging conversations, and handling errors.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1       # Setup Event Handlers2      audio_buffer = bytearray()3      file_counter = 04      processing_complete = False56      def on_audio_data(self, data, **kwargs):7          nonlocal audio_buffer8          audio_buffer.extend(data)9          print(f\"Received audio data from agent: {len(data)} bytes\")10          print(f\"Total buffer size: {len(audio_buffer)} bytes\")11          print(f\"Audio data format: {data[:16].hex()}...\")1213      def on_agent_audio_done(self, agent_audio_done, **kwargs):14          nonlocal audio_buffer, file_counter, processing_complete15          print(f\"AgentAudioDone event received\")16          print(f\"Buffer size at completion: {len(audio_buffer)} bytes\")17          print(f\"Agent audio done: {agent_audio_done}\")18          if len(audio_buffer) > 0:19              with open(f\"output-{file_counter}.wav\", 'wb') as f:20                  f.write(create_wav_header())21                  f.write(audio_buffer)22              print(f\"Created output-{file_counter}.wav\")23          audio_buffer = bytearray()24          file_counter += 125          processing_complete = True2627      def on_conversation_text(self, conversation_text, **kwargs):28          print(f\"Conversation Text: {conversation_text}\")29          with open(\"chatlog.txt\", 'a') as chatlog:30              chatlog.write(f\"{json.dumps(conversation_text.__dict__)}\\n\")3132      def on_welcome(self, welcome, **kwargs):33          print(f\"Welcome message received: {welcome}\")34          with open(\"chatlog.txt\", 'a') as chatlog:35              chatlog.write(f\"Welcome message: {welcome}\\n\")3637      def on_settings_applied(self, settings_applied, **kwargs):38          print(f\"Settings applied: {settings_applied}\")39          with open(\"chatlog.txt\", 'a') as chatlog:40              chatlog.write(f\"Settings applied: {settings_applied}\\n\")4142      def on_user_started_speaking(self, user_started_speaking, **kwargs):43          print(f\"User Started Speaking: {user_started_speaking}\")44          with open(\"chatlog.txt\", 'a') as chatlog:45              chatlog.write(f\"User Started Speaking: {user_started_speaking}\\n\")4647      def on_agent_thinking(self, agent_thinking, **kwargs):48          print(f\"Agent Thinking: {agent_thinking}\")49          with open(\"chatlog.txt\", 'a') as chatlog:50              chatlog.write(f\"Agent Thinking: {agent_thinking}\\n\")5152      def on_agent_started_speaking(self, agent_started_speaking, **kwargs):53          nonlocal audio_buffer54          audio_buffer = bytearray()  # Reset buffer for new response55          print(f\"Agent Started Speaking: {agent_started_speaking}\")56          with open(\"chatlog.txt\", 'a') as chatlog:57              chatlog.write(f\"Agent Started Speaking: {agent_started_speaking}\\n\")5859      def on_close(self, close, **kwargs):60          print(f\"Connection closed: {close}\")61          with open(\"chatlog.txt\", 'a') as chatlog:62              chatlog.write(f\"Connection closed: {close}\\n\")6364      def on_error(self, error, **kwargs):65          print(f\"Error: {error}\")66          with open(\"chatlog.txt\", 'a') as chatlog:67              chatlog.write(f\"Error: {error}\\n\")6869      def on_unhandled(self, unhandled, **kwargs):70          print(f\"Unhandled event: {unhandled}\")71          with open(\"chatlog.txt\", 'a') as chatlog:72              chatlog.write(f\"Unhandled event: {unhandled}\\n\")7374      # Register handlers75      connection.on(AgentWebSocketEvents.AudioData, on_audio_data)76      connection.on(AgentWebSocketEvents.AgentAudioDone, on_agent_audio_done)77      connection.on(AgentWebSocketEvents.ConversationText, on_conversation_text)78      connection.on(AgentWebSocketEvents.Welcome, on_welcome)79      connection.on(AgentWebSocketEvents.SettingsApplied, on_settings_applied)80      connection.on(AgentWebSocketEvents.UserStartedSpeaking, on_user_started_speaking)81      connection.on(AgentWebSocketEvents.AgentThinking, on_agent_thinking)82      connection.on(AgentWebSocketEvents.AgentStartedSpeaking, on_agent_started_speaking)83      connection.on(AgentWebSocketEvents.Close, on_close)84      connection.on(AgentWebSocketEvents.Error, on_error)85      connection.on(AgentWebSocketEvents.Unhandled, on_unhandled)86      print(\"Event handlers registered\")8788      # Start the connection89      print(\"Starting WebSocket connection...\")90      if not connection.start(options):91          print(\"Failed to start connection\")92          return93      print(\"WebSocket connection started successfully\")9495      # Stream audio96      print(\"Downloading and sending audio...\")97      response = requests.get(\"https://dpgr.am/spacewalk.wav\", stream=True)98      # Skip WAV header99      header = response.raw.read(44)100101      # Verify WAV header102      if header[0:4] != b'RIFF' or header[8:12] != b'WAVE':103          print(\"Invalid WAV header\")104          return105106      # Extract sample rate from header107      sample_rate = int.from_bytes(header[24:28], 'little')108109      chunk_size = 8192110      total_bytes_sent = 0111      chunk_count = 0112      for chunk in response.iter_content(chunk_size=chunk_size):113          if chunk:114              print(f\"Sending chunk {chunk_count}: {len(chunk)} bytes\")115              connection.send(chunk)116              total_bytes_sent += len(chunk)117              chunk_count += 1118              time.sleep(0.1)  # Small delay between chunks119120      print(f\"Total audio data sent: {total_bytes_sent} bytes in {chunk_count} chunks\")121      print(\"Waiting for agent response...\")122123      # Wait for processing124      print(\"Waiting for processing to complete...\")125      start_time = time.time()126      timeout = 30  # 30 second timeout127128      while not processing_complete and (time.time() - start_time) < timeout:129          time.sleep(1)130          print(f\"Still waiting for agent response... ({int(time.time() - start_time)}s elapsed)\")131132      if not processing_complete:133          print(\"Processing timed out after 30 seconds\")134      else:135          print(\"Processing complete. Check output-*.wav and chatlog.txt for results.\")136137      # Cleanup138      connection.finish()139      print(\"Finished\")140141  except Exception as e:142      print(f\"Error: {str(e)}\")143144# WAV Header Functions145def create_wav_header(sample_rate=24000, bits_per_sample=16, channels=1):146  \"\"\"Create a WAV header with the specified parameters\"\"\"147  byte_rate = sample_rate * channels * (bits_per_sample // 8)148  block_align = channels * (bits_per_sample // 8)149150  header = bytearray(44)151  # RIFF header152  header[0:4] = b'RIFF'153  header[4:8] = b'\\x00\\x00\\x00\\x00'  # File size (to be updated later)154  header[8:12] = b'WAVE'155  # fmt chunk156  header[12:16] = b'fmt '157  header[16:20] = b'\\x10\\x00\\x00\\x00'  # Subchunk1Size (16 for PCM)158  header[20:22] = b'\\x01\\x00'  # AudioFormat (1 for PCM)159  header[22:24] = channels.to_bytes(2, 'little')  # NumChannels160  header[24:28] = sample_rate.to_bytes(4, 'little')  # SampleRate161  header[28:32] = byte_rate.to_bytes(4, 'little')  # ByteRate162  header[32:34] = block_align.to_bytes(2, 'little')  # BlockAlign163  header[34:36] = bits_per_sample.to_bytes(2, 'little')  # BitsPerSample164  # data chunk165  header[36:40] = b'data'166  header[40:44] = b'\\x00\\x00\\x00\\x00'  # Subchunk2Size (to be updated later)167168  return header169170if __name__ == \"__main__\":171  main()\n\n```\n\n### 7\\. Run the Voice Agent\n\nNow that you have your complete code, you can run the Voice Agent! If it works you should see the conversation text and audio in the files: `output-0.wav` and `chatlog.txt`. These files will be saved in the same directory as your main application file.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1python main.py\n```\n\n### 8\\. Putting it all together\n\nBelow is the final code for the Voice Agent you just built. If you saw any errors after running your Agent, you can compare the code below to the code you wrote in the steps above to find and fix the errors.\n\nPythonJavaScriptC#Go\n\n```code-block text-sm\n\n1# Copyright 2025 Deepgram SDK contributors. All Rights Reserved.2# Use of this source code is governed by a MIT license that can be found in the LICENSE file.3# SPDX-License-Identifier: MIT45# Import dependencies and set up the main function6import requests7import wave8import io9import time10import os11import json12import threading13from datetime import datetime1415from deepgram import (16  DeepgramClient,17  DeepgramClientOptions,18  AgentWebSocketEvents,19  AgentKeepAlive,20)21from deepgram.clients.agent.v1.websocket.options import SettingsOptions2223def main():24  try:25      # Initialize the Voice Agent26      api_key = os.getenv(\"DEEPGRAM_API_KEY\")27      if not api_key:28          raise ValueError(\"DEEPGRAM_API_KEY environment variable is not set\")29      print(f\"API Key found:\")3031      # Initialize Deepgram client32      config = DeepgramClientOptions(33          options={34              \"keepalive\": \"true\",35              # \"speaker_playback\": \"true\",36          },37      )38      deepgram = DeepgramClient(api_key, config)39      connection = deepgram.agent.websocket.v(\"1\")40      print(\"Created WebSocket connection...\")4142      # 4. Configure the Agent43      options = SettingsOptions()44      # Audio input configuration45      options.audio.input.encoding = \"linear16\"46      options.audio.input.sample_rate = 2400047      # Audio output configuration48      options.audio.output.encoding = \"linear16\"49      options.audio.output.sample_rate = 2400050      options.audio.output.container = \"wav\"51      # Agent configuration52      options.agent.language = \"en\"53      options.agent.listen.provider.type = \"deepgram\"54      options.agent.listen.model = \"nova-3\"55      options.agent.think.provider.type = \"open_ai\"56      options.agent.think.model = \"gpt-4o-mini\"57      options.agent.think.prompt = \"You are a friendly AI assistant.\"58      options.agent.speak.provider.type = \"deepgram\"59      options.agent.speak.model = \"aura-2-thalia-en\"60      options.agent.greeting = \"Hello! How can I help you today?\"6162      # Send Keep Alive messages63      def send_keep_alive():64          while True:65              time.sleep(5)66              print(\"Keep alive!\")67              connection.send(str(AgentKeepAlive()))6869      # Start keep-alive in a separate thread70      keep_alive_thread = threading.Thread(target=send_keep_alive, daemon=True)71      keep_alive_thread.start()7273      # Setup Event Handlers74      audio_buffer = bytearray()75      file_counter = 076      processing_complete = False7778      def on_audio_data(self, data, **kwargs):79          nonlocal audio_buffer80          audio_buffer.extend(data)81          print(f\"Received audio data from agent: {len(data)} bytes\")82          print(f\"Total buffer size: {len(audio_buffer)} bytes\")83          print(f\"Audio data format: {data[:16].hex()}...\")8485      def on_agent_audio_done(self, agent_audio_done, **kwargs):86          nonlocal audio_buffer, file_counter, processing_complete87          print(f\"AgentAudioDone event received\")88          print(f\"Buffer size at completion: {len(audio_buffer)} bytes\")89          print(f\"Agent audio done: {agent_audio_done}\")90          if len(audio_buffer) > 0:91              with open(f\"output-{file_counter}.wav\", 'wb') as f:92                  f.write(create_wav_header())93                  f.write(audio_buffer)94              print(f\"Created output-{file_counter}.wav\")95          audio_buffer = bytearray()96          file_counter += 197          processing_complete = True9899      def on_conversation_text(self, conversation_text, **kwargs):100          print(f\"Conversation Text: {conversation_text}\")101          with open(\"chatlog.txt\", 'a') as chatlog:102              chatlog.write(f\"{json.dumps(conversation_text.__dict__)}\\n\")103104      def on_welcome(self, welcome, **kwargs):105          print(f\"Welcome message received: {welcome}\")106          with open(\"chatlog.txt\", 'a') as chatlog:107              chatlog.write(f\"Welcome message: {welcome}\\n\")108109      def on_settings_applied(self, settings_applied, **kwargs):110          print(f\"Settings applied: {settings_applied}\")111          with open(\"chatlog.txt\", 'a') as chatlog:112              chatlog.write(f\"Settings applied: {settings_applied}\\n\")113114      def on_user_started_speaking(self, user_started_speaking, **kwargs):115          print(f\"User Started Speaking: {user_started_speaking}\")116          with open(\"chatlog.txt\", 'a') as chatlog:117              chatlog.write(f\"User Started Speaking: {user_started_speaking}\\n\")118119      def on_agent_thinking(self, agent_thinking, **kwargs):120          print(f\"Agent Thinking: {agent_thinking}\")121          with open(\"chatlog.txt\", 'a') as chatlog:122              chatlog.write(f\"Agent Thinking: {agent_thinking}\\n\")123124      def on_agent_started_speaking(self, agent_started_speaking, **kwargs):125          nonlocal audio_buffer126          audio_buffer = bytearray()  # Reset buffer for new response127          print(f\"Agent Started Speaking: {agent_started_speaking}\")128          with open(\"chatlog.txt\", 'a') as chatlog:129              chatlog.write(f\"Agent Started Speaking: {agent_started_speaking}\\n\")130131      def on_close(self, close, **kwargs):132          print(f\"Connection closed: {close}\")133          with open(\"chatlog.txt\", 'a') as chatlog:134              chatlog.write(f\"Connection closed: {close}\\n\")135136      def on_error(self, error, **kwargs):137          print(f\"Error: {error}\")138          with open(\"chatlog.txt\", 'a') as chatlog:139              chatlog.write(f\"Error: {error}\\n\")140141      def on_unhandled(self, unhandled, **kwargs):142          print(f\"Unhandled event: {unhandled}\")143          with open(\"chatlog.txt\", 'a') as chatlog:144              chatlog.write(f\"Unhandled event: {unhandled}\\n\")145146      # Register handlers147      connection.on(AgentWebSocketEvents.AudioData, on_audio_data)148      connection.on(AgentWebSocketEvents.AgentAudioDone, on_agent_audio_done)149      connection.on(AgentWebSocketEvents.ConversationText, on_conversation_text)150      connection.on(AgentWebSocketEvents.Welcome, on_welcome)151      connection.on(AgentWebSocketEvents.SettingsApplied, on_settings_applied)152      connection.on(AgentWebSocketEvents.UserStartedSpeaking, on_user_started_speaking)153      connection.on(AgentWebSocketEvents.AgentThinking, on_agent_thinking)154      connection.on(AgentWebSocketEvents.AgentStartedSpeaking, on_agent_started_speaking)155      connection.on(AgentWebSocketEvents.Close, on_close)156      connection.on(AgentWebSocketEvents.Error, on_error)157      connection.on(AgentWebSocketEvents.Unhandled, on_unhandled)158      print(\"Event handlers registered\")159160      # Start the connection161      print(\"Starting WebSocket connection...\")162      if not connection.start(options):163          print(\"Failed to start connection\")164          return165      print(\"WebSocket connection started successfully\")166167      # Stream audio168      print(\"Downloading and sending audio...\")169      response = requests.get(\"https://dpgr.am/spacewalk.wav\", stream=True)170      # Skip WAV header171      header = response.raw.read(44)172173      # Verify WAV header174      if header[0:4] != b'RIFF' or header[8:12] != b'WAVE':175          print(\"Invalid WAV header\")176          return177178      # Extract sample rate from header179      sample_rate = int.from_bytes(header[24:28], 'little')180181      chunk_size = 8192182      total_bytes_sent = 0183      chunk_count = 0184      for chunk in response.iter_content(chunk_size=chunk_size):185          if chunk:186              print(f\"Sending chunk {chunk_count}: {len(chunk)} bytes\")187              connection.send(chunk)188              total_bytes_sent += len(chunk)189              chunk_count += 1190              time.sleep(0.1)  # Small delay between chunks191192      print(f\"Total audio data sent: {total_bytes_sent} bytes in {chunk_count} chunks\")193      print(\"Waiting for agent response...\")194195      # Wait for processing196      print(\"Waiting for processing to complete...\")197      start_time = time.time()198      timeout = 30  # 30 second timeout199200      while not processing_complete and (time.time() - start_time) < timeout:201          time.sleep(1)202          print(f\"Still waiting for agent response... ({int(time.time() - start_time)}s elapsed)\")203204      if not processing_complete:205          print(\"Processing timed out after 30 seconds\")206      else:207          print(\"Processing complete. Check output-*.wav and chatlog.txt for results.\")208209      # Cleanup210      connection.finish()211      print(\"Finished\")212213  except Exception as e:214      print(f\"Error: {str(e)}\")215216# WAV Header Functions217def create_wav_header(sample_rate=24000, bits_per_sample=16, channels=1):218  \"\"\"Create a WAV header with the specified parameters\"\"\"219  byte_rate = sample_rate * channels * (bits_per_sample // 8)220  block_align = channels * (bits_per_sample // 8)221222  header = bytearray(44)223  # RIFF header224  header[0:4] = b'RIFF'225  header[4:8] = b'\\x00\\x00\\x00\\x00'  # File size (to be updated later)226  header[8:12] = b'WAVE'227  # fmt chunk228  header[12:16] = b'fmt '229  header[16:20] = b'\\x10\\x00\\x00\\x00'  # Subchunk1Size (16 for PCM)230  header[20:22] = b'\\x01\\x00'  # AudioFormat (1 for PCM)231  header[22:24] = channels.to_bytes(2, 'little')  # NumChannels232  header[24:28] = sample_rate.to_bytes(4, 'little')  # SampleRate233  header[28:32] = byte_rate.to_bytes(4, 'little')  # ByteRate234  header[32:34] = block_align.to_bytes(2, 'little')  # BlockAlign235  header[34:36] = bits_per_sample.to_bytes(2, 'little')  # BitsPerSample236  # data chunk237  header[36:40] = b'data'238  header[40:44] = b'\\x00\\x00\\x00\\x00'  # Subchunk2Size (to be updated later)239240  return header241242if __name__ == \"__main__\":243  main()\n\n```\n\n## Implementation Examples\n\nTo better understand how to build a more complex Voice Agent, check out the following examples for working code.\n\n| Use Case | Runtime / Language | Repo |\n| --- | --- | --- |\n| Voice agent basic demo | Node, TypeScript, JavaScript | [Deepgram Voice Agent Demo](https://github.com/deepgram-devs/deepgram-voice-agent-demo) |\n| Voice agent medical assistant demo | Node, TypeScript, JavaScript | [Deepgram Voice Agent Medical Assistant Demo](https://github.com/deepgram-devs/voice-agent-medical-assistant-demo) |\n| Voice agent demo with Twilio | Python | [Python Twilio > Voice Agent Demo](https://developers.deepgram.com/docs/twilio-and-deepgram-voice-agent) |\n| Voice agent demo with text input | Node, TypeScript, JavaScript | [Deepgram Conversational AI Demo](https://github.com/deepgram-devs/deepgram-ai-agent-demo) |\n| Voice agent with Azure Open AI Services | Python | [Deepgram Voice Agent with OpenAI Azure](https://github.com/deepgram-devs/voice-agent-azure-open-ai-services) |\n| Voice agent with Function Calling using Python Flask | Python / Flask | [Python Flask Agent Function Calling Demo](https://github.com/deepgram-devs/flask-agent-function-calling-demo) |\n|  |  |  |\n\n## Rate Limits\n\nFor information on Deepgram’s Concurrency Rate Limits, refer to our [API Rate Limits Documentation](https://developers.deepgram.com/reference/api-rate-limits).\n\n## Usage Tracking\n\nUsage is calculated based on websocket connection time. 1 hour of websocket connection time = 1 hour of API usage.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=s4yqogwbs0tp)",
    "metadata": {
      "og:title": "Getting Started | Deepgram's Docs",
      "title": "Getting Started | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "description": "An introduction to using Deepgram's Voice Agent API to build interactive voice agents.",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Getting Started | Deepgram's Docs",
      "ogDescription": "An introduction to using Deepgram's Voice Agent API to build interactive voice agents.",
      "ogTitle": "Getting Started | Deepgram's Docs",
      "og:description": "An introduction to using Deepgram's Voice Agent API to build interactive voice agents.",
      "twitter:description": "An introduction to using Deepgram's Voice Agent API to build interactive voice agents.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "scrapeId": "e212bf44-6694-4762-9443-b1b7ad62e420",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agent",
      "url": "https://developers.deepgram.com/docs/voice-agent",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Voice Agent\n\nFunction calling is the ability of large language models (LLMs) to invoke external functions or APIs in response to user queries. For example, if a user asks for the current weather in a specific location, the LLM can use function calling to call a weather API, fetch real-time data, and present it in a structured response.\n\nThis capability allows LLMs to enhance their functionality by integrating with other systems, services, or databases to provide real-time data, perform specific tasks, or trigger actions.\n\n## How Function Calling Works\n\n- **User Query**: A user asks the LLM something that requires external data or specific action (e.g., “Check the weather in New York” or “Book an appointment”).\n- **Function Identification:** The LLM identifies that the query requires a specific function to be called. For instance, if the user asks for the weather, the model recognizes that it needs to call a weather API rather than generate a general response.\n- **Parameter Extraction:** The LLM analyzes the user’s query to extract the required parameters (e.g., location, date, or other variables). For example, in the weather query, “New York” would be extracted as the location parameter.\n- **Call the Function:** The LLM triggers an external function or API with the appropriate parameters. This could involve fetching live data, performing a task (e.g., making a booking), or retrieving information that is outside the LLM’s static knowledge.\n- **Return the Result:** The function returns the result (such as the current weather data), which the LLM incorporates into its response back to the user.\n\n![Function Calling Flow Diagram](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Ffunction_call_flow_chart.png&w=1080&q=75)\n\n## Configuring Function Calling\n\nBelow is an example of the `Settings` message with the `agent.think` configuration object that includes function calling capabilities. To see a complete example of the `Settings` message, see the [Configure the Voice Agent](https://developers.deepgram.com/docs/configure-voice-agent) documentation.\n\nJSON\n\n```code-block text-sm\n\n1{2  \"type\": \"Settings\",3  ...// other settings fields4  \"agent\": {5      \"think\": {6      \"provider\": {7        \"type\": \"open_ai\",8        \"model\": \"gpt-4\",9        \"temperature\": 0.710      },11      \"endpoint\": { // Optional for non-Deepgram LLM providers. When present, must include url field and headers object12        \"url\": \"https://api.example.com/llm\",13        \"headers\": {14          \"authorization\": \"Bearer {{token}}\"15        }16      },17      \"prompt\": \"You are a helpful AI assistant focused on customer service.\",18      \"functions\": [19        {20          \"name\": \"check_order_status\",21          \"description\": \"Check the status of a customer order\",22          \"parameters\": {23            \"type\": \"object\",24            \"properties\": {25              \"order_id\": {26                \"type\": \"string\",27                \"description\": \"The order ID to check\"28              }29            },30            \"required\": [\"order_id\"]31          },32          \"endpoint\": { // If not provided, function is called client-side33            \"url\": \"https://api.example.com/orders/status\",34            \"method\": \"post\",35            \"headers\": {36              \"authorization\": \"Bearer {{token}}\"37            }38          }39        }40      ]41    }42  }43}\n\n```\n\n## Client-Side Function Calling\n\nIf your function will run client-side and you do not need to make a request to a server, you will not need to use the endpoint object and do not need to provide the `url`, `headers`, or `method` fields.\n\nJSON\n\n```code-block text-sm\n\n1{2\"type\": \"Settings\",3...// other settings fields4\"agent\": {5    \"prompt\": \"You are a helpful AI assistant that can provide weather information.\",6    \"functions\": [7      {8        \"name\": \"get_weather\",9        \"description\": \"Get the current weather for a specific location\",10        \"parameters\": {11          \"type\": \"object\",12          \"properties\": {13            \"location\": {14              \"type\": \"string\",15              \"description\": \"The city or location to get weather for\"16            }17          },18          \"required\": [\"location\"]19        }20      }21    ]22  }23}24}25...// other settings fields\n\n```\n\nIn this example code below, the `get_weather` function gets triggered when someone asks the Agent about the weather in a particular place.\n\nJavaScriptPythonC#Go\n\n```code-block text-sm\n\n1import os2import requests3from typing import Optional45def get_weather(location: str) -> Optional[str]:6  api_key = os.getenv(\"OPENWEATHER_API_KEY\")78  try:9      response = requests.get(10          f\"https://api.openweathermap.org/data/2.5/weather\",11          params={\"q\": location, \"appid\": api_key}12      )13      response.raise_for_status()1415      data = response.json()16      return f\"The current weather in {data['name']} is {data['weather'][0]['description']} with a temperature of {data['main']['temp']}°K.\"17  except Exception as err:18      print(f\"Error: {err}\")19      return None\n```\n\n# Function Calling Message Flow\n\n2 types of Function calling messages are exchanged between the client and Deepgram’s Voice Agent API server through a websocket.\n\nA [`FunctionCallRequest`](https://developers.deepgram.com/docs/voice-agent-function-call-request) message is used to initiate function calls in your Voice Agent. This message can trigger either a server-side function execution or request a client-side function execution, depending on the client\\_side property setting.\n\nA [`FunctionCallResponse`](https://developers.deepgram.com/docs/voice-agent-function-call-response) can be sent by the client or server. When sent from the client it is a response to a function call, but when sent from the server it is information about a function call that was requested by the agent.\n\nBelow is an example of a function call message flow based on the `get_weather` function example above.\n\n1. User submits a query → The agent determines a function is needed.\n2. Server sends a `FunctionCallRequest` → Requests function execution.\n3. Client executes the function and sends a `FunctionCallResponse` → Returns the function result.\n4. Server uses the response.\n5. The agent continues the conversation.\n\nClientServerAgentUserClientServerAgentUserExecutes get\\_weather functionAsks about weatherDetermines function neededSends FunctionCallRequestSends FunctionCallResponseProcesses responseProvides weather information\n\n* * *\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=cc01fca1-db69-4cdf-ab34-b7b649e6c125&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=d5c6632d-19b9-4c69-8873-12ce60e4063e&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fvoice-agents-function-calling&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=cc01fca1-db69-4cdf-ab34-b7b649e6c125&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=d5c6632d-19b9-4c69-8873-12ce60e4063e&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fdocs%2Fvoice-agents-function-calling&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n![Function Calling Flow Diagram](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Ffunction_call_flow_chart.png&w=1080&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=q3h493c3ywpj)",
    "metadata": {
      "language": "en",
      "og:description": "Overview of Function Calling with Voice Agents.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "title": "Function Calling | Deepgram's Docs",
      "ogTitle": "Function Calling | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:description": "Overview of Function Calling with Voice Agents.",
      "application-name": "Deepgram's Docs",
      "description": "Overview of Function Calling with Voice Agents.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogDescription": "Overview of Function Calling with Voice Agents.",
      "twitter:title": "Function Calling | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "og:title": "Function Calling | Deepgram's Docs",
      "scrapeId": "2c6558cf-75c3-480b-a05b-96424f5a8eb5",
      "sourceURL": "https://developers.deepgram.com/docs/voice-agents-function-calling",
      "url": "https://developers.deepgram.com/docs/voice-agents-function-calling",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Overview\n\nDeepgram’s APIs offer powerful capabilities for [speech-to-text](https://developers.deepgram.com/docs/getting-started-with-pre-recorded-audio) and [text-to-speech](https://developers.deepgram.com/docs/text-to-speech) as well as [audio intelligence](https://developers.deepgram.com/docs/audio-intelligence) and [text intelligence](https://developers.deepgram.com/docs/text-intelligence). To ensure all users receive consistent and predictable service, and to prevent accidental misuse, Deepgram enforces concurrency and rate limits on API usage. This guide will help you understand these limits, how to work within them, and strategies to maximize your usage without hitting your limits.\n\nAPI concurrency rate limits protect your applications and services built on Deepgram from abuse or failure.\n\n## Working with Concurrency Rate Limits\n\nConcurrency limits define the maximum number of simultaneous API requests you can make. Understanding these limits is crucial for applications that require high throughput.\n\nFor information on Deepgram’s Concurrency Rate Limits, refer to our [API Rate Limits Documentation](https://developers.deepgram.com/reference/api-rate-limits).\n\n### Managing Concurrency\n\nWhen using the Deepgram Speech-to-Text API, you might need to process multiple audio files simultaneously.\n\nIn this scenario, you must ensure your application doesn’t exceed the concurrency limits. Implementing a queue system can help manage requests efficiently, ensuring no more than the allowed number of concurrent requests are sent to the Deepgram API.\n\n### Considering Concurrency Rate Limits\n\nConcurrency rate limits define the maximum number of API requests you can make in a given time frame. These limits help maintain service quality and prevent abuse. Deepgram doesn’t restrict the number of requests you can send in a given time span, only the number of concurrent requests you can make.\n\nFor information on Deepgram’s Concurrency Rate Limits, refer to our [API Rate Limits Documentation](https://developers.deepgram.com/reference/api-rate-limits).\n\n### Calculation of Concurrency Rate Limits\n\nConcurrency rate limits are typically expressed as the number of requests per minute (RPM). For instance, if your plan allows 480 requests per minute, you can distribute these requests evenly across the minute.\n\n### Handling Rate Limits\n\nTo avoid hitting rate limits, consider the following strategies:\n\n1. **Rate Limiting Middleware**: Implement middleware in your application to throttle requests, ensuring they do not exceed the allowed rate.\n2. **Exponential Backoff**: Use an exponential backoff strategy to retry requests after hitting a rate limit, gradually increasing the delay between retries. An exponential-backoff strategy introduces a delay before each retry attempt. The delay between retries increases exponentially with each consecutive failure, helping to mitigate the impact of transient errors and reduce the likelihood of overwhelming the system with retries.\n3. **Monitor Usage**: Regularly monitor your API usage to anticipate and adjust to usage patterns.\n\n## Other Considerations\n\n### What Happens if You Hit Your Concurrency Rate Limits?\n\nIf you exceed your rate limits, the API will return a `429: Too Many Requests` error. This error indicates that your project has more concurrent requests than allowed. To learn more, see the [Deepgram Error Documentation](https://developers.deepgram.com/reference/errors#429-rate-limit-exceeded-1).\n\n### Can You Increase Your Concurrency Rate Limits?\n\n- Users on Pay As You Go and Growth plans cannot have their limits increased.\n- New and existing Enterprise customers can request an increase by discussing your needs with the [Deepgram Sales Team.](https://deepgram.com/contact-us)\n\n## Getting Help\n\nIf you encounter issues with concurrency or rate limits, Deepgram offers several support options:\n\n- **Community Support**: Join the [Deepgram Discord community](https://discord.gg/xWRaCDBtW4) or participate in [GitHub Discussions](https://github.com/orgs/deepgram/discussions) for assistance.\n- **Enterprise Support**: Enterprise plan subscribers can reach out to the support team via email or Slack for dedicated support.\n\n* * *\n\nWhat’s Next\n\n- [API Rate Limits](https://developers.deepgram.com/reference/api-rate-limits)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=j2su3990bxga)",
    "metadata": {
      "title": "Working With Concurrency Rate Limits | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "twitter:description": "Learn how to better handle concurrency rate limit issues when using Deepgram.",
      "ogDescription": "Learn how to better handle concurrency rate limit issues when using Deepgram.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Working With Concurrency Rate Limits | Deepgram's Docs",
      "og:description": "Learn how to better handle concurrency rate limit issues when using Deepgram.",
      "application-name": "Deepgram's Docs",
      "description": "Learn how to better handle concurrency rate limit issues when using Deepgram.",
      "twitter:title": "Working With Concurrency Rate Limits | Deepgram's Docs",
      "language": "en",
      "ogTitle": "Working With Concurrency Rate Limits | Deepgram's Docs",
      "scrapeId": "493a829c-61c3-4b7e-8b70-6380246e5f07",
      "sourceURL": "https://developers.deepgram.com/docs/working-with-concurrency-rate-limits",
      "url": "https://developers.deepgram.com/docs/working-with-concurrency-rate-limits",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Zapier](https://zapier.com/) is an online automation tool that allows you to connect your favorite apps, such as Amazon S3, Zoom, Deepgram, and more. It enables you to automate tasks between them, without having to write any code.\n\n## Introduction to Zapier\n\nZapier workflows are called “Zaps.” A Zap is a connection between two apps made up of a trigger and one or more actions.\n\nHere’s how it works:\n\n1. Trigger: An event in one app that starts the Zap. For example, receiving a new voicemail, recording a new meeting in a video conference software program, or uploading a video of a lecture.\n2. Action: An event that completes the Zap. It’s the result or output you want to achieve, such as transcribing a new voicemail to text, converting a recorded meeting to written notes, or generating a summary text document from a spoken lecture.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fc9a12a1-trigger_action.png&w=1920&q=75)\n\nAn example Zap could be the following:\n\nAdd an audio file to a folder in Dropbox (Trigger) -> Transcribe the file with Deepgram (Action) -> Add a text file with the transcription to another folder in Dropbox (Action).\n\nCurrently, Deepgram offers these actions in Zapier:\n\n1. Create Transcription (Plain Text)\n2. Create Summary\n3. Create Deepgram API Request (Speech-To-Text)\n4. Create Transcription (Callback)\n\nTo use the Create Transcription (Callback) integration, you will need to deploy a server to handle the callback response. This approach is best if you want to automate the transcription of files larger than approximately 200MB. You can find a step-by-step tutorial explaining how to do this in the [Deepgram Blog](https://deepgram.com/learn/no-more-zapier-timeouts-transcribe-large-audio-files-with-deepgram-and-zapier-s-w).\n\n## How to Build a Workflow in Zapier\n\n### Create a Zap\n\nTo create a Zap, click on the “Create Zap” button in the left-side navigation bar. This will create a starter zap with a trigger and an action.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F5a142f0-starter_zap.png&w=3840&q=75)\n\n### Set up the Trigger\n\nClick into the first box to change the trigger. A Zap must start with a trigger. The trigger starts off the workflow with an initial trigger event.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F20d4e85-change_trigger.png&w=3840&q=75)\n\nThe Deepgram integration cannot be used as a trigger event so you should choose a different integration to be the trigger.\n\nExample triggers with Deepgram actions could be:\n\n| Trigger | Action |\n| --- | --- |\n| New Recording is Completed in Zoom | Deepgram transcribes the recording into a text transcript |\n| New Recording in Twilio | Deepgram summarizes the content of the message |\n| New Audio File in Dropbox | Deepgram makes an API request and returns a JSON response including the transcription, diarization, or any other features available in the API |\n\nConfigure the trigger with your chosen integration (Amazon S3, Dropbox, etc.). Integrations may use OAuth to authenticate automatically, or you may have to enter an API key.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F0397791-sign_in.png&w=3840&q=75)\n\nOnce your trigger has been set up, you can add actions.\n\n### Configure a Deepgram Action\n\nClick into the action box to configure it to use Deepgram.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Ff8629d3-configure_deepgram.png&w=3840&q=75)\n\nConnect to your Deepgram account by adding your API key.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F57500c0-add_api_key.png&w=3840&q=75)\n\nAfter successfully connecting your account, you will select your configuration options in the form. Be sure to add a publicly accessible URL as the audio file to transcribe.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F09d6f06-config_options.png&w=3840&q=75)\n\nDeepgram’s Zapier integration only accepts a publicly accessible URL audio file. If you need to convert raw audio to a URL, we recommend using the [Cloud Convert integration](https://www.make.com/en/integrations/cloudconvert) to convert the audio file to a URL.\n\nYou can test the workflow by clicking “Test Step”. This will run the workflow, and then you should see a transcription response that looks similar to this:\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fded312a-test_step.png&w=3840&q=75)\n\nIf you add another action after your Deepgram action, you can use the transcript in that following action.\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F0b6faab-use_transcript.png&w=3840&q=75)\n\nClick “Publish” in the final step to publish your zap.\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fc9a12a1-trigger_action.png&w=1920&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F5a142f0-starter_zap.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F20d4e85-change_trigger.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F0397791-sign_in.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Ff8629d3-configure_deepgram.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F57500c0-add_api_key.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F09d6f06-config_options.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2Fded312a-test_step.png&w=3840&q=75)\n\n![](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Fdeepgram.docs.buildwithfern.com%2F2025-05-23T23%3A08%3A50.550Z%2Fimages%2F0b6faab-use_transcript.png&w=3840&q=75)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=a8mousg9b40h)",
    "metadata": {
      "ogTitle": "Zapier and Deepgram | Deepgram's Docs",
      "description": "Learn how to use Deepgram in Zapier automated workflows.",
      "og:description": "Learn how to use Deepgram in Zapier automated workflows.",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Zapier and Deepgram | Deepgram's Docs",
      "language": "en",
      "title": "Zapier and Deepgram | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "Learn how to use Deepgram in Zapier automated workflows.",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "og:title": "Zapier and Deepgram | Deepgram's Docs",
      "ogDescription": "Learn how to use Deepgram in Zapier automated workflows.",
      "application-name": "Deepgram's Docs",
      "scrapeId": "5546ac4c-6381-43c2-a70d-1a6a99f81f5a",
      "sourceURL": "https://developers.deepgram.com/docs/zapier-integration",
      "url": "https://developers.deepgram.com/docs/zapier-integration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Overview\n\nYour Deepgram account is structured into projects. Each project consists of a set of users, a set of API keys, and billing and monitoring for Deepgram Services.\n\nProjects in Deepgram are completely distinct environments with no connection to one another. Projects have unique access to Deepgram models, features, and services. To learn about scenarios in which it would be best to set up multiple projects, see [Using Multiple Projects](https://developers.deepgram.com/docs/using-multiple-projects).\n\nWhen you sign up, we automatically create a Project for you. Any promotional credit you have earned is attached to this first project. If you would like to transfer your promotional balance to a new project, [contact Support](https://developers.deepgram.com/support).\n\nYou can manage your Projects using either the [Deepgram Console](https://console.deepgram.com/) or the [Deepgram API](https://developers.deepgram.com/reference/get-projects).\n\n## When to Create New Projects\n\nIn many cases, the first project that comes with your Deepgram account will be sufficient for your needs. However, there are a couple scenarios where creating a separate project makes sense. Here are a couple of examples:\n\n- Creating one project for personal use and another for business use.\n- Using one project with one team and another project with a different team.\n\n## Manage your Project\n\n## Rename a Project\n\nTo change a project’s name:\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project that you want to rename.\n\n3. Select **Settings**.\n\n4. Enter a new **Project Name** for your project, and select **Update**.\n\n\nThe selected Project has been renamed.\n\n## Manage Team Members\n\nAfter you have created a Project, you can invite Team Members who you can let create transcripts for your Project, monitor Project balances and usage, or even manage other Team Members and create API Keys. You control what actions a Team Member can perform by assigning them a Role.\n\n### Invite a Team Member\n\nWhen you invite a Team Member, you assign them a Role, which determines which actions they can perform in the associated Project. Deepgram uses a tiered system of access control to provide granular access to its endpoints. To learn more about roles, see [Working with Roles](https://developers.deepgram.com/docs/working-with-roles). You can change the role for a user at any time.\n\nTo invite a Team Member to your Project:\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project to which you want to invite a Team Member.\n\n3. Select **Settings**.\n\n4. Select the **Team Members** view.\n\n5. Select **Invite New Member**.\n\n6. Enter the following settings, and select **Send Invites**:\n\n\n| Name | Description |\n| --- | --- |\n| **Email Address(es)** | Email address(es) to which you want to send invitations for the selected Project. |\n| **Role** | Role to assign to the Team Member. The Team Member may perform only the actions allowed by the permissions associated with this role. To learn more about roles, see [Working with Roles](https://developers.deepgram.com/docs/working-with-roles). |\n\nDeepgram has sent your invitations via email. To access your Project, the Team Members must accept the invitation using the email address to which it was originally sent.\n\n### Resend Invitation to a Team Member\n\nWhen you invite a user to your Project, Deepgram sends them an invitation via email. To access your Project, they must accept the invitation. If they don’t receive the invitation, you can resend it.\n\nTo resend an invitation:\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project with which the Team Member is associated.\n\n3. Select **Settings**.\n\n4. Select the **Team Members** view.\n\n5. Locate the user to whom you want to resend an invitation. Users with unaccepted invitations will have only their email address populated.\n\n6. Select **Resend Invitation**.\n\n\nThe user’s invitation has been resent via email.\n\n### Change a Team Member Role\n\nTo change the role for a Team Member:\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project with which the Team Member is associated.\n\n3. Select **Settings**.\n\n4. Select the **Team Members** view.\n\n5. Locate the Team Member who you want to edit, and select their role from the **Role** column.\n\n6. Select a new role.\n\n\nThe Team Member’s role in your Project has been updated.\n\n### Remove a Team Member\n\nTo remove a Team Member:\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project with which the Team Member is associated.\n\n3. Select **Settings**.\n\n4. Select the **Team Members** view.\n\n5. Locate the Team Member to remove, and select the associated trash can icon.\n\n\nThe Team Member has been removed from your Project.\n\n## Manage API Keys\n\nDeepgram’s API uses API Keys to authenticate requests. You can view and manage your API Keys in the [Deepgram Console](https://console.deepgram.com/) or through the [Deepgram API](https://developers.deepgram.com/reference/list-keys).\n\nYour API keys grant many privileges, so be sure to keep them secure. Do not share your secret API keys in publicly accessible areas such as GitHub or client-side code.\n\nFor best results, use different API Keys for testing and production. To help filter usage, you can also use different API Keys for different consumers or teams at your organization.\n\n### API Keys & Projects\n\nAPI keys are generated by an account within the scope of a specific project. To continue using the API key, the account that created it must remain part of that project. Additionally, the key cannot be used outside the context of its original project.\n\nIf the account that created the key is removed from the project or deleted, the API key becomes invalid.\n\n### Create an API Key\n\nWhen you create an API Key, you assign it a Role, which determines which actions it can be used to perform in the associated Project. Deepgram uses a tiered system of access control to provide granular access to its endpoints. To learn more about roles, see [Working with Roles](https://developers.deepgram.com/docs/working-with-roles).\n\nTo learn more about creating API Keys and see examples of how to use them with our API, see [Authenticating](https://developers.deepgram.com/docs/authenticating).\n\n### Delete an API Key\n\n1. Log in to the [Deepgram Console](https://console.deepgram.com/).\n\n2. From the **Projects** dropdown on the top-left, select the Project in which you want to delete an API Key.\n\n3. Select **Settings**.\n\n4. Select the **API Keys** view.\n\n5. Locate the API Key to delete, and select the associated trash can icon.\n\n\nThe API Key has been removed from your Project.\n\n## Manage Billing\n\nProjects are assigned credits, which determine how many transactions can be performed for the associated Project.\n\nIn certain cases, credits may expire:\n\n- Credits associated with an enterprise contract expire at the end of the contract period.\n- Deepgram free promotional credits expire one year from signup.\n\nCredits purchased by individuals using a credit card do not expire.\n\nIf you would like to transfer your credit balance to another project, [contact Support](https://developers.deepgram.com/support). When credits are transferred, any associated expiration date also transfers.\n\n### Serving Multiple Clients Under a Single Project\n\nMany users of Deepgram are businesses serving other businesses. You can use a single Deepgram project to serve each of your customers and even tag their respective usage.\n\nDeepgram allows you to tag your API Keys and/or individual requests. You can then rely on those tags to filter usage and bill your customers accordingly.\n\nFor example, say Fruit Company has customers Apple, Banana, and Pear. Fruit Company can have a single Deepgram project, but create 3 API Keys:\n\n1. Production Key ( `tag=apple`)\n2. Production Key ( `tag=banana`)\n3. Production Key ( `tag=pear`)\n\nAt the end of the month, Fruit Company can rely on those tags to correctly bill Apple, Banana, and Pear for their respective usage.\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=5swee975e7ho)",
    "metadata": {
      "language": "en",
      "ogDescription": "Learn about Deepgram Projects, which organize all of your Deepgram resources and consist of a set of users, a set of API Keys, and billing and monitoring settings.",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "og:title": "Managing Projects | Deepgram's Docs",
      "twitter:description": "Learn about Deepgram Projects, which organize all of your Deepgram resources and consist of a set of users, a set of API Keys, and billing and monitoring settings.",
      "twitter:title": "Managing Projects | Deepgram's Docs",
      "title": "Managing Projects | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "description": "Learn about Deepgram Projects, which organize all of your Deepgram resources and consist of a set of users, a set of API Keys, and billing and monitoring settings.",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Learn about Deepgram Projects, which organize all of your Deepgram resources and consist of a set of users, a set of API Keys, and billing and monitoring settings.",
      "ogTitle": "Managing Projects | Deepgram's Docs",
      "scrapeId": "d8a74eb5-1883-4869-be2b-92941209f5cb",
      "sourceURL": "https://developers.deepgram.com/guides/deep-dives/managing-projects",
      "url": "https://developers.deepgram.com/guides/deep-dives/managing-projects",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Overview\n\nIn Deepgram, projects are completely distinct environments with no connection to one another. Projects have unique access to Deepgram models, features, and services.\n\nYou can manage your Projects using either the [Deepgram Console](https://console.deepgram.com/) or the [Deepgram API](https://developers.deepgram.com/reference/get-projects). To learn more about Projects, see [Managing Projects](https://developers.deepgram.com/docs/managing-projects).\n\nIn many cases, our users find that a single project is enough, but in certain scenarios, you may want to set up multiple projects.\n\n## Your First Project\n\nWhen you sign up, we automatically create a Project for you.\n\nAny promotional credit you have earned is attached to this first project. If you would like to transfer your promotional balance to a new project, [contact Support](https://developers.deepgram.com/support).\n\n## When to Create New Projects\n\nIn many cases, the first project that comes with your Deepgram account will be sufficient for your needs. However, depending on the different users you support, you may prefer to set up additional projects. Some examples include:\n\n- You have two separate use cases for Deepgram products—one that involves a personal project and one that involves a completely unrelated business project.\n\n- You have multiple, unrelated business projects, which are managed by different business teams or under different cost centers.\n\n- You operate a business-to-business (B2B) model that focuses on selling products and services to other companies and have separate teams that handle individual customers. You may also want to create a separate project to track your customers’ usage data separately for billing purposes, although this can also be accomplished using a single project.\n\n\n## Serving Multiple Customers With a Single Project\n\nMany Deepgram users are businesses serving other businesses. In this scenario, you may want to create separate projects for each of your customers to see their usage, but you don’t have to—you can use a single Deepgram project to serve all of your customers and still separate out customer usage.\n\nTo do this, you must [create a separate API Key for each customer and tag it](https://developers.deepgram.com/docs/authenticating#create-an-api-key) with the customer’s information. You can then rely on the API Key tag to filter usage down to the individual request and bill your customer accordingly.\n\nFor example, say Fruit Company has customers Apple, Banana, and Pear. Fruit Company can have a single Deepgram project, but create three API Keys:\n\n1. Production Key ( `tag=apple`)\n2. Production Key ( `tag=banana`)\n3. Production Key ( `tag=pear`)\n\nAt the end of the month, Fruit Company can rely on those tags to correctly bill Apple, Banana, and Pear for their respective usage.\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=e9bo559i1yz7)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Using Multiple Projects | Deepgram's Docs",
      "ogDescription": "Learn about scenarios in which it would be best to set up multiple Deepgram projects.",
      "title": "Using Multiple Projects | Deepgram's Docs",
      "og:title": "Using Multiple Projects | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "ogTitle": "Using Multiple Projects | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Learn about scenarios in which it would be best to set up multiple Deepgram projects.",
      "twitter:description": "Learn about scenarios in which it would be best to set up multiple Deepgram projects.",
      "description": "Learn about scenarios in which it would be best to set up multiple Deepgram projects.",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "twitter:card": "summary",
      "scrapeId": "220d6a6b-8ef1-46f8-b033-312d06bab765",
      "sourceURL": "https://developers.deepgram.com/guides/deep-dives/using-multiple-projects",
      "url": "https://developers.deepgram.com/guides/deep-dives/using-multiple-projects",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram uses a tiered system of access control to provide granular access to its endpoints. These tiers include account (or global) permissions and project permissions. Applying different tiers of permissions allows for more granularity at the project level. For example, an account may have the `project:kick` permission for one project but not for another project.\n\n## Account Roles\n\nAt the account level, certain permissions imply other specific permissions. For example, an account that has access to the `project:write` permission also implicitly has access to the `project:read` permission. Similarly, `account:write` access implies access to every other account permission.\n\n## Project Roles\n\nAt the project level, users can have access to several roles, including `owner`, `admin`, and `member`, which, similar to account permissions, imply access to another set of permissions:\n\n| Project Role | Implicit Project Permissions |\n| --- | --- |\n| `owner` | `project:read` `project:write` `project:write:settings` `project:write:destroy` `keys:read` `keys:write` `members:read` `members:read:invites` `members:read:scopes` `members:write` `members:write:invites` `members:write:scopes` `members:write:kick` `admins:read` `admins:read:invites` `admins:read:scopes` `admins:write` `admins:write:invites` `admins:write:scopes` `admins:write:kick` `owners:read` `owners:read:invites` `owners:read:scopes` `owners:write` `owners:write:invites` `owners:write:scopes` `owners:write:kick` `usage:read` `usage:write` `billing:read` `billing:write` |\n| `admin` | `project:read` `project:write` `keys:read` `keys:write` (restricted to keys they’ve created) `members:read` `members:read:invites` `members:read:scopes` `members:write` `members:write:invites` `members:write:scopes` `members:write:kick` `admins:read` `admins:read:invites` `admins:read:scopes` `admins:write` `admins:write:invites` `admins:write:scopes` `admins:write:kick` `owners:read` `owners:read:invites` `owners:read:scopes` `usage:read` `usage:write` `billing:read` |\n| `member` | `project:read` `project:write` `keys:read` (restricted to keys they’ve created) `keys:write` (restricted to keys they’ve created) `usage:read` `usage:write` |\n\n## Self-Hosted Product Scopes\n\nDeepgram self-hosted users have been assigned self-hosted product scopes in accordance with their contracts. Any user with these scopes may create [self-hosted API keys and distribution credentials](https://developers.deepgram.com/docs/self-hosted-self-service-tutorial).\n\nThe full list of self-hosted product scopes is as follows:\n\n| Product Scope |\n| --- |\n| `self-hosted:product:api` `self-hosted:product:engine` `self-hosted:product:license-proxy` `self-hosted:product:dgtools` `self-hosted:product:billing` `self-hosted:product:hotpepper` `self-hosted:product:metrics-server` |\n\nThe `self-hosted:products` scope can be provided at self-hosted API key or distribution credentials creation time as a short-hand which implies all available self-hosted product scopes.\n\nFor example an API key has the `self-hosted:product:api`, `self-hosted:product:engine`, and `self-hosted:product:license-proxy` scopes granted to it. For requests authenticated with that API key, the use of `self-hosted:products` would imply all of those scopes when included in a key creation request.\n\n| Product Scope | Example of Implicit Product Scopes |\n| --- | --- |\n| `self-hosted:products` | `self-hosted:product:api` `self-hosted:product:engine` `self-hosted:product:license-proxy` |\n\n### Product Scopes and Project Roles\n\nSelf-hosted API keys can also be created with Console project roles. To do so, simply include the desired role in the same `scopes` list as the self-hosted product scopes when submitting the key creation request.\n\nHere is an example of an self-hosted API key which includes both the `member` project role as well as the `self-hosted:products` scopes.\n\nJSON\n\n```code-block text-sm\n\n1{2  \"member\": {3    \"member_id\": \"550e8400-e29b-41d4-a716-446655440000\",4    \"email\": \"[email protected]\"5  },6  \"api_key\": {7    \"api_key_id\": \"6dcd4ce0-2d9e-4f7f-9257-67e9420b9b7f\",8    \"comment\": \"Self-hosted API Key Example with both the member role and product scopes.\",9    \"scopes\": [10      \"member\",11      \"self-hosted:product:api\",12      \"self-hosted:product:engine\",13      \"self-hosted:product:license-proxy\"14    ],15    \"created\": \"2023-06-27T16:59:46.572660Z\"16  }17}\n```\n\n* * *\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=ec8a1b29-2348-43c5-84f3-9620344a8dd7&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=f2ecc440-6505-4786-9b90-4f1e2f62eaa5&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fguides%2Fdeep-dives%2Fworking-with-roles&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=ec8a1b29-2348-43c5-84f3-9620344a8dd7&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=f2ecc440-6505-4786-9b90-4f1e2f62eaa5&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fguides%2Fdeep-dives%2Fworking-with-roles&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=ne623g1dffv)",
    "metadata": {
      "title": "Working With Roles & API Scopes | Deepgram's Docs",
      "ogTitle": "Working With Roles & API Scopes | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:title": "Working With Roles & API Scopes | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "og:description": "Learn how to use roles and API scope permissions when working with the Deepgram API and Console.",
      "language": "en",
      "ogDescription": "Learn how to use roles and API scope permissions when working with the Deepgram API and Console.",
      "twitter:description": "Learn how to use roles and API scope permissions when working with the Deepgram API and Console.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "description": "Learn how to use roles and API scope permissions when working with the Deepgram API and Console.",
      "twitter:card": "summary",
      "og:title": "Working With Roles & API Scopes | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "scrapeId": "eb947c98-7438-494e-8b9c-bf44d9d50c96",
      "sourceURL": "https://developers.deepgram.com/guides/deep-dives/working-with-roles",
      "url": "https://developers.deepgram.com/guides/deep-dives/working-with-roles",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "If you need to create and distribute short-lived tokens for API requests, you can use the [token-based Auth API](https://developers.deepgram.com/reference/ephemeral-auth-api/grant-token).\n\nDeepgram’s API uses API keys to authenticate requests. You can view and manage your API keys in the [Deepgram Console](https://console.deepgram.com/) or through the [Deepgram API](https://developers.deepgram.com/reference).\n\nYour API keys grant many privileges, so be sure to keep them secure. Do not share your secret API keys in publicly accessible areas such as GitHub or client-side code.\n\nFor best results, use different API keys for testing and production. To help filter usage, you can also use different API keys for different consumers or teams at your organization.\n\nIf you still need an API key, you can [sign up to Deepgram today for free](https://console.deepgram.com/signup)!\n\n## Authenticating with the API Key\n\nOnce you have created an API key, you can use it as credentials to call Deepgram’s API.\n\nSend requests to the API with an `Authorization` header that references your project’s API key:\n\nText\n\n```code-block text-sm\n\nAuthorization: Token YOUR_DEEPGRAM_API_KEY\n```\n\nAll API requests must be made over HTTPS. Calls made over plain HTTP will fail. API requests made without authentication will also fail.\n\n## Test Request\n\nA quick test to see if your key is validating correctly, is to make a request to the `/auth/token` endpoint on our API. This will return an `invalid credentials` error if your key is invalid, and a `JSON` response with details about your key if it’s valid.\n\ncURL\n\n```code-block text-sm\n\n$curl https://api.deepgram.com/v1/auth/token \\>  -H \"Authorization: Token YOUR_DEEPGRAM_API_KEY\"\n```\n\n## Additional Keys\n\nTo create additional API keys, be sure that the API key you are using to authenticate your request has been assigned either the `administrator` role or the following permissions: `keys:read`, `keys:write`.\n\nMake sure you are sending API requests over HTTPS. Calls made over plain HTTP will fail. API requests made without authentication will also fail.\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=25cylfwr2pl2)",
    "metadata": {
      "description": "Learn how to authenticate with Deepgram's API.",
      "title": "Authenticating | Deepgram's Docs",
      "twitter:title": "Authenticating | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogDescription": "Learn how to authenticate with Deepgram's API.",
      "og:description": "Learn how to authenticate with Deepgram's API.",
      "twitter:card": "summary",
      "twitter:description": "Learn how to authenticate with Deepgram's API.",
      "theme-color": "#f5f5f7",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "ogTitle": "Authenticating | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Authenticating | Deepgram's Docs",
      "scrapeId": "ffe0ff26-b650-4ff8-8e06-37d3d5a4ad49",
      "sourceURL": "https://developers.deepgram.com/guides/fundamentals/authenticating",
      "url": "https://developers.deepgram.com/guides/fundamentals/authenticating",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Before you can use Deepgram, you’ll need to [create a Deepgram account](https://console.deepgram.com/signup?jump=keys). Signup is free and includes **$200** in free credit and access to all of Deepgram’s features!\n\n## Create a Deepgram API Key\n\nTo access Deepgram’s API, you’ll need to [create a Deepgram API Key](https://console.deepgram.com/signup?jump=keys). Make note of your API Key; you will need it later.\n\n## Make a Request to the API\n\nHere are several options for trying out the Deepgram API. These examples are meant to help you make a first request to Deepgram; we encourage you to try out one of our Getting Started guides to learn more.\n\n### Deepgram Playground\n\nMake a request without writing any code! Head to the [Deepgram Playground](https://playground.deepgram.com/?smart_format=true&language=en&model=nova-3) to try out the API. No sign-up required!\n\n### CURL\n\nRun the following cURL command in your shell. Be sure to replace the `DEEPGRAM_API_KEY` with your own key.\n\ncURL\n\n```code-block text-sm\n\n$curl \\>  --request POST \\>  --header 'Authorization: Token YOUR_DEEPGRAM_API_KEY' \\>  --header 'Content-Type: application/json' \\>  --data '{\"url\":\"https://static.deepgram.com/examples/interview_speech-analytics.wav\"}' \\>  --url 'https://api.deepgram.com/v1/listen?model=nova-3&smart_format=true'\n```\n\nFor more examples using CURL, check out the [Transcribing Pre-Recorded Audio](https://developers.deepgram.com/docs/transcribing-pre-recorded-audio) guide.\n\n### Deepgram SDKs\n\nThis section will help you get set up to use Deepgram’s SDKs. Then you can continue on to one of the Getting Started guides, which demonstrate how to make common API requests with Deepgram’s officially supported SDKs.\n\n#### Configure Environment\n\nWe provide sample scripts throughout our documentation in the languages of our SDKs and assume you have already configured your development environment. System requirements will vary depending on the programming language you use:\n\n- **Node.js**: node >= 14.14.37\n- **Python**: python >= 3.10\n- **.NET**: dotnet >= 6.0\n- **GO**: Go >= 1.18\n\nIf you get stuck at any point, help is just a click away! [Contact Support](https://developers.deepgram.com/support).\n\n#### Install the SDK\n\nIf you intend to use one of Deepgram’s SDKs to make your request, you must install it.\n\nOpen your terminal, navigate to the location on your drive where you want to create your project, and install the Deepgram SDK.\n\nPythonJavaScript.NETGo\n\n```code-block text-sm\n\n$# Install the Deepgram Python SDK># https://github.com/deepgram/deepgram-python-sdk>pip install deepgram-sdk==3.*\n```\n\n#### Make a Request with the SDKs\n\nContinue on to one of our **Getting Started Guides** where you will find language-specific code samples that show you how to make requests to Deepgram with the SDK of your choice.\n\n- [Pre-Recorded Speech to Text](https://developers.deepgram.com/docs/getting-started-with-pre-recorded-audio)\n- [Streaming Speech to Text](https://developers.deepgram.com/docs/getting-started-with-live-streaming-audio)\n- [Text to Speech](https://developers.deepgram.com/docs/text-to-speech)\n- [Audio Intelligence](https://developers.deepgram.com/docs/audio-intelligence)\n- [Text Intelligence](https://developers.deepgram.com/docs/text-intelligence)\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=ha5w4t1qvg6y)",
    "metadata": {
      "ogDescription": "Follow these steps to get started with Deepgram and make your first request.",
      "theme-color": "#f5f5f7",
      "og:description": "Follow these steps to get started with Deepgram and make your first request.",
      "description": "Follow these steps to get started with Deepgram and make your first request.",
      "twitter:card": "summary",
      "og:title": "Make Your First API Request | Deepgram's Docs",
      "language": "en",
      "title": "Make Your First API Request | Deepgram's Docs",
      "twitter:title": "Make Your First API Request | Deepgram's Docs",
      "twitter:description": "Follow these steps to get started with Deepgram and make your first request.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Make Your First API Request | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "13cbc039-0798-4456-8bc7-ad8cb8d74ee8",
      "sourceURL": "https://developers.deepgram.com/guides/fundamentals/make-your-first-api-request",
      "url": "https://developers.deepgram.com/guides/fundamentals/make-your-first-api-request",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "The Models endpoint allows users to efficiently query all available public models or private models and determine which models they have access to.\n\nFor additional details on these API endpoints refer to our [API Reference](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n## Enable Feature\n\n### GET /models\n\nReturns metadata on all the latest public models. If multiple versions exist, the latest model version is returned. If you wish to return all models you can use the `include_outdated=true` parameter in your request.\\`\n\nIf you need to get information on a custom model (non-public) you can use the Get Project Models endpoints.\n\n#### Request\n\ncURL\n\n```code-block text-sm\n\n$curl --location 'https://api.deepgram.com/v1/models' \\\n```\n\nFor this endpoint you **do not** need to provide your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n#### Result\n\nJSON\n\n```code-block text-sm\n\n1{2  \"stt\": [3  \t{4      \"name\": \"general\",5      \"canonical_name\": \"nova-3-general\",6      \"architecture\": \"nova3\",7      \"languages\": [8        \"en\",9        \"en-US\"10      ],11      \"version\": \"2025-01-09.0\",12      \"uuid\": \"bf05427e-a1f1-4ced-a976-38b2f3533d8d\",13      \"batch\": false,14      \"streaming\": true,15      \"formatted_output\": false16    },17    // ... other STT models18  ],19  \"tts\": [20    {21      \"name\": \"angus\",22      \"canonical_name\": \"aura-angus-en\",23      \"architecture\": \"aura\",24      \"languages\": [25        \"en\",26        \"en-IE\"27      ],28      \"version\": \"2024-11-19.0\",29      \"uuid\": \"b50880e3-4e2e-4e53-ba27-ea0472bf2cf4\",30      \"metadata\": {31        \"accent\": \"Irish\",32        \"color\": \"#BA80F5\",33        \"image\": \"https://static.deepgram.com/examples/avatars/angus.jpg\",34        \"sample\": \"https://static.deepgram.com/examples/voices/angus.wav\",35        \"tags\": [36          \"masculine\"37        ]38      }39    },40    // ... other TTS models41  ]42}\n\n```\n\n### GET /projects/{project}/models\n\nReturns metadata on all the latest models that a specific project has access to, including non-public models. If multiple versions exist, the latest model version is returned. If you wish to return all models you can use the `include_outdated=true` parameter in your request.\n\n#### Request\n\ncURL\n\n```code-block text-sm\n\n$curl --location 'https://api.deepgram.com/v1/projects/YOUR_PROJECT_ID/models' \\>--header 'Authorization: Token YOUR_DEEPGRAM_API_KEY'\n```\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys) and replace `YOUR_PROJECT_ID` with your [Deepgram Project ID](https://developers.deepgram.com/docs/managing-projects).\n\n#### Result\n\nJSON\n\n```code-block text-sm\n\n1{2  \"stt\": [3    {4      \"name\": \"general\",5      \"canonical_name\": \"nova-3-general\",6      \"architecture\": \"nova3\",7      \"languages\": [8        \"en\",9        \"en-US\"10      ],11      \"version\": \"2025-01-09.0\",12      \"uuid\": \"bf05427e-a1f1-4ced-a976-38b2f3533d8d\",13      \"batch\": false,14      \"streaming\": true,15      \"formatted_output\": false16    },17\t\t... additional STT Models.18  ],19  \"tts\": [20    {21      \"name\": \"angus\",22      \"canonical_name\": \"aura-angus-en\",23      \"architecture\": \"aura\",24      \"languages\": [25        \"en\",26        \"en-IE\"27      ],28      \"version\": \"2024-11-19.0\",29      \"uuid\": \"b50880e3-4e2e-4e53-ba27-ea0472bf2cf4\",30      \"metadata\": {31        \"accent\": \"Irish\",32        \"color\": \"#BA80F5\",33        \"image\": \"https://static.deepgram.com/examples/avatars/angus.jpg\",34        \"sample\": \"https://static.deepgram.com/examples/voices/angus.wav\",35        \"tags\": [36          \"masculine\"37        ]38      }39    },40\t\t... additional TTS Models.41  ]42}\n\n```\n\n### GET /models/{modelId}\n\nReturns the metadata for a specific model. If the model is not found a `404` error is returned. This endpoint works for public models only.\n\n#### Request\n\ncURL\n\n```code-block text-sm\n\n$curl --location 'https://api.deepgram.com/v1/models/MODEL_UUID' \\\n```\n\nFor this endpoint you **do not** need to provide your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n#### Results\n\nJSON\n\n```code-block text-sm\n\n1{2    \"name\": \"angus\",3    \"canonical_name\": \"aura-angus-en\",4    \"architecture\": \"aura\",5    \"language\": [\"en\"],6    \"version\": \"2024-03-28.0\",7    \"uuid\": \"af6e9977-99f6-4d8f-b6f5-dfdf6fb6e291\",8    \"metadata\": {9        \"accent\": \"Irish\",10        \"color\": \"#BA80F5\",11        \"tags\": [\"masculine\"],12        \"image\": \"https://static.deepgram.com/examples/avatars/angus.jpg\",13        \"sample\": \"https://static.deepgram.com/examples/voices/angus.wav\"14    }15}\n```\n\n### GET /projects/{project}/models/{modelId}\n\nReturns the metadata for a specific model that a particular project has access to. If the model is not found a `404` error is returned. This endpoint works for both public models and models accessible by the specified project.\n\n#### Request\n\ncURL\n\n```code-block text-sm\n\n$curl --location 'https://api.deepgram.com/v1/projects/YOUR_PROJECT_ID/models/MODEL_UUID' \\>--header 'Authorization: Token YOUR_DEEPGRAM_API_KEY'\n```\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys) and replace `YOUR_PROJECT_ID` with your [Deepgram Project ID](https://developers.deepgram.com/docs/managing-projects) and replace `MODEL_UUID` with the specific Model UUID.\n\n#### Results\n\nJSON\n\n```code-block text-sm\n\n1{2    \"name\": \"angus\",3    \"canonical_name\": \"aura-angus-en\",4    \"architecture\": \"aura\",5    \"language\": [\"en\"],6    \"version\": \"2024-03-28.0\",7    \"uuid\": \"af6e9977-99f6-4d8f-b6f5-dfdf6fb6e291\",8    \"metadata\": {9        \"accent\": \"Irish\",10        \"color\": \"#BA80F5\",11        \"tags\": [\"masculine\"],12        \"image\": \"https://static.deepgram.com/examples/avatars/angus.jpg\",13        \"sample\": \"https://static.deepgram.com/examples/voices/angus.wav\"14    }15}\n```\n\n* * *\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=e0d2mphffmbd)",
    "metadata": {
      "ogDescription": "Use the Models endpoint to determine which models you can access and returns metadata about those models.",
      "ogTitle": "Model Metadata | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "twitter:description": "Use the Models endpoint to determine which models you can access and returns metadata about those models.",
      "twitter:title": "Model Metadata | Deepgram's Docs",
      "og:title": "Model Metadata | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "title": "Model Metadata | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:description": "Use the Models endpoint to determine which models you can access and returns metadata about those models.",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "description": "Use the Models endpoint to determine which models you can access and returns metadata about those models.",
      "scrapeId": "d705c941-3fa5-4d98-b0a9-6889bf687dd0",
      "sourceURL": "https://developers.deepgram.com/guides/fundamentals/model-metadata",
      "url": "https://developers.deepgram.com/guides/fundamentals/model-metadata",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "A temporary token is a secure, authentication credential that provides time-limited access to Deepgram’s APIs. These tokens have a 30 second Time To Live (TTL) and are designed specifically for short-lived, secure API access scenarios, particularly in client-side applications where long-term credential storage is not recommended. Unlike traditional API keys, temporary tokens are ideal for real-time applications requiring secure, temporary access to Deepgram’s services.\n\nDeepgramYour Backend ProxyYour ClientDeepgramYour Backend ProxyYour ClientAuthorization: Token <API Key>Authorization: Bearer <JWT>GET /your-token-endpointPOST /v1/auth/grant200 { access\\_token: <jwt>, expires\\_in: 30 }200 { access\\_token: <jwt>, expires\\_in: 30 }GET /v1/listen{ ... }\n\n## Use Cases\n\nTemporary tokens are ideal for client-side/untrusted applications because they allow clients to directly access the Deepgram API. Normal API keys, to be secure, require proxying traffic through your own servers where the API key is stored.\n\nDirect access to the Deepgram API is particularly useful for client-side/untrusted applications that are more latency-sensitive, like realtime connections.\n\n## Implementation Considerations\n\n1. Create a backend service to generate temporary tokens\n2. Generate tokens only when needed (e.g., at connection start)\n3. Pass the token from your backend to your client\n4. Initiate the Deepgram inference request from your client with the token\n5. Use tokens immediately after generation\n6. Implement proper error handling for expired tokens\n\n## Example\n\nTo create a JWT token, you can use the `/auth/grant` endpoint using the Authorization header with the `token` scheme.\n\ncURL\n\n```code-block text-sm\n\n$curl -X POST https://api.deepgram.com/v1/auth/grant \\>   -H \"Authorization: Token YOUR_DEEPGRAM_API_KEY\"\n```\n\nReplace `YOUR_DEEPGRAM_API_KEY` with your [Deepgram API Key](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n## Response\n\nJSON\n\n```code-block text-sm\n\n1{2  \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiI2ZDNkMWJiYy0yNmI0LTRlZGQtYjliMy0zNjc3MDM3OTFmZTciLCJle BAiOjE3NDM2MjY2MzQsInN1YmplY3QiOiI2ZDNkMWJiYy0yNmI0LTRlZGQtYjliMy0zNjc3MDM3OTFmZTciLCJzY29wZXMiOlsiYXXyOndyaXRlIl0sInByb2plY3RfY2xhaW1zIjpbInVzYWdlOndyaXRlIl0sImFjY2Vzc29yIjoiMDgy1mM1YTMtNDRlMy00MWVkLThlZWItNDJiOGE1MDkwNjYwIiwiYWNjZXNzb3JfZ2VuZXJhdGlvbiI6MCwiY3JlYXRlZCI6IjIwMjMtMDItYjFUMjE6MTM6NDAuMDE0MzczWiJ9.-nutqvuezqlpxgUiBTKK9niCJeAiy855gBRzop32kCw\",3  \"expires_in\": 304}\n\n```\n\nTo use the JWT token, you can then pass it in the `Authorization` header of your request to any Deepgram API that supports token-based authentication using the `Bearer` scheme.\n\n## Example\n\ncURL\n\n```code-block text-sm\n\n$ curl -X POST https://api.deepgram.com/v1/listen \\>    -H \"Authorization: Bearer YOUR_JWT_TOKEN\"\n```\n\nReplace `YOUR_JWT_TOKEN` with the JWT token you received from the `/auth/grant` endpoint.\n\n## FAQ\n\n### Why do I get a Forbidden error?\n\n`{\"err_code\":\"FORBIDDEN\",\"err_msg\":\"Insufficient permissions.\"}`\n\nThe API key you use for the `/auth/grant` request needs to have at least Member permissions.\nTo create a key with Member permissions, login to the [Deepgram Console](https://console.deepgram.com/) and click on “API Keys” from the left sidebar. Click the “Create Key” button, then select “Advanced” options and choose “Member” from the permissions dropdown.\n\nAlternatively, you can create a key with Member permissions using the [Create Key](https://developers.deepgram.com/reference/management-api/keys/create) endpoint.\n\n### Can a token have a longer TTL (Time To Live) than 30 seconds?\n\nWe currently don’t support modifying the TTL value of temporary tokens.\n\n### Can my websocket connection last longer than 30 seconds?\n\nYes! You only need the temporary token to be valid during the initial websocket connection to Deepgram’s APIs. The websocket connection will then stay open as it would in any other case until you close it.\n\n### Which Deepgram APIs can I use with a temporary token?\n\nTemporary tokens have usage::write permission for these Deepgram APIs:\n\n- [`/listen` REST API](https://developers.deepgram.com/reference/speech-to-text-api/listen) \\- Speech to Text\n- [`/listen` WebSocket API](https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming) \\- Speech to Text\n- [`/speak` REST API](https://developers.deepgram.com/reference/text-to-speech-api/speak) \\- Text to Speech\n- [`/speak` WebSocket API](https://developers.deepgram.com/reference/text-to-speech-api/speak-streaming) \\- Text to Speech\n- [`/read` REST API](https://developers.deepgram.com/reference/text-intelligence-api/text-read) \\- Text Intelligence\n\nThese APIs will not work with temporary tokens:\n\n- The collection of [Management APIs](https://developers.deepgram.com/reference/deepgram-api-overview)\n- The [`/agent` API](https://developers.deepgram.com/reference/voice-agent-api/agent) \\- Coming soon!\n\n### Can I use this token for speech-to-text pre-recorded requests?\n\nYes! You can use this token with speech-to-text pre-recorded requests. Just note that due to the short TTL you may need to request a new token before subsequent pre-recorded requests. Unless you have latency constraints, you’re likely better off just making the request from inside the proxy.\n\n### Are temporary tokens supported in the Deepgram SDKs?\n\nYes. The Deepgram SDKs support token-based authentication. Please refer to the [SDKs Feature Matrix](https://developers.deepgram.com/docs/sdk-feature-matrix#token-based-authentication) page for more information.\n\n### Why should I use temporary tokens over temporary API keys?\n\n- Fewer Disruptions: Temporary tokens are more resilient to outages, reducing the chances of interruptions to your workflow — especially during planned maintenance or unexpected incidents.\n- Cleaner Deepgram Console Experience: Using temporary tokens means you’ll no longer see pages cluttered with expired API keys. Your usage summary and API keys views will be cleaner and easier to navigate.\n- Smoother Console Performance: Switching to temporary tokens means the Deepgram Console will remain fast and efficient, even as your usage scales.\n- Faster Access: Creating a temporary token is faster than creating an API key, which means faster connection times for WebSockets.\n\n### Can I track the usage from temporary tokens?\n\nYes! The temporary tokens generated have the same accessor as the API key used to generate them.\n\n* * *\n\nWhat’s Next\n\n- For more information, refer to the [Token-based Authentication API Reference](https://developers.deepgram.com/reference/token-based-auth-api/grant-token).\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=720321ee-50c0-4c96-98ae-4e253c2d1c6f&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=2ace6a32-2743-4525-bc34-29a8ae5ed5cd&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fguides%2Ffundamentals%2Ftoken-based-authentication&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=720321ee-50c0-4c96-98ae-4e253c2d1c6f&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=2ace6a32-2743-4525-bc34-29a8ae5ed5cd&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Fguides%2Ffundamentals%2Ftoken-based-authentication&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "title": "Token-Based Auth | Deepgram's Docs",
      "ogDescription": "Generates a temporary JSON Web Token (JWT) with a 30-second TTL (Time To Live) for Deepgram APIs.",
      "og:title": "Token-Based Auth | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Token-Based Auth | Deepgram's Docs",
      "ogTitle": "Token-Based Auth | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "description": "Generates a temporary JSON Web Token (JWT) with a 30-second TTL (Time To Live) for Deepgram APIs.",
      "twitter:description": "Generates a temporary JSON Web Token (JWT) with a 30-second TTL (Time To Live) for Deepgram APIs.",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "twitter:card": "summary",
      "og:description": "Generates a temporary JSON Web Token (JWT) with a 30-second TTL (Time To Live) for Deepgram APIs.",
      "scrapeId": "20c564d8-2fb5-4293-aabf-c785efe095fb",
      "sourceURL": "https://developers.deepgram.com/guides/fundamentals/token-based-authentication",
      "url": "https://developers.deepgram.com/guides/fundamentals/token-based-authentication",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "# JS SDK\n\nThe Deepgram JS SDK has defined [typed parameters](https://github.com/deepgram/deepgram-js-sdk/tree/main/src/lib/types), but also allows for arbitrary key/value pairs. You can provide custom parameters when using the JS SDK to make an API Request even if the parameter isn’t defined as a type.\n\nThis is useful if you want to use a feature of the Deepgram API that isn’t officially supported in the JS SDK.\n\n## Example\n\nJavaScript\n\n```code-block text-sm\n\n1// install our SDK @deepgram/sdk23import { createClient } from \"@deepgram/sdk\";4// - or -5// const { createClient } = require(\"@deepgram/sdk\");67const { result, error } = await deepgram.listen.prerecorded.transcribeUrl(8  {9    url: \"https://dpgr.am/spacewalk.wav\",10  },11  {12    model: \"nova-3\",13    // To demonstrate using the custom addon parameters, you could enable it like this14    custom_parameter: option15  }16);\n```\n\n# Python SDK\n\nThe Deepgram Python SDK has defined option parameters, but also allows for arbitrary key/value pairs. You can provide custom parameters when using the Python SDK to make an API Request even if the parameter isn’t defined as an option.\n\nThis is useful if you want to use a feature of the Deepgram API that isn’t officially supported in the Python SDK.\n\n## Example\n\nThreadedAsync IO\n\n```code-block text-sm\n\n1# Install the SDK: pip install deepgram-sdk23import os4from dotenv import load_dotenv56from deepgram import DeepgramClient, PrerecordedOptions78load_dotenv()910AUDIO_URL = {11    \"url\": \"https://dpgr.am/bueller.wav\"12}1314def main():15    options: PrerecordedOptions = PrerecordedOptions(16        model=\"nova-3\"17    )1819    # To demonstrate using the custom addon parameters, you could enable it like this20    custom_options: dict = {\"custom_parameter\": option}2122    # STEP 1 Create a Deepgram client using the API key in the environment variables DEEPGRAM_API_KEY23    deepgram: DeepgramClient = DeepgramClient()2425    try:26        # STEP 2 Call the transcribe_url method on the prerecorded class27        response = deepgram.listen.rest.v(\"1\").transcribe_url(28            AUDIO_URL, options, addons=custom_options29        )30        print(response.to_json(indent=4))31    except Exception as e:32        print(f\"Exception: {e}\")3334if __name__ == \"__main__\":35    main()\n```\n\n# .NET SDK\n\nThe Deepgram .NET SDK has defined option parameters, but also allows for arbitrary key/value pairs. You can provide custom parameters when using the .NET SDK to make an API Request even if the parameter isn’t defined as an option.\n\nThis is useful if you want to use a feature of the Deepgram API that isn’t officially supported in the .NET SDK.\n\n## Example\n\nC#\n\n```code-block text-sm\n\n1//Install the SDK: dotnet add package Deepgram23using Deepgram.Models.Listen.v1.REST;45namespace PreRecorded6{7    class Program8    {9        static async Task Main(string[] args)10        {11            // Initialize Library with default logging12            // Normal logging is \"Info\" level13            Library.Initialize();1415            // Set \"DEEPGRAM_API_KEY\" environment variable to your Deepgram API Key16            var deepgramClient = ClientFactory.CreateListenRESTClient();17          18            var prerecordedOptions = new PreRecordedSchema()19            {20                Model = \"nova-3\"21            };22          23            // but to demonstrate using the custom addon parameters, you could enable it like this24            var customOptions = new Dictionary<string, string>();25            customOptions[\"custom_parameter\"] = \"option\";2627            var response = await deepgramClient.TranscribeUrl(28                new UrlSource(\"https://dpgr.am/bueller.wav\"),29                prerecordedOptions,30                null, // Don't want to specify a cancellation token, use the default31                customOptions,32            \t);3334            Console.WriteLine(response);3536            // Teardown Library37            Library.Terminate();38        }39    }40}\n```\n\n# Go SDK\n\nThe Deepgram Go SDK has defined option parameters, but also allows for arbitrary key/value pairs. You can provide custom parameters when using the Go SDK to make an API Request even if the parameter isn’t defined as an option.\n\nThis is useful if you want to use a feature of the Deepgram API that isn’t officially supported in the Go SDK.\n\n## Example\n\nGo\n\n```code-block text-sm\n\n1// Install the SDK: go get github.com/deepgram/deepgram-go-sdk23package main45import (6\t\"context\"7\t\"encoding/json\"8\t\"fmt\"9\t\"os\"1011\tprettyjson \"github.com/hokaccha/go-prettyjson\"1213\tapi \"github.com/deepgram/deepgram-go-sdk/pkg/api/listen/v1/rest\"14\tinterfaces \"github.com/deepgram/deepgram-go-sdk/pkg/client/interfaces\"15\tclient \"github.com/deepgram/deepgram-go-sdk/pkg/client/listen\"16)1718const (19\turl string = \"https://dpgr.am/bueller.wav\"20)2122func main() {23\t// init library24\tclient.InitWithDefault()2526\t// Go context27\tctx := context.Background()2829\t// set the Transcription options30\toptions := &interfaces.PreRecordedTranscriptionOptions{31\t\tModel: \"nova-3\",32\t}3334\t// create a Deepgram client35\tc := client.NewRESTWithDefaults()36\tdg := api.New(c)3738\t// but to demonstrate using the custom addon parameters, you could enable it like this39\tparams := make(map[string][]string, 0)40\tparams[\"custom_parameter\"] = []string{\"option\"}41\tctx = interfaces.WithCustomParameters(ctx, params)4243\t// send/process file to Deepgram44\tres, err := dg.FromURL(ctx, url, options)45\tif err != nil {46\t\tif e, ok := err.(*interfaces.StatusError); ok {47\t\t\tfmt.Printf(\"DEEPGRAM ERROR:\\n%s:\\n%s\\n\", e.DeepgramError.ErrCode, e.DeepgramError.ErrMsg)48\t\t}49\t\tfmt.Printf(\"FromStream failed. Err: %v\\n\", err)50\t\tos.Exit(1)51\t}5253\tdata, err := json.Marshal(res)54\tif err != nil {55\t\tfmt.Printf(\"json.Marshal failed. Err: %v\\n\", err)56\t\tos.Exit(1)57\t}5859\t// make the JSON pretty60\tprettyJSON, err := prettyjson.Format(data)61\tif err != nil {62\t\tfmt.Printf(\"prettyjson.Marshal failed. Err: %v\\n\", err)63\t\tos.Exit(1)64\t}65\tfmt.Printf(\"\\n\\nResult:\\n%s\\n\\n\", prettyJSON)66}\n```",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogDescription": "Learn how to use custom add on parameters to set arbitrary key/value pairs with the Deepgram SDKs.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:description": "Learn how to use custom add on parameters to set arbitrary key/value pairs with the Deepgram SDKs.",
      "twitter:title": "Using Custom Add On Parameters with SDKs | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:title": "Using Custom Add On Parameters with SDKs | Deepgram's Docs",
      "theme-color": [
        "#f5f5f7",
        "#0b0b0c",
        "#f5f5f7"
      ],
      "description": "Learn how to use custom add on parameters to set arbitrary key/value pairs with the Deepgram SDKs.",
      "og:description": "Learn how to use custom add on parameters to set arbitrary key/value pairs with the Deepgram SDKs.",
      "ogTitle": "Using Custom Add On Parameters with SDKs | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "twitter:card": "summary",
      "title": "Using Custom Add On Parameters with SDKs | Deepgram's Docs",
      "scrapeId": "466c1a19-fd72-4495-8fad-36d4b0c99350",
      "sourceURL": "https://developers.deepgram.com/guides/fundamentals/using-custom-parameters-sdks",
      "url": "https://developers.deepgram.com/guides/fundamentals/using-custom-parameters-sdks",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "[Introducing Aura-2, our text-to-speech built for enterprise use cases.](https://developers.deepgram.com/docs/text-to-speech)\n\nVoice Agent\n\nCreate agents for contact centers, teaching, drive thrus and more.\n\n- [Getting started](https://developers.deepgram.com/docs/voice-agent)\n- [Function calling](https://developers.deepgram.com/docs/voice-agents-function-calling)\n\nSpeech-to-Text\n\nTranscribe audio for contact centers, medical audio, wearables and more\n\n- [Pre-recorded](https://developers.deepgram.com/docs/pre-recorded-audio)\n- [Streaming](https://developers.deepgram.com/docs/live-streaming-audio)\n- [Models and Languages](https://developers.deepgram.com/docs/models-languages-overview)\n\nText-to-Speech\n\nGenerate audio for contact centers, IVRs, drive thrus and more\n\n- [Getting started](https://developers.deepgram.com/docs/text-to-speech)\n- [Voices](https://developers.deepgram.com/docs/tts-models)\n\nIntelligence\n\nGain insights for phone calls and transcripts\n\n- [Audio inputs](https://developers.deepgram.com/docs/audio-intelligence)\n- [Text inputs](https://developers.deepgram.com/docs/text-intelligence)\n\n## SDKs\n\n[![Python](https://fern-image-hosting.s3.us-east-1.amazonaws.com/deepgram/python.svg)\\\\\n\\\\\nPython SDK](https://github.com/deepgram/deepgram-python-sdk) [![JavaScript](https://fern-image-hosting.s3.us-east-1.amazonaws.com/deepgram/js-yellow.svg)\\\\\n\\\\\nJS SDK](https://github.com/deepgram/deepgram-javascript-sdk) [![Go](https://fern-image-hosting.s3.us-east-1.amazonaws.com/deepgram/go.svg)\\\\\n\\\\\nGo SDK](https://github.com/deepgram/deepgram-go-sdk) [![.NET](https://fern-image-hosting.s3.us-east-1.amazonaws.com/deepgram/net.svg)\\\\\n\\\\\n.NET SDK](https://github.com/deepgram/deepgram-dotnet-sdk)\n\n## Resources\n\nLearn & Discover\n\n- [Playground](https://playground.deepgram.com/)\n- [Starters](https://github.com/orgs/deepgram-starters/repositories?type=all)\n- [API Reference](https://developers.deepgram.com/reference/deepgram-api-overview)\n\nConnect & Engage\n\n- [Support](https://developers.deepgram.com/docs/support)\n- [Discord](https://dpgr.am/discord)\n- [Forums](https://github.com/orgs/deepgram/discussions)\n\nTrust & Safety\n\n- [Security](https://developers.deepgram.com/docs/security-policy)\n- [Compliance](https://developers.deepgram.com/docs/data-privacy-compliance)\n- [Privacy](https://developers.deepgram.com/docs/information-security-privacy-statement)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=xpthzhmy137w)",
    "metadata": {
      "ogTitle": "Welcome to Deepgram's Docs! | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": "Welcome to Deepgram's Docs! | Deepgram's Docs",
      "twitter:title": "Welcome to Deepgram's Docs! | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Welcome to Deepgram's Docs! | Deepgram's Docs",
      "twitter:card": "summary",
      "scrapeId": "c45b019b-94b9-41ba-af9c-fecc16512d6a",
      "sourceURL": "https://developers.deepgram.com/home",
      "url": "https://developers.deepgram.com/home",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Pay as You Go / Growth\n\nLimits to consider if you use the Pay as You Go or Growth plans with Deepgram.\n\n### Voice Agent\n\n| API | Connection Limits |\n| --- | --- |\n| [Voice Agent API](https://developers.deepgram.com/reference/build-a-voice-agent) | Up to 5 concurrent connections |\n\n### Speech to Text\n\nIf multiple services are used in one API call (e.g Speech to Text + Sentiment Analysis), the lower of the rate limits is applied.\n\n| Model | Service Limit |\n| --- | --- |\n| [Nova-3](https://developers.deepgram.com/docs/models-languages-overview#nova-3) | `Pre-Recorded` Up to 100 concurrent requests<br>`Streaming` Up to 50 concurrent requests |\n| [Nova-2](https://developers.deepgram.com/docs/models-languages-overview#nova-2) | `Pre-Recorded` Up to 100 concurrent requests<br>`Streaming` Up to 50 concurrent requests |\n| [Nova](https://developers.deepgram.com/docs/models-languages-overview#nova) | `Pre-Recorded` Up to 100 concurrent requests<br>`Streaming` Up to 50 concurrent requests |\n| [Enhanced](https://developers.deepgram.com/docs/models-languages-overview#enhanced) | `Pre-Recorded` Up to 100 concurrent requests<br>`Streaming` Up to 50 concurrent requests |\n| [Base](https://developers.deepgram.com/docs/models-languages-overview#base) | `Pre-Recorded` Up to 100 concurrent requests<br>`Streaming` Up to 50 concurrent requests |\n| [Whisper Cloud](https://developers.deepgram.com/docs/models-languages-overview#deepgram-whisper-cloud) | `Pre-Recorded` Up to 5 concurrent requests |\n\n### Text to Speech REST\n\n| Model | Service Limit |\n| --- | --- |\n| [Aura](https://developers.deepgram.com/docs/text-to-speech) | Pay as You Go: Up to 5 concurrent requests |\n| [Aura](https://developers.deepgram.com/docs/text-to-speech) | Growth: Up to 5 concurrent requests |\n| [Aura-2](https://developers.deepgram.com/docs/text-to-speech) | Pay as You Go: Up to 5 concurrent requests |\n| [Aura-2](https://developers.deepgram.com/docs/text-to-speech) | Growth: Up to 5 concurrent requests |\n\n### Text to Speech Streaming\n\n| Model | Service Limit |\n| --- | --- |\n| [Aura](https://developers.deepgram.com/docs/streaming-text-to-speech) | Pay as You Go: Up to 40 concurrent requests |\n| [Aura](https://developers.deepgram.com/docs/streaming-text-to-speech) | Growth: Up to 80 concurrent requests |\n| [Aura-2](https://developers.deepgram.com/docs/streaming-text-to-speech) | Pay as You Go: n/a |\n| [Aura-2](https://developers.deepgram.com/docs/streaming-text-to-speech) | Growth: n/a |\n\nAura-2 is currently available for the [TTS REST API only](https://developers.deepgram.com/reference/text-to-speech-api/speak). Websocket support is coming soon.\n\n### Audio Intelligence\n\nIf you include Audio Intelligence features in requests to `/listen`, you will be subject to the service limits noted in the table below.\n\n| Model | Service Limit |\n| --- | --- |\n| [Intent Recognition](https://developers.deepgram.com/docs/intent-recognition) | Up to 10 concurrent requests |\n| [Entity Detection](https://developers.deepgram.com/docs/detect-entities) | Up to 5 concurrent requests |\n| [Sentiment Analysis](https://developers.deepgram.com/docs/sentiment-analysis) | Up to 10 concurrent requests |\n| [Summarization](https://developers.deepgram.com/docs/summarization) | Up to 10 concurrent requests |\n| [Topic Detection](https://developers.deepgram.com/docs/topic-detection) | Up to 10 concurrent requests |\n\n### Text Intelligence\n\n| Model | Service Limit |\n| --- | --- |\n| [Intent Recognition](https://developers.deepgram.com/docs/text-intention-recognition) | Up to 10 concurrent requests |\n| [Sentiment Analysis](https://developers.deepgram.com/docs/text-sentiment-analysis) | Up to 10 concurrent requests |\n| [Summarization](https://developers.deepgram.com/docs/text-summarization) | Up to 10 concurrent requests |\n| [Topic Detection](https://developers.deepgram.com/docs/text-topic-detection) | Up to 10 concurrent requests |\n\n## Enterprise\n\nStarting limits to consider if you have an Enterprise Contract with Deepgram.\n\nNew and existing Enterprise customers can request a Service Limit increase by discussing your needs with the [Deepgram Sales Team.](mailto:sales@deepgram.com)\n\n### Voice Agent\n\n| API | Connection Limits |\n| --- | --- |\n| [Voice Agent API](https://developers.deepgram.com/reference/build-a-voice-agent) | Up to 5 concurrent connections |\n\n### Speech to Text\n\nIf multiple services are used in one API call (e.g Speech to Text + Sentiment Analysis), the lower of the rate limits is applied.\n\n| Model | Service Limit |\n| --- | --- |\n| [Nova-3](https://developers.deepgram.com/docs/models-languages-overview#nova-3) | `Pre-Recorded` Starting at 100 concurrent requests<br>`Streaming` Starting at 100 concurrent requests |\n| [Nova-2](https://developers.deepgram.com/docs/models-languages-overview#nova-2) | `Pre-Recorded` Starting at 100 concurrent requests<br>`Streaming` Starting at 100 concurrent requests |\n| [Nova](https://developers.deepgram.com/docs/models-languages-overview#nova) | `Pre-Recorded` Starting at 100 concurrent requests<br>`Streaming` Starting at 100 concurrent requests |\n| [Enhanced](https://developers.deepgram.com/docs/models-languages-overview#enhanced) | `Pre-Recorded` Starting at 100 concurrent requests<br>`Streaming` Starting at 100 concurrent requests |\n| [Base](https://developers.deepgram.com/docs/models-languages-overview#base) | `Pre-Recorded` Starting at 100 concurrent requests<br>`Streaming` Starting at 100 concurrent requests |\n| [Whisper Cloud](https://developers.deepgram.com/docs/models-languages-overview#deepgram-whisper-cloud) | `Pre-Recorded` Starting at 15 concurrent requests |\n\n### Text to Speech REST\n\n| Model | Service Limit |\n| --- | --- |\n| [Aura](https://developers.deepgram.com/docs/text-to-speech) | Starting at 2400 requests / min |\n| [Aura-2](https://developers.deepgram.com/docs/text-to-speech) | Starting at 5 requests / min |\n\n### Text to Speech Streaming\n\n| Model | Service Limit |\n| --- | --- |\n| [Aura](https://developers.deepgram.com/docs/streaming-text-to-speech) | Starting at 150 concurrent requests |\n| [Aura-2](https://developers.deepgram.com/docs/streaming-text-to-speech) | n/a |\n\nAura-2 is currently available for the [TTS REST API only](https://developers.deepgram.com/reference/text-to-speech-api/speak). Websocket support is coming soon.\n\n### Audio Intelligence\n\nIf you include Audio Intelligence features in requests to `/listen`, you will be subject to the service limits noted in the table below.\n\n| Model | Service Limit |\n| --- | --- |\n| [Intent Recognition](https://developers.deepgram.com/docs/intent-recognition) | Starting at 10 concurrent requests |\n| [Entity Detection](https://developers.deepgram.com/docs/detect-entities) | Starting at 10 concurrent requests |\n| [Sentiment Analysis](https://developers.deepgram.com/docs/sentiment-analysis) | Starting at 10 concurrent requests |\n| [Summarization](https://developers.deepgram.com/docs/summarization) | Starting at 10 concurrent requests |\n| [Topic Detection](https://developers.deepgram.com/docs/topic-detection) | Starting at 10 concurrent requests |\n\n### Text Intelligence\n\n| Model | Service Limit |\n| --- | --- |\n| [Intent Recognition](https://developers.deepgram.com/docs/text-intention-recognition) | Starting at 10 concurrent requests |\n| [Sentiment Analysis](https://developers.deepgram.com/docs/text-sentiment-analysis) | Starting at 10 concurrent requests |\n| [Summarization](https://developers.deepgram.com/docs/text-summarization) | Starting at 10 concurrent requests |\n| [Topic Detection](https://developers.deepgram.com/docs/text-topic-detection) | Starting at 10 concurrent requests |\n\nThe [error](https://developers.deepgram.com/docs/errors#429-rate-limit-exceeded-1) `429: Too Many Requests` is returned when your project has more concurrent requests than the rate limits allow. To learn more about this error please see our Documentation on [Errors](https://developers.deepgram.com/docs/errors).\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=463v1eg6lmf)",
    "metadata": {
      "og:description": "Understand the different service limits of Deepgram's APIs.",
      "language": "en",
      "og:title": "API Rate Limits | Deepgram's Docs",
      "twitter:description": "Understand the different service limits of Deepgram's APIs.",
      "ogDescription": "Understand the different service limits of Deepgram's APIs.",
      "twitter:title": "API Rate Limits | Deepgram's Docs",
      "title": "API Rate Limits | Deepgram's Docs",
      "ogTitle": "API Rate Limits | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "description": "Understand the different service limits of Deepgram's APIs.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "scrapeId": "01019e30-8692-4f3d-84da-a0c4dd310fcc",
      "sourceURL": "https://developers.deepgram.com/reference/api-rate-limits",
      "url": "https://developers.deepgram.com/reference/api-rate-limits",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "If you need to create short lived tokens for `/Listen`, `/Speak`, or `/Read` API requests, you can use the [Token-based Auth API](https://developers.deepgram.com/reference/token-based-auth-api/grant-token).\n\nSend requests to the API with an `Authorization` header that references your project’s API Key:\n\n`Authorization: Token <YOUR_DEEPGRAM_API_KEY>`\n\nYou can [create a Deepgram API Key in the Deepgram Console](https://console.deepgram.com/signup?utm_source=api-ref). You must create your first API Key using the Console.\n\nAll API requests must be made over HTTPS. Calls made over plain HTTP will fail. API requests made without authentication will also fail.\n\n|  |  |\n| --- | --- |\n| **Security Scheme Type** | API Key |\n| **Header parameter name:** | Authorization |\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=udco4kqh8o98)",
    "metadata": {
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Authentication | Deepgram's Docs",
      "ogDescription": "Authenticating requests made to the Deepgram API",
      "og:description": "Authenticating requests made to the Deepgram API",
      "application-name": "Deepgram's Docs",
      "description": "Authenticating requests made to the Deepgram API",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "ogTitle": "Authentication | Deepgram's Docs",
      "title": "Authentication | Deepgram's Docs",
      "twitter:title": "Authentication | Deepgram's Docs",
      "language": "en",
      "twitter:description": "Authenticating requests made to the Deepgram API",
      "scrapeId": "ca84bf85-f06b-4ca2-9e59-4b798877632b",
      "sourceURL": "https://developers.deepgram.com/reference/authentication",
      "url": "https://developers.deepgram.com/reference/authentication",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram’s APIs allows you to interact with Deepgram programmatically. You can use our APIs to:\n\n- Build a [Voice Agent](https://developers.deepgram.com/reference/build-a-voice-agent)\n\n- Transcribe & analyze [pre-recorded audio](https://developers.deepgram.com/reference/listen-file)\n\n- Transcribe [streaming audio](https://developers.deepgram.com/reference/listen-live)\n\n- Transform [text to speech](https://developers.deepgram.com/reference/text-to-speech-api)\n\n- Transform [streaming text to speech](https://developers.deepgram.com/reference/transform-text-to-speech-websocket)\n\n- Analyze [text](https://developers.deepgram.com/reference/analyze-text)\n\n- Administer your Deepgram account:\n  - Manage [projects](https://developers.deepgram.com/reference/get-projects) and project [members](https://developers.deepgram.com/reference/get-members)\n  - Manage project [invitations](https://developers.deepgram.com/reference/list-invites)\n  - Manage user [scopes](https://developers.deepgram.com/reference/get-member-scopes)\n  - Retrieve billing [balances](https://developers.deepgram.com/reference/get-all-balances)\n  - Retrieve usage [summaries](https://developers.deepgram.com/reference/get-all-requests)\n  - Manage [API keys](https://developers.deepgram.com/reference/list-keys)\n  - Manage [self-hosted distribution credentials](https://developers.deepgram.com/reference/list-credentials)\n  - Retrieve [Model Metadata](https://developers.deepgram.com/reference/get-models)\n- Create [Temporary API Tokens](https://developers.deepgram.com/reference/token-based-auth-api/grant-token)\n\n\nTo create your first API key refer to our Guide [Creating API Keys](https://developers.deepgram.com/docs/create-additional-api-keys).\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=pcznmilwxit7)",
    "metadata": {
      "language": "en",
      "twitter:title": "Deepgram API Overview | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "og:title": "Deepgram API Overview | Deepgram's Docs",
      "ogTitle": "Deepgram API Overview | Deepgram's Docs",
      "title": "Deepgram API Overview | Deepgram's Docs",
      "twitter:card": "summary",
      "generator": "https://buildwithfern.com",
      "scrapeId": "91df85a9-38f5-4a3d-af6a-7398f6deb590",
      "sourceURL": "https://developers.deepgram.com/reference/deepgram-api-overview",
      "url": "https://developers.deepgram.com/reference/deepgram-api-overview",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves details about the specified balance\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nbalance\\_idstringRequired\n\nThe unique identifier of the balance\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA specific balance\n\nbalance\\_idstringOptional\n\nThe unique identifier of the balance\n\namountintegerOptionalDefaults to `0`\n\nThe amount of the balance\n\nunitsstringOptional\n\nThe units of the balance, such as “USD”\n\npurchase\\_order\\_idstringOptional\n\nDescription or reference of the purchase\n\n### Errors\n\n400\n\nBalances Get Request Bad Request Error\n\n403\n\nBalances Get Request Forbidden Error\n\n404\n\nBalances Get Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=hgjx1r3lnk30)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "og:title": "Get a Project Balance | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "ogTitle": "Get a Project Balance | Deepgram's Docs",
      "title": "Get a Project Balance | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "twitter:title": "Get a Project Balance | Deepgram's Docs",
      "scrapeId": "0e44e6b9-433d-4426-b1f2-5d9620ec36f6",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/balances/get",
      "url": "https://developers.deepgram.com/reference/management-api/balances/get",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Generates a list of outstanding balances for the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA list of outstanding balances\n\nbalanceslist of objectsOptional\n\nShow 4 properties\n\n### Errors\n\n400\n\nBalances List Request Bad Request Error\n\n403\n\nBalances List Request Forbidden Error\n\n404\n\nBalances List Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=qk3jxj73j5mc)",
    "metadata": {
      "title": "Get Project Balances | Deepgram's Docs",
      "ogTitle": "Get Project Balances | Deepgram's Docs",
      "twitter:title": "Get Project Balances | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "application-name": "Deepgram's Docs",
      "og:title": "Get Project Balances | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "scrapeId": "17186b06-e68d-4272-9797-addce43456e7",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/balances/list",
      "url": "https://developers.deepgram.com/reference/management-api/balances/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Generates an invite for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Request\n\nThis endpoint expects an object.\n\nemailstringRequired\n\nThe email address of the invitee\n\nscopestringRequired\n\nThe scope of the invitee\n\n### Response\n\nThe invite was successfully generated\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n400\n\nInvitations Create Request Bad Request Error\n\n401\n\nInvitations Create Request Unauthorized Error\n\n403\n\nInvitations Create Request Forbidden Error\n\n404\n\nInvitations Create Request Not Found Error\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=20cc4341-2b15-49cd-bc7e-67dee7cd24b1&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=7bdc902c-fa39-43e4-a02e-3b34d6c35a05&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Freference%2Fmanagement-api%2Finvitations%2Fcreate&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=20cc4341-2b15-49cd-bc7e-67dee7cd24b1&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=7bdc902c-fa39-43e4-a02e-3b34d6c35a05&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Freference%2Fmanagement-api%2Finvitations%2Fcreate&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=awz1ui59k2bf)",
    "metadata": {
      "og:title": "Create a Project Invite | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "ogTitle": "Create a Project Invite | Deepgram's Docs",
      "title": "Create a Project Invite | Deepgram's Docs",
      "twitter:title": "Create a Project Invite | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "6068934e-78f3-4e0c-8530-794599726dd9",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/invitations/create",
      "url": "https://developers.deepgram.com/reference/management-api/invitations/create",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deletes an invite for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nemailstringRequired\n\nThe email address of the member\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nThe invite was successfully deleted\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n400\n\nInvitations Delete Request Bad Request Error\n\n401\n\nInvitations Delete Request Unauthorized Error\n\n403\n\nInvitations Delete Request Forbidden Error\n\n404\n\nInvitations Delete Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=v5z35ktiienl)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "language": "en",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": "Delete a Project Invite | Deepgram's Docs",
      "twitter:title": "Delete a Project Invite | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Delete a Project Invite | Deepgram's Docs",
      "title": "Delete a Project Invite | Deepgram's Docs",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "scrapeId": "3d33d89a-82ea-46b6-a9c0-91d1e1894612",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/invitations/delete",
      "url": "https://developers.deepgram.com/reference/management-api/invitations/delete",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Removes the authenticated account from the specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nSuccessfully removed account from project\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n400\n\nInvitations Leave Request Bad Request Error\n\n401\n\nInvitations Leave Request Unauthorized Error\n\n403\n\nInvitations Leave Request Forbidden Error\n\n404\n\nInvitations Leave Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=zbz0axnyk0vl)",
    "metadata": {
      "language": "en",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "ogTitle": "Leave a Project | Deepgram's Docs",
      "twitter:title": "Leave a Project | Deepgram's Docs",
      "title": "Leave a Project | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "og:title": "Leave a Project | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "scrapeId": "121aa091-da0b-4dd6-b028-733027ec9bcb",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/invitations/leave",
      "url": "https://developers.deepgram.com/reference/management-api/invitations/leave",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Generates a list of invites for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA list of invites for a specific project\n\ninviteslist of objectsOptional\n\nShow 2 properties\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=pls0ab9w7fc0)",
    "metadata": {
      "title": "List Project Invites | Deepgram's Docs",
      "og:title": "List Project Invites | Deepgram's Docs",
      "twitter:title": "List Project Invites | Deepgram's Docs",
      "ogTitle": "List Project Invites | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "application-name": "Deepgram's Docs",
      "scrapeId": "959ebdef-92f9-4be9-9dbd-ce53c447b810",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/invitations/list",
      "url": "https://developers.deepgram.com/reference/management-api/invitations/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Creates a new API key with specified settings for the project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstatusenumOptional\n\nOnly return keys with a specific status\n\nAllowed values:activeexpired\n\n### Request\n\nThis endpoint expects any.\n\n### Response\n\nAPI key created successfully\n\napi\\_key\\_idstringOptional\n\nThe unique identifier of the API key\n\nkeystringOptional\n\nThe API key\n\ncommentstringOptional\n\nA comment for the API key\n\nscopeslist of stringsOptional\n\nThe scopes for the API key\n\ntagslist of stringsOptional\n\nThe tags for the API key\n\nexpiration\\_datedatetimeOptional\n\nThe expiration date of the API key\n\n### Errors\n\n403\n\nKeys Create Request Forbidden Error\n\n404\n\nKeys Create Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=c3i2hfv1ub)",
    "metadata": {
      "ogTitle": "Create a Project Key | Deepgram's Docs",
      "og:title": "Create a Project Key | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "twitter:title": "Create a Project Key | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "title": "Create a Project Key | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "92f62807-820d-4ec7-b4c3-2c3d221f8d0e",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/keys/create",
      "url": "https://developers.deepgram.com/reference/management-api/keys/create",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deletes an API key for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nkey\\_idstringRequired\n\nThe unique identifier of the API key\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nAPI key deleted\n\nmessagestringOptional\n\nA message indicating that the API key was deleted\n\n### Errors\n\n403\n\nKeys Delete Request Forbidden Error\n\n404\n\nKeys Delete Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=88pwbdkb3vdb)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": "Delete a Project Key | Deepgram's Docs",
      "title": "Delete a Project Key | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "og:title": "Delete a Project Key | Deepgram's Docs",
      "twitter:title": "Delete a Project Key | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "application-name": "Deepgram's Docs",
      "scrapeId": "d3fec8bd-e912-4d58-aca7-dbed42e7fbeb",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/keys/delete",
      "url": "https://developers.deepgram.com/reference/management-api/keys/delete",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves information about a specified API key\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nkey\\_idstringRequired\n\nThe unique identifier of the API key\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA specific API key\n\nitemobjectOptional\n\nShow 1 properties\n\n### Errors\n\n403\n\nKeys Get Request Forbidden Error\n\n404\n\nKeys Get Request Not Found Error\n\n![](https://t.co/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=7352bfe1-d897-47aa-9a38-26a92c7d5b11&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=99c16229-f35a-4908-8f9f-f643d5aa3592&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Freference%2Fmanagement-api%2Fkeys%2Fget&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)![](https://analytics.twitter.com/1/i/adsct?bci=4&dv=America%2FAdak%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261280%261024%264%2624%261280%261024%260%26na&eci=3&event=%7B%7D&event_id=7352bfe1-d897-47aa-9a38-26a92c7d5b11&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=99c16229-f35a-4908-8f9f-f643d5aa3592&tw_document_href=https%3A%2F%2Fdevelopers.deepgram.com%2Freference%2Fmanagement-api%2Fkeys%2Fget&tw_iframe_status=0&txn_id=o6k8v&type=javascript&version=2.3.33)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=hr1rfik9v36e)",
    "metadata": {
      "title": "Get a Project Key | Deepgram's Docs",
      "ogTitle": "Get a Project Key | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Get a Project Key | Deepgram's Docs",
      "language": "en",
      "application-name": "Deepgram's Docs",
      "twitter:title": "Get a Project Key | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "scrapeId": "b46135ab-9ec7-44d5-9151-6c86d2314103",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/keys/get",
      "url": "https://developers.deepgram.com/reference/management-api/keys/get",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves all API keys associated with the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstatusenumOptional\n\nOnly return keys with a specific status\n\nAllowed values:activeexpired\n\n### Response\n\nA list of API keys\n\napi\\_keyslist of lists of objectsOptional\n\nShow 2 properties\n\n### Errors\n\n403\n\nKeys List Request Forbidden Error\n\n404\n\nKeys List Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=e2bf6op0pb67)",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "List Project Keys | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "language": "en",
      "og:title": "List Project Keys | Deepgram's Docs",
      "title": "List Project Keys | Deepgram's Docs",
      "ogTitle": "List Project Keys | Deepgram's Docs",
      "scrapeId": "8fe781ac-2d39-48af-b7aa-396f472e9060",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/keys/list",
      "url": "https://developers.deepgram.com/reference/management-api/keys/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Removes a member from the project using their unique member ID\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nmember\\_idstringRequired\n\nThe unique identifier of the Member\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nDelete the specific member from the project\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n403\n\nMembers Delete Request Forbidden Error\n\n404\n\nMembers Delete Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=g2mqec5a9gsb)",
    "metadata": {
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "title": "Delete a Project Member | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Delete a Project Member | Deepgram's Docs",
      "og:title": "Delete a Project Member | Deepgram's Docs",
      "twitter:card": "summary",
      "language": "en",
      "twitter:title": "Delete a Project Member | Deepgram's Docs",
      "scrapeId": "08c40562-f962-4d08-af65-ce2568169747",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/members/delete",
      "url": "https://developers.deepgram.com/reference/management-api/members/delete",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves a list of account objects for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA list of account objects\n\nmemberslist of objectsOptional\n\nShow 1 properties\n\n### Errors\n\n403\n\nMembers List Request Forbidden Error\n\n404\n\nMembers List Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=sltu60pqdcb4)",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "og:title": "List Project Members | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "theme-color": "#f5f5f7",
      "title": "List Project Members | Deepgram's Docs",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "ogTitle": "List Project Members | Deepgram's Docs",
      "twitter:title": "List Project Members | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "6063fe54-633c-4bdb-8afc-31d181223984",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/members/list",
      "url": "https://developers.deepgram.com/reference/management-api/members/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns metadata for a specific public model\n\n### Path parameters\n\nmodel\\_idstringRequired\n\nThe specific UUID of the model\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA model object that can be either STT or TTS\n\nobject\n\nShow 9 properties\n\nOR\n\nobject\n\nShow 7 properties\n\n### Errors\n\n400\n\nModels Get Request Bad Request Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=rnwrl6bg9s37)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "title": "Get a specific Model | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Get a specific Model | Deepgram's Docs",
      "ogTitle": "Get a specific Model | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Get a specific Model | Deepgram's Docs",
      "scrapeId": "499bd210-7db7-4c7d-9729-fd702e6e58e2",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/models/get",
      "url": "https://developers.deepgram.com/reference/management-api/models/get",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns metadata on all the latest public models. To retrieve custom models, use the Get Projects Models endpoint\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\ninclude\\_outdatedbooleanOptional\n\nreturns non-latest versions of models\n\n### Response\n\nA list of all public models\n\nsttlist of objectsOptional\n\nShow 9 properties\n\nttslist of objectsOptional\n\nShow 7 properties\n\n### Errors\n\n400\n\nModels List Request Bad Request Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=rps9lbf0hc62)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "ogTitle": "List Models | Deepgram's Docs",
      "language": "en",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": "List Models | Deepgram's Docs",
      "twitter:card": "summary",
      "og:title": "List Models | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:title": "List Models | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "scrapeId": "a875503e-8b3f-4e4a-8e8c-66d38fe0c37b",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/models/list",
      "url": "https://developers.deepgram.com/reference/management-api/models/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deletes the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA project\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n400\n\nProjects Delete Request Bad Request Error\n\n403\n\nProjects Delete Request Forbidden Error\n\n404\n\nProjects Delete Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=nh3fsssytwx0)",
    "metadata": {
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Delete a Project | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "ogTitle": "Delete a Project | Deepgram's Docs",
      "title": "Delete a Project | Deepgram's Docs",
      "twitter:title": "Delete a Project | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "scrapeId": "91e0f633-c247-43ed-8299-4e2f2892b9de",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/delete",
      "url": "https://developers.deepgram.com/reference/management-api/projects/delete",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns metadata for a specific model\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nmodel\\_idstringRequired\n\nThe specific UUID of the model\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA model object that can be either STT or TTS\n\nobject\n\nShow 9 properties\n\nOR\n\nobject\n\nShow 7 properties\n\n### Errors\n\n400\n\nProjects Get Model Request Bad Request Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=r46pj8o0fhad)",
    "metadata": {
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "language": "en",
      "twitter:title": "Get a Project Model | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Get a Project Model | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "og:title": "Get a Project Model | Deepgram's Docs",
      "title": "Get a Project Model | Deepgram's Docs",
      "scrapeId": "38554c10-350f-49de-883c-8b1a16d4c72b",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/get-model",
      "url": "https://developers.deepgram.com/reference/management-api/projects/get-model",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves information about the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nlimitintegerOptional `>=1` `<=1000` Defaults to `10`\n\nNumber of results to return per page. Default 10. Range \\[1,1000\\]\n\npageintegerOptional\n\nNavigate and return the results to retrieve specific portions of information of the response\n\n### Response\n\nA project\n\nproject\\_idstringOptional\n\nThe unique identifier of the project\n\nmip\\_opt\\_outbooleanOptional\n\nModel Improvement Program opt-out\n\nnamestringOptional\n\nThe name of the project\n\n### Errors\n\n400\n\nProjects Get Request Bad Request Error\n\n403\n\nProjects Get Request Forbidden Error\n\n404\n\nProjects Get Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=j286pbap6eds)",
    "metadata": {
      "title": "Get a Project | Deepgram's Docs",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": "Get a Project | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Get a Project | Deepgram's Docs",
      "og:title": "Get a Project | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "theme-color": "#f5f5f7",
      "scrapeId": "82455e52-ac51-4de1-a051-a7436d234570",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/get",
      "url": "https://developers.deepgram.com/reference/management-api/projects/get",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns metadata on all the latest models that a specific project has access to, including non-public models\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\ninclude\\_outdatedbooleanOptional\n\nreturns non-latest versions of models\n\n### Response\n\nA list of models\n\nsttlist of lists of objectsOptional\n\nShow 9 properties\n\nttslist of lists of objectsOptional\n\nShow 7 properties\n\n### Errors\n\n400\n\nProjects List Models Request Bad Request Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=p2vz6x92joy4)",
    "metadata": {
      "language": "en",
      "title": "List All Project Models | Deepgram's Docs",
      "og:title": "List All Project Models | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "List All Project Models | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:title": "List All Project Models | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "scrapeId": "f9809798-acbf-41a9-ba99-1c346cb15996",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/list-models",
      "url": "https://developers.deepgram.com/reference/management-api/projects/list-models",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves basic information about the projects associated with the API key\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA list of projects\n\nprojectslist of objectsOptional\n\nShow 2 properties\n\n### Errors\n\n403\n\nProjects List Request Forbidden Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=ulfgb3r502j6)",
    "metadata": {
      "og:title": "List Projects | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "List Projects | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "twitter:title": "List Projects | Deepgram's Docs",
      "title": "List Projects | Deepgram's Docs",
      "language": "en",
      "scrapeId": "7cc34978-e3e6-4ead-9db5-2559daf313e4",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/list",
      "url": "https://developers.deepgram.com/reference/management-api/projects/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Updates the name or other properties of an existing project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Request\n\nThis endpoint expects an object.\n\nnamestringOptional\n\nThe name of the project\n\n### Response\n\nA project\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n400\n\nProjects Update Request Bad Request Error\n\n403\n\nProjects Update Request Forbidden Error\n\n404\n\nProjects Update Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=2h0gnjmgufzq)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "title": "Update a Project | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Update a Project | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Update a Project | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "ogTitle": "Update a Project | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "scrapeId": "7b1ed3c8-ea88-4712-9caf-d3f933a9bbdd",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/projects/update",
      "url": "https://developers.deepgram.com/reference/management-api/projects/update",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns the original purchased amount on an order transaction\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nlimitintegerOptional `>=1` `<=1000` Defaults to `10`\n\nNumber of results to return per page. Default 10. Range \\[1,1000\\]\n\n### Response\n\nSuccessful response with orders list\n\norderslist of objectsOptional\n\nShow 6 properties\n\n### Errors\n\n400\n\nPurchases List Request Bad Request Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=orvwbgp0o6nq)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "ogTitle": "List Project Purchases | Deepgram's Docs",
      "og:title": "List Project Purchases | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "List Project Purchases | Deepgram's Docs",
      "title": "List Project Purchases | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "5d3f1877-b12a-4cce-9565-e51f32c8c683",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/purchases/list",
      "url": "https://developers.deepgram.com/reference/management-api/purchases/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves a list of scopes for a specific member\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nmember\\_idstringRequired\n\nThe unique identifier of the Member\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA list of scopes for a specific member\n\nscopeslist of stringsOptional\n\nThe API scopes of the member\n\n### Errors\n\n403\n\nScopes List Request Forbidden Error\n\n404\n\nScopes List Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=5kv6ip4ihmc1)",
    "metadata": {
      "application-name": "Deepgram's Docs",
      "ogTitle": "List Project Member Scopes | Deepgram's Docs",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "og:title": "List Project Member Scopes | Deepgram's Docs",
      "twitter:title": "List Project Member Scopes | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": "List Project Member Scopes | Deepgram's Docs",
      "scrapeId": "6e26fdb6-caad-4b63-81ee-f188e9002418",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/scopes/list",
      "url": "https://developers.deepgram.com/reference/management-api/scopes/list",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Updates the scopes for a specific member\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nmember\\_idstringRequired\n\nThe unique identifier of the Member\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Request\n\nThis endpoint expects an object.\n\nscopestringRequired\n\nA scope to update\n\n### Response\n\nUpdated the scopes for a specific member\n\nmessagestringOptional\n\nconfirmation message\n\n### Errors\n\n403\n\nScopes Update Request Forbidden Error\n\n404\n\nScopes Update Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=nbvid91e4j73)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Update Project Member Scopes | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "title": "Update Project Member Scopes | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "language": "en",
      "ogTitle": "Update Project Member Scopes | Deepgram's Docs",
      "twitter:card": "summary",
      "og:title": "Update Project Member Scopes | Deepgram's Docs",
      "scrapeId": "5f4b87b8-6667-4bed-a901-2731006acebc",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/scopes/update",
      "url": "https://developers.deepgram.com/reference/management-api/scopes/update",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves the usage breakdown for a specific project, with various filter options by API feature or by groupings. Setting a feature (e.g. diarize) to true includes requests that used that feature, while false excludes requests that used it. Multiple true filters are combined with OR logic, while false filters use AND logic.\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstartstringOptional `format: \"date\"`\n\nStart date of the requested date range. Format accepted is YYYY-MM-DD\n\nendstringOptional `format: \"date\"`\n\nEnd date of the requested date range. Format accepted is YYYY-MM-DD\n\ngroupingenumOptional\n\nCommon usage grouping parameters\n\nShow 7 enum values\n\naccessorstringOptional\n\nFilter for requests where a specific accessor was used\n\nalternativesbooleanOptional\n\nFilter for requests where alternatives were used\n\ncallback\\_methodbooleanOptional\n\nFilter for requests where callback method was used\n\ncallbackbooleanOptional\n\nFilter for requests where callback was used\n\nchannelsbooleanOptional\n\nFilter for requests where channels were used\n\ncustom\\_intent\\_modebooleanOptional\n\nFilter for requests where custom intent mode was used\n\ncustom\\_intentbooleanOptional\n\nFilter for requests where custom intent was used\n\ncustom\\_topic\\_modebooleanOptional\n\nFilter for requests where custom topic mode was used\n\ncustom\\_topicbooleanOptional\n\nFilter for requests where custom topic was used\n\ndeploymentenumOptional\n\nFilter for requests where a specific deployment was used\n\nAllowed values:hostedbetaself-hosted\n\ndetect\\_entitiesbooleanOptional\n\nFilter for requests where detect entities was used\n\ndetect\\_languagebooleanOptional\n\nFilter for requests where detect language was used\n\ndiarizebooleanOptional\n\nFilter for requests where diarize was used\n\ndictationbooleanOptional\n\nFilter for requests where dictation was used\n\nencodingbooleanOptional\n\nFilter for requests where encoding was used\n\nendpointenumOptional\n\nFilter for requests where a specific endpoint was used\n\nAllowed values:listenreadspeakagent\n\nextrabooleanOptional\n\nFilter for requests where extra was used\n\nfiller\\_wordsbooleanOptional\n\nFilter for requests where filler words was used\n\nintentsbooleanOptional\n\nFilter for requests where intents was used\n\nkeytermbooleanOptional\n\nFilter for requests where keyterm was used\n\nkeywordsbooleanOptional\n\nFilter for requests where keywords was used\n\nlanguagebooleanOptional\n\nFilter for requests where language was used\n\nmeasurementsbooleanOptional\n\nFilter for requests where measurements were used\n\nmethodenumOptional\n\nFilter for requests where a specific method was used\n\nAllowed values:syncasyncstreaming\n\nmodelstringOptional\n\nFilter for requests where a specific model uuid was used\n\nmultichannelbooleanOptional\n\nFilter for requests where multichannel was used\n\nnumeralsbooleanOptional\n\nFilter for requests where numerals were used\n\nparagraphsbooleanOptional\n\nFilter for requests where paragraphs were used\n\nprofanity\\_filterbooleanOptional\n\nFilter for requests where profanity filter was used\n\npunctuatebooleanOptional\n\nFilter for requests where punctuate was used\n\nredactbooleanOptional\n\nFilter for requests where redact was used\n\nreplacebooleanOptional\n\nFilter for requests where replace was used\n\nsample\\_ratebooleanOptional\n\nFilter for requests where sample rate was used\n\nsearchbooleanOptional\n\nFilter for requests where search was used\n\nsentimentbooleanOptional\n\nFilter for requests where sentiment was used\n\nsmart\\_formatbooleanOptional\n\nFilter for requests where smart format was used\n\nsummarizebooleanOptional\n\nFilter for requests where summarize was used\n\ntagstringOptional\n\nFilter for requests where a specific tag was used\n\ntopicsbooleanOptional\n\nFilter for requests where topics was used\n\nutt\\_splitbooleanOptional\n\nFilter for requests where utt split was used\n\nutterancesbooleanOptional\n\nFilter for requests where utterances was used\n\nversionbooleanOptional\n\nFilter for requests where version was used\n\n### Response\n\nUsage breakdown response\n\nstartstring `format: \"date\"`\n\nStart date of the usage period\n\nendstring `format: \"date\"`\n\nEnd date of the usage period\n\nresolutionobject\n\nShow 2 properties\n\nresultslist of objects\n\nShow 8 properties\n\n### Errors\n\n400\n\nUsage Get Breakdown Request Bad Request Error\n\n401\n\nUsage Get Breakdown Request Unauthorized Error\n\n404\n\nUsage Get Breakdown Request Not Found Error",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "og:title": "Get Project Usage Breakdown | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Get Project Usage Breakdown | Deepgram's Docs",
      "title": "Get Project Usage Breakdown | Deepgram's Docs",
      "language": "en",
      "twitter:card": "summary",
      "twitter:title": "Get Project Usage Breakdown | Deepgram's Docs",
      "scrapeId": "e4388d69-83ba-4893-9b99-d3d32b8128b0",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/usage/get-breakdown",
      "url": "https://developers.deepgram.com/reference/management-api/usage/get-breakdown",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves a specific request for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\nrequest\\_idstringRequired\n\nThe unique identifier of the request\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nA specific request for a specific project\n\nrequestobjectOptional\n\nA single request\n\nShow 9 properties\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=43f9d0h7bmql)",
    "metadata": {
      "og:title": "Get a Project Request | Deepgram's Docs",
      "twitter:title": "Get a Project Request | Deepgram's Docs",
      "language": "en",
      "title": "Get a Project Request | Deepgram's Docs",
      "ogTitle": "Get a Project Request | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "scrapeId": "554be2db-5d2f-444b-9035-4f4ea125aacc",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/usage/get-request",
      "url": "https://developers.deepgram.com/reference/management-api/usage/get-request",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Retrieves the usage for a specific project. Use Get Project Usage Breakdown for a more comprehensive usage summary.\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstartstringOptional `format: \"date\"`\n\nStart date of the requested date range. Format accepted is YYYY-MM-DD\n\nendstringOptional `format: \"date\"`\n\nEnd date of the requested date range. Format accepted is YYYY-MM-DD\n\naccessorstringOptional\n\nFilter for requests where a specific accessor was used\n\nalternativesbooleanOptional\n\nFilter for requests where alternatives were used\n\ncallback\\_methodbooleanOptional\n\nFilter for requests where callback method was used\n\ncallbackbooleanOptional\n\nFilter for requests where callback was used\n\nchannelsbooleanOptional\n\nFilter for requests where channels were used\n\ncustom\\_intent\\_modebooleanOptional\n\nFilter for requests where custom intent mode was used\n\ncustom\\_intentbooleanOptional\n\nFilter for requests where custom intent was used\n\ncustom\\_topic\\_modebooleanOptional\n\nFilter for requests where custom topic mode was used\n\ncustom\\_topicbooleanOptional\n\nFilter for requests where custom topic was used\n\ndeploymentenumOptional\n\nFilter for requests where a specific deployment was used\n\nAllowed values:hostedbetaself-hosted\n\ndetect\\_entitiesbooleanOptional\n\nFilter for requests where detect entities was used\n\ndetect\\_languagebooleanOptional\n\nFilter for requests where detect language was used\n\ndiarizebooleanOptional\n\nFilter for requests where diarize was used\n\ndictationbooleanOptional\n\nFilter for requests where dictation was used\n\nencodingbooleanOptional\n\nFilter for requests where encoding was used\n\nendpointenumOptional\n\nFilter for requests where a specific endpoint was used\n\nAllowed values:listenreadspeakagent\n\nextrabooleanOptional\n\nFilter for requests where extra was used\n\nfiller\\_wordsbooleanOptional\n\nFilter for requests where filler words was used\n\nintentsbooleanOptional\n\nFilter for requests where intents was used\n\nkeytermbooleanOptional\n\nFilter for requests where keyterm was used\n\nkeywordsbooleanOptional\n\nFilter for requests where keywords was used\n\nlanguagebooleanOptional\n\nFilter for requests where language was used\n\nmeasurementsbooleanOptional\n\nFilter for requests where measurements were used\n\nmethodenumOptional\n\nFilter for requests where a specific method was used\n\nAllowed values:syncasyncstreaming\n\nmodelstringOptional\n\nFilter for requests where a specific model uuid was used\n\nmultichannelbooleanOptional\n\nFilter for requests where multichannel was used\n\nnumeralsbooleanOptional\n\nFilter for requests where numerals were used\n\nparagraphsbooleanOptional\n\nFilter for requests where paragraphs were used\n\nprofanity\\_filterbooleanOptional\n\nFilter for requests where profanity filter was used\n\npunctuatebooleanOptional\n\nFilter for requests where punctuate was used\n\nredactbooleanOptional\n\nFilter for requests where redact was used\n\nreplacebooleanOptional\n\nFilter for requests where replace was used\n\nsample\\_ratebooleanOptional\n\nFilter for requests where sample rate was used\n\nsearchbooleanOptional\n\nFilter for requests where search was used\n\nsentimentbooleanOptional\n\nFilter for requests where sentiment was used\n\nsmart\\_formatbooleanOptional\n\nFilter for requests where smart format was used\n\nsummarizebooleanOptional\n\nFilter for requests where summarize was used\n\ntagstringOptional\n\nFilter for requests where a specific tag was used\n\ntopicsbooleanOptional\n\nFilter for requests where topics was used\n\nutt\\_splitbooleanOptional\n\nFilter for requests where utt split was used\n\nutterancesbooleanOptional\n\nFilter for requests where utterances was used\n\nversionbooleanOptional\n\nFilter for requests where version was used\n\n### Response\n\nUsage Summary\n\nstartstringOptional `format: \"date\"`\n\nendstringOptional `format: \"date\"`\n\nresolutionobjectOptional\n\nShow 2 properties\n\n### Errors\n\n400\n\nUsage Get Request Bad Request Error\n\n401\n\nUsage Get Request Unauthorized Error\n\n403\n\nUsage Get Request Forbidden Error\n\n404\n\nUsage Get Request Not Found Error",
    "metadata": {
      "ogTitle": "Get Project Usage | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "og:title": "Get Project Usage | Deepgram's Docs",
      "twitter:title": "Get Project Usage | Deepgram's Docs",
      "title": "Get Project Usage | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "language": "en",
      "scrapeId": "50eb1be8-086a-49a0-9c2d-a5651da0ad9c",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/usage/get",
      "url": "https://developers.deepgram.com/reference/management-api/usage/get",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Lists the features, models, tags, languages, and processing method used for requests in the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstartstringOptional `format: \"date\"`\n\nStart date of the requested date range. Format accepted is YYYY-MM-DD\n\nendstringOptional `format: \"date\"`\n\nEnd date of the requested date range. Format accepted is YYYY-MM-DD\n\n### Response\n\nA list of fields for a specific project\n\ntagslist of stringsOptional\n\nList of tags associated with the project\n\nmodelslist of objectsOptional\n\nList of models available for the project.\n\nShow 4 properties\n\nprocessing\\_methodslist of stringsOptional\n\nProcessing methods supported by the API\n\nfeatureslist of stringsOptional\n\nAPI features available to the project\n\n### Errors\n\n400\n\nUsage List Fields Request Bad Request Error\n\n401\n\nUsage List Fields Request Unauthorized Error\n\n403\n\nUsage List Fields Request Forbidden Error\n\n404\n\nUsage List Fields Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=khsn7zhqpnw6)",
    "metadata": {
      "ogTitle": "List Project Usage Fields | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "List Project Usage Fields | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "title": "List Project Usage Fields | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "List Project Usage Fields | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "scrapeId": "b8841980-9e4f-4200-b6b3-c9e081d717db",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/usage/list-fields",
      "url": "https://developers.deepgram.com/reference/management-api/usage/list-fields",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Generates a list of requests for a specific project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nstartdatetimeOptional\n\nStart date of the requested date range. Formats accepted are YYYY-MM-DD, YYYY-MM-DDTHH:MM:SS, or YYYY-MM-DDTHH:MM:SS+HH:MM\n\nenddatetimeOptional\n\nEnd date of the requested date range. Formats accepted are YYYY-MM-DD, YYYY-MM-DDTHH:MM:SS, or YYYY-MM-DDTHH:MM:SS+HH:MM\n\nlimitintegerOptional `>=1` `<=1000` Defaults to `10`\n\nNumber of results to return per page. Default 10. Range \\[1,1000\\]\n\npageintegerOptional\n\nNavigate and return the results to retrieve specific portions of information of the response\n\n### Response\n\nA list of requests for a specific project\n\npageintegerOptional\n\nThe page number of the paginated response\n\nlimitintegerOptional\n\nThe number of results per page\n\nrequestslist of objectsOptional\n\nShow 9 properties\n\n### Errors\n\n400\n\nUsage List Requests Request Bad Request Error\n\n403\n\nUsage List Requests Request Forbidden Error\n\n404\n\nUsage List Requests Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=b3mv5fhtyqj0)",
    "metadata": {
      "theme-color": "#f5f5f7",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "ogTitle": "List Project Requests | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "title": "List Project Requests | Deepgram's Docs",
      "language": "en",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "List Project Requests | Deepgram's Docs",
      "twitter:title": "List Project Requests | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "scrapeId": "545218da-03a4-4230-8737-929fe07e1a4e",
      "sourceURL": "https://developers.deepgram.com/reference/management-api/usage/list-requests",
      "url": "https://developers.deepgram.com/reference/management-api/usage/list-requests",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Creates a set of distribution credentials for the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nscopesenumOptional\n\nList of permission scopes for the credentials\n\nShow 8 enum values\n\nprovider\"quay\"Required\n\nThe provider of the distribution service\n\n### Request\n\nThis endpoint expects an object.\n\ncommentstringOptional\n\nOptional comment about the credentials\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=iq27ahbn6rc)",
    "metadata": {
      "title": "Create a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "ogTitle": "Create a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "og:title": "Create a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Create a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "scrapeId": "df0188d1-c3b5-4b90-b9ee-e34b8ada60e6",
      "sourceURL": "https://developers.deepgram.com/reference/self-hosted-api/create-credentials",
      "url": "https://developers.deepgram.com/reference/self-hosted-api/create-credentials",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deletes a set of distribution credentials for the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\ndistribution\\_credentials\\_idstringRequired\n\nThe UUID of the distribution credentials\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nSingle distribution credential\n\nmemberobject\n\nShow 2 properties\n\ndistribution\\_credentialsobject\n\nShow 5 properties\n\n### Errors\n\n403\n\nSelf Hosted API Delete Credentials Request Forbidden Error\n\n404\n\nSelf Hosted API Delete Credentials Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=txix4onnzlzm)",
    "metadata": {
      "title": "Delete a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Delete a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "og:title": "Delete a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "language": "en",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": "Delete a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "scrapeId": "55ca8fe8-46c7-407a-8af4-45a2ee353c68",
      "sourceURL": "https://developers.deepgram.com/reference/self-hosted-api/delete-credentials",
      "url": "https://developers.deepgram.com/reference/self-hosted-api/delete-credentials",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Returns a set of distribution credentials for the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\ndistribution\\_credentials\\_idstringRequired\n\nThe UUID of the distribution credentials\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nSingle distribution credential\n\nmemberobject\n\nShow 2 properties\n\ndistribution\\_credentialsobject\n\nShow 5 properties\n\n### Errors\n\n403\n\nSelf Hosted API Get Credentials Request Forbidden Error\n\n404\n\nSelf Hosted API Get Credentials Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=r1ur6dt4kjcu)",
    "metadata": {
      "language": "en",
      "og:title": "Get a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "ogTitle": "Get a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Get a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "title": "Get a Project Self-Hosted Distribution Credential | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "scrapeId": "12423cd6-7d4f-4e7d-8d95-47ba9cdad02e",
      "sourceURL": "https://developers.deepgram.com/reference/self-hosted-api/get-credentials",
      "url": "https://developers.deepgram.com/reference/self-hosted-api/get-credentials",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Lists sets of distribution credentials for the specified project\n\n### Path parameters\n\nproject\\_idstringRequired\n\nThe unique identifier of the project\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nList of distribution credentials\n\ndistribution\\_credentialslist of objectsOptional\n\nArray of distribution credentials with associated member information\n\nShow 2 properties\n\n### Errors\n\n403\n\nSelf Hosted API List Credentials Request Forbidden Error\n\n404\n\nSelf Hosted API List Credentials Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=83ho2tpkxnpf)",
    "metadata": {
      "language": "en",
      "twitter:card": "summary",
      "twitter:title": "List Project Self-Hosted Distribution Credentials | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "generator": "https://buildwithfern.com",
      "og:title": "List Project Self-Hosted Distribution Credentials | Deepgram's Docs",
      "ogTitle": "List Project Self-Hosted Distribution Credentials | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "title": "List Project Self-Hosted Distribution Credentials | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "scrapeId": "26d051c0-ad13-4ea7-9085-46c7608b7c3b",
      "sourceURL": "https://developers.deepgram.com/reference/self-hosted-api/list-credentials",
      "url": "https://developers.deepgram.com/reference/self-hosted-api/list-credentials",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram Speech to Text WebSocket\n\n## Handshake [Try it](https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming?explorer=true)\n\nGET\n\nwss://api.deepgram.com/v1/listen\n\n### Headers\n\nAuthorizationstringRequired\n\nAPI key for authentication. Format should be be either ‘token <DEEPGRAM\\_API\\_KEY>’ or ‘Bearer <JWT\\_TOKEN>’\n\n### Query parameters\n\ncallbackstringOptional\n\nURL to which we’ll make the callback request\n\ncallback\\_methodenumOptionalDefaults to `POST`\n\nHTTP method by which the callback request will be made\n\nAllowed values:POSTGETPUTDELETE\n\nchannelsstringOptionalDefaults to `1`\n\nThe number of channels in the submitted audio\n\ndiarizebooleanOptional\n\nDefaults to `false`. Recognize speaker changes. Each word in the transcript will be assigned a speaker number starting at 0\n\ndictationenumOptionalDefaults to `false`\n\nIdentify and extract key entities from content in submitted audio\n\nAllowed values:truefalse\n\nencodingenumOptional\n\nSpecify the expected encoding of your submitted audio\n\nShow 8 enum values\n\nendpointingstringOptionalDefaults to `10`\n\nIndicates how long Deepgram will wait to detect whether a speaker has finished speaking or pauses for a significant period of time. When set to a value, the streaming endpoint immediately finalizes the transcription for the processed time range and returns the transcript with a speech\\_final parameter set to true. Can also be set to false to disable endpointing\n\nextrastringOptional\n\nArbitrary key-value pairs that are attached to the API response for usage in downstream processing\n\nfiller\\_wordsenumOptionalDefaults to `false`\n\nFiller Words can help transcribe interruptions in your audio, like “uh” and “um”\n\nAllowed values:truefalse\n\ninterim\\_resultsenumOptionalDefaults to `false`\n\nSpecifies whether the streaming endpoint should provide ongoing transcription updates as more audio is received. When set to true, the endpoint sends continuous updates, meaning transcription results may evolve over time\n\nAllowed values:truefalse\n\nkeytermlist of stringsOptional\n\nKey term prompting can boost or suppress specialized terminology and brands. Only compatible with Nova-3\n\nkeywordsstringOptional\n\nKeywords can boost or suppress specialized terminology and brands\n\nlanguageenumOptionalDefaults to `en`\n\nThe [BCP-47 language tag](https://tools.ietf.org/html/bcp47) that hints at the primary spoken language. Depending on the Model you choose only certain languages are available\n\nShow 56 enum values\n\nmodelenumOptional\n\nAI model to use for the transcription\n\nShow 30 enum values\n\nmultichannelenumOptionalDefaults to `false`\n\nTranscribe each audio channel independently\n\nAllowed values:truefalse\n\nnumeralsenumOptionalDefaults to `false`\n\nConvert numbers from written format to numerical format\n\nAllowed values:truefalse\n\nprofanity\\_filterenumOptionalDefaults to `false`\n\nProfanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely\n\nAllowed values:truefalse\n\npunctuateenumOptionalDefaults to `false`\n\nAdd punctuation and capitalization to the transcript\n\nAllowed values:truefalse\n\nredactenumOptionalDefaults to `false`\n\nRedaction removes sensitive information from your transcripts\n\nShow 6 enum values\n\nreplacestringOptional\n\nSearch for terms or phrases in submitted audio and replaces them\n\nsample\\_ratestringOptional\n\nSample rate of submitted audio. Required (and only read) when a value is provided for encoding\n\nsearchstringOptional\n\nSearch for terms or phrases in submitted audio\n\nsmart\\_formatenumOptionalDefaults to `false`\n\nApply formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability\n\nAllowed values:truefalse\n\ntagstringOptional\n\nLabel your requests for the purpose of identification during usage reporting\n\nutterance\\_endstringOptional\n\nIndicates how long Deepgram will wait to send an UtteranceEnd message after a word has been transcribed. Use with interim\\_results\n\nvad\\_eventsenumOptionalDefaults to `false`\n\nIndicates that speech has started. You’ll begin receiving Speech Started messages upon speech starting\n\nAllowed values:truefalse\n\nversionstringOptionalDefaults to `latest`\n\nVersion of an AI model to use\n\n### Send\n\ntranscriptionRequeststringRequired\n\nOR\n\nlisten\\_controlMessagesRequestobjectRequired\n\nShow 3 variants\n\n### Receive\n\ntranscriptionResponseobjectRequired\n\nShow 9 properties\n\nOR\n\nobjectRequired\n\nShow 2 properties\n\nOR\n\nobjectRequired\n\nShow 7 properties\n\nOR\n\nobjectRequired\n\nShow 7 properties\n\nOR\n\nlisten\\_closeFrameobjectRequired\n\nShow 2 properties\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=jrcgm9biibe9)",
    "metadata": {
      "twitter:title": "Live Audio | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:title": "Live Audio | Deepgram's Docs",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": "Live Audio | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "title": "Live Audio | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "scrapeId": "572786c2-ffb0-4a83-bf58-6b48d73f8984",
      "sourceURL": "https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming",
      "url": "https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Transcribe audio using Deepgram’s speech-to-text API\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\ncallbackstringOptional\n\nURL to which we’ll make the callback request\n\ncallback\\_methodenumOptionalDefaults to `POST`\n\nHTTP method by which the callback request will be made\n\nAllowed values:POSTPUT\n\ncustom\\_topicstringOptional\n\nCustom topics you want the model to detect within your input audio or text if present Submit up to 100\n\ncustom\\_topic\\_modeenumOptionalDefaults to `extended`\n\nSets how the model will interpret strings submitted to the `custom_topic` param. When `strict`, the model will only return topics submitted using the `custom_topic` param. When `extended`, the model will return its own detected topics in addition to those submitted using the `custom_topic` param\n\nAllowed values:extendedstrict\n\ncustom\\_intentstringOptional\n\nCustom intents you want the model to detect within your input audio if present\n\ncustom\\_intent\\_modeenumOptionalDefaults to `extended`\n\nSets how the model will interpret intents submitted to the `custom_intent` param. When `strict`, the model will only return intents submitted using the `custom_intent` param. When `extended`, the model will return its own detected intents in addition those submitted using the `custom_intents` param\n\nAllowed values:extendedstrict\n\ndetect\\_entitiesbooleanOptionalDefaults to `false`\n\nIdentifies and extracts key entities from content in submitted audio\n\ndetect\\_languagebooleanOptionalDefaults to `false`\n\nIdentifies the dominant language spoken in submitted audio\n\ndiarizebooleanOptionalDefaults to `false`\n\nRecognize speaker changes. Each word in the transcript will be assigned a speaker number starting at 0\n\ndictationbooleanOptionalDefaults to `false`\n\nIdentify and extract key entities from content in submitted audio\n\nencodingenumOptional\n\nSpecify the expected encoding of your submitted audio\n\nShow 8 enum values\n\nextrastringOptional\n\nArbitrary key-value pairs that are attached to the API response for usage in downstream processing\n\nfiller\\_wordsbooleanOptionalDefaults to `false`\n\nFiller Words can help transcribe interruptions in your audio, like “uh” and “um”\n\nintentsbooleanOptionalDefaults to `false`\n\nRecognizes speaker intent throughout a transcript or text\n\nkeytermstringOptional\n\nKey term prompting can boost or suppress specialized terminology and brands. Only compatible with Nova-3\n\nkeywordsstringOptional\n\nKeywords can boost or suppress specialized terminology and brands\n\nlanguageenumOptionalDefaults to `en`\n\nThe [BCP-47 language tag](https://tools.ietf.org/html/bcp47) that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available\n\nShow 56 enum values\n\nmeasurementsbooleanOptionalDefaults to `false`\n\nSpoken measurements will be converted to their corresponding abbreviations\n\nmodelstring or optional enumOptional\n\nAI model used to process submitted audio\n\nShow 2 variants\n\nmultichannelbooleanOptionalDefaults to `false`\n\nTranscribe each audio channel independently\n\nnumeralsbooleanOptionalDefaults to `false`\n\nNumerals converts numbers from written format to numerical format\n\nparagraphsbooleanOptionalDefaults to `false`\n\nSplits audio into paragraphs to improve transcript readability\n\nprofanity\\_filterbooleanOptionalDefaults to `false`\n\nProfanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely\n\npunctuatebooleanOptionalDefaults to `false`\n\nAdd punctuation and capitalization to the transcript\n\nredactstringOptional\n\nRedaction removes sensitive information from your transcripts\n\nreplacestringOptional\n\nSearch for terms or phrases in submitted audio and replaces them\n\nsearchstringOptional\n\nSearch for terms or phrases in submitted audio\n\nsentimentbooleanOptionalDefaults to `false`\n\nRecognizes the sentiment throughout a transcript or text\n\nsmart\\_formatbooleanOptionalDefaults to `false`\n\nApply formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability\n\nsummarizeenumOptional\n\nSummarize content. For Listen API, supports string version option. For Read API, accepts boolean only.\n\nAllowed values:v2v1\n\ntagstringOptional\n\nLabel your requests for the purpose of identification during usage reporting\n\ntopicsbooleanOptionalDefaults to `false`\n\nDetect topics throughout a transcript or text\n\nutterancesbooleanOptionalDefaults to `false`\n\nSegments speech into meaningful semantic units\n\nutt\\_splitdoubleOptionalDefaults to `0.8`\n\nSeconds to wait before detecting a pause between words in submitted audio\n\nversionstring or optional enumOptional\n\nVersion of an AI model to use\n\nShow 2 variants\n\n### Request\n\nThis endpoint expects an object or a string.\n\nobjectRequired\n\nShow 1 properties\n\nOR\n\nstringRequired `format: \"binary\"`\n\n### Response\n\nSuccessful transcription\n\nmetadataobject\n\nShow 13 properties\n\nresultsobject\n\nShow 6 properties\n\n### Errors\n\n400\n\nSpeech to Text Listen Request Bad Request Error\n\n401\n\nSpeech to Text Listen Request Unauthorized Error\n\n402\n\nSpeech to Text Listen Request Payment Required Error\n\n403\n\nSpeech to Text Listen Request Forbidden Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=2ksxfr75gud)",
    "metadata": {
      "generator": "https://buildwithfern.com",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Pre-Recorded Audio | Deepgram's Docs",
      "language": "en",
      "ogTitle": "Pre-Recorded Audio | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "title": "Pre-Recorded Audio | Deepgram's Docs",
      "og:title": "Pre-Recorded Audio | Deepgram's Docs",
      "twitter:card": "summary",
      "scrapeId": "99ebc755-8ce4-428a-815f-32078c09715e",
      "sourceURL": "https://developers.deepgram.com/reference/speech-to-text-api/listen",
      "url": "https://developers.deepgram.com/reference/speech-to-text-api/listen",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Analyze text content using Deepgram’s text analysis API\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\ncallbackstringOptional\n\nURL to which we’ll make the callback request\n\ncallback\\_methodenumOptionalDefaults to `POST`\n\nHTTP method by which the callback request will be made\n\nAllowed values:POSTPUT\n\ncustom\\_topicstringOptional\n\nCustom topics you want the model to detect within your input audio or text if present Submit up to 100\n\ncustom\\_topic\\_modeenumOptionalDefaults to `extended`\n\nSets how the model will interpret strings submitted to the `custom_topic` param. When `strict`, the model will only return topics submitted using the `custom_topic` param. When `extended`, the model will return its own detected topics in addition to those submitted using the `custom_topic` param\n\nAllowed values:extendedstrict\n\nintentsbooleanOptionalDefaults to `false`\n\nRecognizes speaker intent throughout a transcript or text\n\nlanguageenumOptionalDefaults to `en`\n\nThe [BCP-47 language tag](https://tools.ietf.org/html/bcp47) that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available\n\nShow 56 enum values\n\nsentimentbooleanOptionalDefaults to `false`\n\nRecognizes the sentiment throughout a transcript or text\n\nsummarizeenumOptional\n\nSummarize content. For Listen API, supports string version option. For Read API, accepts boolean only.\n\nAllowed values:v2v1\n\ntopicsbooleanOptionalDefaults to `false`\n\nDetect topics throughout a transcript or text\n\n### Request\n\nThis endpoint expects an object.\n\nobjectRequired\n\nShow 2 properties\n\nOR\n\nobjectRequired\n\nShow 2 properties\n\n### Response\n\nSuccessful text analysis\n\nmetadataobject\n\nShow 1 properties\n\nresultsobject\n\nShow 4 properties\n\n### Errors\n\n400\n\nText Intelligence Text Read Request Bad Request Error\n\n401\n\nText Intelligence Text Read Request Unauthorized Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=ccsv2lh33z6x)",
    "metadata": {
      "og:title": "Analyze Text | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:title": "Analyze Text | Deepgram's Docs",
      "title": "Analyze Text | Deepgram's Docs",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Analyze Text | Deepgram's Docs",
      "scrapeId": "7591b54a-c6a9-4c1b-93d5-558e6e540d70",
      "sourceURL": "https://developers.deepgram.com/reference/text-intelligence-api/text-read",
      "url": "https://developers.deepgram.com/reference/text-intelligence-api/text-read",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram Text to Speech WebSocket\n\n## Handshake [Try it](https://developers.deepgram.com/reference/text-to-speech-api/speak-streaming?explorer=true)\n\nGET\n\nwss://api.deepgram.com/v1/speak\n\n### Headers\n\nAuthorizationstringRequired\n\nAPI key for authentication. Format should be be either ‘token <DEEPGRAM\\_API\\_KEY>’ or ‘Bearer <JWT\\_TOKEN>’\n\n### Query parameters\n\nencodingenumOptionalDefaults to `mp3`\n\nEncoding allows you to specify the expected encoding of your audio output\n\nShow 7 enum values\n\nmodelenumOptionalDefaults to `aura-asteria-en`\n\nAI model used to process submitted text\n\nShow 53 enum values\n\nsample\\_rateenumOptionalDefaults to `24000`\n\nSample Rate specifies the sample rate for the output audio. Based on encoding 8000 or 24000 are possible defaults. For some encodings sample rate is not configurable.\n\nAllowed values:800016000240004410048000\n\n### Send\n\ntextToSpeechRequestobjectRequired\n\nShow 2 properties\n\nOR\n\nspeak\\_controlMessagesRequestobjectRequired\n\nShow 1 properties\n\n### Receive\n\ntextToSpeechResponsestringRequired\n\nOR\n\ncontrolMessagesResponseobjectRequired\n\nShow 2 properties\n\nOR\n\nspeak\\_closeFrameobjectRequired\n\nShow 2 properties\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=am4b1vjuib09)",
    "metadata": {
      "language": "en",
      "ogTitle": "Continuous Text Stream | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "title": "Continuous Text Stream | Deepgram's Docs",
      "og:title": "Continuous Text Stream | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "twitter:title": "Continuous Text Stream | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "scrapeId": "085b0c31-7696-409b-851d-3de7bf247af0",
      "sourceURL": "https://developers.deepgram.com/reference/text-to-speech-api/speak-streaming",
      "url": "https://developers.deepgram.com/reference/text-to-speech-api/speak-streaming",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Convert text into natural-sounding speech using Deepgram’s TTS API\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Query parameters\n\nbit\\_rateintegerOptional\n\nThe bitrate of the audio in bits per second. Choose from predefined ranges or specific values based on the encoding type.\n\ncallbackstringOptional\n\nURL to which we’ll make the callback request\n\ncontainerenumOptionalDefaults to `wav`\n\nContainer specifies the file format wrapper for the output audio. The available options depend on the encoding type.\n\nAllowed values:nonewavogg\n\nencodingenumOptionalDefaults to `mp3`\n\nEncoding allows you to specify the expected encoding of your audio output\n\nShow 7 enum values\n\nmodelenumOptionalDefaults to `aura-asteria-en`\n\nAI model used to process submitted text\n\nShow 53 enum values\n\nsample\\_rateintegerOptional\n\nSample Rate specifies the sample rate for the output audio. Based on the encoding, different sample rates are supported. For some encodings, the sample rate is not configurable\n\n### Request\n\nThis endpoint expects an object.\n\ntextstringRequired\n\nThe text content to be converted to speech\n\n### Response\n\nSuccessful text to speech\n\n### Errors\n\n400\n\nText to Speech Speak Request Bad Request Error\n\n403\n\nText to Speech Speak Request Forbidden Error\n\n413\n\nText to Speech Speak Request Content Too Large Error\n\n415\n\nText to Speech Speak Request Unsupported Media Type Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=yem9q9xpx05s)",
    "metadata": {
      "ogTitle": "Single Text Request | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "title": "Single Text Request | Deepgram's Docs",
      "twitter:card": "summary",
      "twitter:title": "Single Text Request | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "og:title": "Single Text Request | Deepgram's Docs",
      "language": "en",
      "scrapeId": "aa469f2d-2955-4f85-bcee-20863407082e",
      "sourceURL": "https://developers.deepgram.com/reference/text-to-speech-api/speak",
      "url": "https://developers.deepgram.com/reference/text-to-speech-api/speak",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Generates a temporary JSON Web Token (JWT) with a 30-second TTL and usage::write permission for core voice APIs, requiring an API key with Member or higher authorization. Tokens created with this endpoint will not work with the Management APIs.\n\n### Headers\n\nAuthorizationstringRequired\n\nHeader authentication of the form Token <token>\n\n### Response\n\nJWT token response\n\naccess\\_tokenstring\n\nJSON Web Token (JWT)\n\nexpires\\_indoubleOptional\n\nTime in seconds until the JWT expires\n\n### Errors\n\n403\n\nGrant Token Request Forbidden Error\n\n404\n\nGrant Token Request Not Found Error\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=gy7exu8ewsdg)",
    "metadata": {
      "twitter:card": "summary",
      "og:title": "Grant Token | Deepgram's Docs",
      "ogTitle": "Grant Token | Deepgram's Docs",
      "twitter:title": "Grant Token | Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": "Grant Token | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "scrapeId": "3483cfc0-e25a-4df5-920e-6379dc3c9e4e",
      "sourceURL": "https://developers.deepgram.com/reference/token-based-auth-api/grant-token",
      "url": "https://developers.deepgram.com/reference/token-based-auth-api/grant-token",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram Voice Agent WebSocket\n\n## Handshake [Try it](https://developers.deepgram.com/reference/voice-agent-api/agent?explorer=true)\n\nGET\n\nwss://agent.deepgram.com/v1/agent/converse\n\n### Headers\n\nAuthorizationstringRequired\n\nAPI key for authentication. Format should be be either ‘token <DEEPGRAM\\_API\\_KEY>’ or ‘Bearer <JWT\\_TOKEN>’\n\n### Send\n\nsettingsobjectRequired\n\nShow 5 properties\n\nOR\n\nupdateSpeakobjectRequired\n\nShow 2 properties\n\nOR\n\ninjectAgentMessageobjectRequired\n\nShow 2 properties\n\nOR\n\nfunctionCallResponseSendobjectRequired\n\nShow 4 properties\n\nOR\n\nagentKeepAliveobjectRequired\n\nShow 1 properties\n\nOR\n\nupdatePromptobjectRequired\n\nShow 2 properties\n\n### Receive\n\nfunctionCallResponseReceiveobjectRequired\n\nShow 4 properties\n\nOR\n\npromptUpdatedobjectRequired\n\nShow 1 properties\n\nOR\n\nspeakUpdatedobjectRequired\n\nShow 1 properties\n\nOR\n\ninjectionRefusedobjectRequired\n\nShow 1 properties\n\nOR\n\nwelcomeMessageobjectRequired\n\nShow 2 properties\n\nOR\n\nsettingsAppliedobjectRequired\n\nShow 1 properties\n\nOR\n\nconversationTextobjectRequired\n\nShow 3 properties\n\nOR\n\nuserStartedSpeakingobjectRequired\n\nShow 1 properties\n\nOR\n\nagentThinkingobjectRequired\n\nShow 2 properties\n\nOR\n\nfunctionCallRequestobjectRequired\n\nShow 2 properties\n\nOR\n\nagentStartedSpeakingobjectRequired\n\nShow 4 properties\n\nOR\n\nagentAudioDoneobjectRequired\n\nShow 1 properties\n\nOR\n\nagentErrorResponseobjectRequired\n\nShow 3 properties\n\nOR\n\nagentWarningobjectRequired\n\nShow 3 properties\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=5dup827356en)",
    "metadata": {
      "language": "en",
      "twitter:card": "summary",
      "ogTitle": "Build a Voice Agent | Deepgram's Docs",
      "title": "Build a Voice Agent | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "Build a Voice Agent | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Build a Voice Agent | Deepgram's Docs",
      "scrapeId": "563c784c-a060-44ce-b84d-71be19c9bb96",
      "sourceURL": "https://developers.deepgram.com/reference/voice-agent-api/agent",
      "url": "https://developers.deepgram.com/reference/voice-agent-api/agent",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide is for users with experience using the Deepgram .NET SDK v3 who want to migrate to the Deepgram .NET SDK v4. This is not an end-to-end guide, but a reference for people using our existing .NET SDK to migrate to our newest version.\n\n# Notable Changes\n\n- Significant Restructure of the .NET SDK\n- Improved Implementation for Live, PreRecorded, and Manage Clients\n- Implements Text-to-Speech API\n- Implements Intelligence APIs for PreRecorded and Text (Summary, Intent, Topic, Sentiment)\n- Support for self-hosted/on-prem (previously not supported)\n- Improved and Independent Timeout Capabilities per API Call\n- Verbosity Logging Levels for Troubleshooting\n- Custom Header and Query Parameters for API calls\n- Better Error Handling\n- Support for future products (APIs)\n\n# Migration Guide\n\nThis section of the migration guide focuses on the SDK’s PreRecorded and Live Clients. It will allow you to transition to the latest version of the SDK.\n\n## Installation\n\nTerminal\n\n```code-block text-sm\n\n1# The latest version will definitely be newer than version 4.0.0 listed below2# Visit https://www.nuget.org/packages/Deepgram for the latest version available.3dotnet add package Deepgram\n```\n\n## Transcription: Pre-Recorded\n\nThere are two methods for transcribing Pre-Recorded audio:\n\n- Using a local file on the file system\n- Providing a URL pointing to an supported audio file\n\n### Local File Transcription\n\nTranscribe a local file on the same filesystem as the app is running.\n\nBeforeAfter\n\n```code-block text-sm\n\n1var credentials = new Credentials(DEEPGRAM_API_KEY);23var deepgramClient = new DeepgramClient(credentials);45using (FileStream fs = File.OpenRead(\"path\\\\to\\\\file\"))6{7    var response = await deepgramClient.Transcription.Prerecorded.GetTranscriptionAsync(8        new StreamSource(9            fs,10            \"audio/wav\"),11        new PrerecordedTranscriptionOptions()12        {13            Model = \"nova-3\",14        });15}\n```\n\n### URL File Transcription\n\nTranscribe a remote file by sending a publicly accessible URL.\n\nBeforeAfter\n\n```code-block text-sm\n\n1var credentials = new Credentials(\"YOUR API KEY\");2var deepgramClient = new DeepgramClient(credentials);34var response = await deepgramClient.Transcription.Prerecorded.GetTranscriptionAsync(5  new UrlSource(\"https://dpgr.am/bueller.wav\"),6  new PrerecordedTranscriptionOptions(){7    Tier = \"nova-3\",8  }9);1011Console.WriteLine(JsonConvert.SerializeObject(response));\n```\n\n## Transcription: Live\n\nThe Live Client abstracts the underlying WebSocket implementation from the user for greater usability. This in turn only requires that you deal with higher-level functions like `Connect()`, `Send()`, `Stop()` methods.\n\nBeforeAfter\n\n```code-block text-sm\n\n1var credentials = new Credentials(DEEPGRAM_API_KEY);23var deepgramClient = new DeepgramClient(credentials);45using (var deepgramLive = deepgramClient.CreateLiveTranscriptionClient())6{7    deepgramLive.TranscriptReceived += HandleTranscriptReceived;89    // Connection opened so start sending audio.10    async void HandleConnectionOpened(object? sender, ConnectionOpenEventArgs e)11    {12        byte[] buffer;1314        using (FileStream fs = File.OpenRead(\"path\\\\to\\\\file\"))15        {16            buffer = new byte[fs.Length];17            fs.Read(buffer, 0, (int)fs.Length);18        }1920        var chunks = buffer.Chunk(1000);2122        foreach (var chunk in chunks)23        {24            deepgramLive.SendData(chunk);25            await Task.Delay(50);26        }2728        await deepgramLive.FinishAsync();29    }3031    void HandleTranscriptReceived(object? sender, TranscriptReceivedEventArgs e)32    {33        if (e.Transcript.IsFinal && e.Transcript.Channel.Alternatives.First().Transcript.Length > 0) {34            var transcript = e.Transcript;35            Console.WriteLine($\"[Speaker: {transcript.Channel.Alternatives.First().Words.First().Speaker}] {transcript.Channel.Alternatives.First().Transcript}\");36        }37    }3839    var options = new LiveTranscriptionOptions()40  \t{41      Model = \"nova-3\"42    };43    await deepgramLive.StartConnectionAsync(options);4445    while (deepgramLive.State() == WebSocketState.Open) { }46}\n\n```\n\n## Management API\n\nBelow is a transition guide for using the Manage APIs.\n\n### Get all projects for a user\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Projects.ListProjectsAsync();\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-projects).\n\n### Get a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Projects.ListProjectAsync(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-project).\n\n### Update a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1var project = new Project()2{3    Project = \"projectId string\",4    Name = \"New name for Project\"5}6var result = await deepgramClient.Projects.UpdateProjectAsync(project);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-project).\n\n### Delete a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Projects.DeleteProjectAsync(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-project).\n\n### Get all project key details\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Keys.ListKeysAsync(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-keys).\n\n### Get a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Keys.GetKeyAsync(projectId,keyId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-key).\n\n### Create a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1var scopes = new string[]{\"admin\",\"member\"};2var result = await deepgramClient.Keys.CreateKeyAsync(projectId,comment,scopes);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/create-key).\n\n### Delete a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Keys.DeleteKeyAsync(projectId, keyId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-key).\n\n### Get all project members\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Projects.GetMembersScopesAsync(projectId,memberId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-members).\n\n### Remove a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Projects.RemoveMemberAsync(projectId,memberId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/remove-member).\n\n### Get all scopes for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Keys. GetMemberScopesAsync(projectId,memberId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-member-scopes).\n\n### Update a scope for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1var scopeOptions = new UpdateScopeOption(){Scope = \"admin\"};2var result = await deepgramClient.Keys.UpdateScopeAsync(projectId,memberId,scopeOptions);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-scope).\n\n### Get all usage requests for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1var listAllRequestOptions = new listAllRequestOptions()2{3     StartDateTime = DateTime.Now4};5var result = await deepgramClient.Usage.ListAllRequestsAsync(projectId,listAllRequestOptions);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-all-requests).\n\n### Get a usage request for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1var result = await deepgramClient.Usage.GetUsageRequestAsync(projectId,requestId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-request).\n\n### Get the project usage summary\n\nBeforeAfter\n\n```code-block text-sm\n\n1var getUsageSummmaryOptions = new GetUsageSummmaryOptions()2{3    StartDateTime = DateTime.Now4}5var result = await deepgramClient.Usage.GetUsageSummaryAsync(projectId,getUsageSummmaryOptions);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/summarize-usage).\n\n### Get project usage fields\n\nBeforeAfter\n\n```code-block text-sm\n\n1var getUsageFieldsOptions = new getUsageFieldsOptions()2{3    StartDateTime = Datetime.Now4}5var result = await deepgramClient.Usage.GetUsageFieldsAsync(projectId,getUsageFieldsOptions);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-fields).\n\n## New to v4\n\n**\\[NOTICE\\]** There were several APIs that were previously unavailable in `v3` of the .NET SDK but that are now available in the `v4` release. These included:\n\n- Self-hosted (on-prem) APIs\n- Manage APIs for Balances and Invitations\n- Intelligence APIs (SITS) for Text and Audio\n- Text-to-Speech\n\nPlease refer to the examples in the `examples` folder at the root of the [.NET SDK](https://github.com/deepgram/deepgram-dotnet-sdk) repository for implementation details.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=a2iwrb2tnnk)",
    "metadata": {
      "twitter:description": "Migrating from Deepgram .NET SDK v3 to the Deepgram .NET SDK v4",
      "generator": "https://buildwithfern.com",
      "og:description": "Migrating from Deepgram .NET SDK v3 to the Deepgram .NET SDK v4",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "title": ".NET SDK V3 to V4 Migration Guide | Deepgram's Docs",
      "language": "en",
      "theme-color": "#f5f5f7",
      "og:title": ".NET SDK V3 to V4 Migration Guide | Deepgram's Docs",
      "twitter:title": ".NET SDK V3 to V4 Migration Guide | Deepgram's Docs",
      "description": "Migrating from Deepgram .NET SDK v3 to the Deepgram .NET SDK v4",
      "ogDescription": "Migrating from Deepgram .NET SDK v3 to the Deepgram .NET SDK v4",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "ogTitle": ".NET SDK V3 to V4 Migration Guide | Deepgram's Docs",
      "twitter:card": "summary",
      "application-name": "Deepgram's Docs",
      "scrapeId": "7482c0c1-44ce-464f-90aa-0ba91b058d98",
      "sourceURL": "https://developers.deepgram.com/sdks/dotnet-sdk/v3-to-v4-migration",
      "url": "https://developers.deepgram.com/sdks/dotnet-sdk/v3-to-v4-migration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide is for users with experience using the Deepgram Go SDK v1.2 who want to migrate to the Deepgram Go SDK v1.3.6. This is not an end-to-end guide, but a reference for people using our existing Go SDK for migration purposes.\n\n## Notable Change(s)\n\nThe `v1.3` release introduced a breaking change to the Speech-to-Text Live Client. If you upgrade from any previous version of this SDK, these notes apply to your project.\n\nWe discovered that the code to retry the connection was not working properly and would, in many cases, cause the client to reconnect to the websocket and call `websocket.read()` on a tight loop 1000+ times. Many times, this would result in a go panic. Since the root cause of the issue was the reconnect not working properly, the decision was made to break the client interfaces to alleviate this unwanted behavior.\n\nSince we were introducing a breaking change, it followed that existing issues with the `golangci-lint` static checker were also addressed in this breaking change as well.\n\n## Root Cause\n\nFor transparency, the root cause of the issue was that we inadvertently tried to reuse the context `ctx` object for re-connection. This turned out to be the source of the bug. To alleviate this problem, the end user must be able to specify and provide their own `cancel context`. A new `context` input was needed on the `Connect()` and `AttemptReconnect()` function calls, thus breaking the interface.\n\n# Migration Guide\n\nPlease review the notes below for a call out on the interface break and instructions on modifying your code to handle this change when upgrading to the latest version.\n\n## WebSocket/Live Client `Connect()`\n\nIn `pkg/client/live/client.go`:\n\n**Code change:** If you are testing if `Connect()` was successful, the return value was changed from `*websocket.Conn` to a `bool` result. **Reason:** This is to prevent users from performing a `wsConn.read()` or `wsConn.write()` directly with the WebSocket.\n\nBeforeAfter\n\n```code-block text-sm\n\n1func (c *Client) Connect() *websocket.Conn\n```\n\n## WebSocket/Live Client `Reconnect()`\n\nIn `pkg/client/live/client.go`:\n\n**Code change:** If you are testing if `AttemptReconnect()` was successful, the return value was changed from `*websocket.Conn` to a `bool` result. **Reason:** This is to prevent users from performing a `wsConn.read()` or `wsConn.write()` directly with the WebSocket.\n\nBeforeAfter\n\n```code-block text-sm\n\n1func (c *Client) AttemptReconnect(retries int64) *websocket.Conn\n```\n\n## PreRecorded/REST Client `New()`\n\nIn:\n\n- `pkg/client/live/client.go`: `New()` functions take a pointer to `LiveTranscriptionOptions` struct\n- `pkg/client/prerecorded/client.go`: `New()` functions take a pointer to `PreRecordedTranscriptionOptions` struct\n- `pkg/client/analyze/client.go`: `New()` functions take a pointer to `AnalyzeOptions` struct\n- `pkg/client/speak/client.go`: `New()` functions take a pointer to `SpeakOptions` struct\n\n**Code change:** Instead of passing in a copy of the struct, the pointer to the struct is provided instead **Reason:** This was to solve an initialization issue causing the struct to get duplicated. Depending on the `struct`, the duplicate could be quite expensive.\n\nUsing `pkg/client/prerecorded/client.go` for the example below:\n\nBeforeAfter\n\n```code-block text-sm\n\n1// create a Deepgram client (NOTE: line 2 without the &)2c := client.NewREST(\"\", interfaces.ClientOptions{))3dg := api.New(c)4                                                  5// transcription options (NOTE: line 6 without the &)6options := interfaces.PreRecordedTranscriptionOptions{7\tModel: \"nova-3\",8}9                                                  10// send/process file to Deepgram11res, err := dg.FromFile(ctx, filePath, options)12if err != nil {13\tif e, ok := err.(*interfaces.StatusError); ok {14\t\tfmt.Printf(\"DEEPGRAM ERROR:\\n%s:\\n%s\\n\", e.DeepgramError.ErrCode, e.DeepgramError.ErrMsg)15\t}16\tfmt.Printf(\"FromStream failed. Err: %v\\n\", err)17\tos.Exit(1)18}\n```\n\nIf you have any questions or need additional support please see our [Support Page](https://developers.deepgram.com/docs/support) for more details of how to get help.\n\n## Naming Changes Due to Linting Enforcement\n\nIn `v1.3`, we implemented using many static code checkers and code linters on the Go SDK. This, in turn, caused these checkers to complain about everything not being up to par with this enforcement. The code base up until this point tried to implement these standards, but we, unfortunately, missed enforcement for variable and module names.\n\nShould you build your application after migrating to `v1.3+` and you find that the compilation failed due to properties on structs that were renamed, you can find a quick find and replace commands that you can run from the root of your repo. These capture all the renamed properties within the struct interfaces exposed in the Go SDK.\n\nBefore running any of these commands, save a copy of your current code base elsewhere to ensure all the intended changes happen correctly. You should be under some kind of source control; if not, start by checking into your application code somewhere.\n\nShell\n\n```code-block text-sm\n\n$# struct property linting updates>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak 's/Url/URL/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak 's/Api/API/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak -E 's/([^a-zA-Z])URI/\\1uri/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak 's/Http/HTTP/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak 's/Uuid/UUID/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"./.git\" -exec sed -i.bak -E 's/Id([^e])/ID\\1/g' \"{}\" +;>># Client module name linting updates>find ./ -type f -iname \"*.go\" -not -path \"examples\" -not -path \".git\" -exec sed -i.bak 's/ReplyOptions/Options/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"examples\" -not -path \".git\" -exec sed -i.bak 's/AnalyzeClient/Client/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"examples\" -not -path \".git\" -exec sed -i.bak 's/ManageClient/Client/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"examples\" -not -path \".git\" -exec sed -i.bak 's/PrerecordedClient/Client/g' \"{}\" +;>find ./ -type f -iname \"*.go\" -not -path \"examples\" -not -path \".git\" -exec sed -i.bak 's/SpeakClient/Client/g' \"{}\" +;>># client Options name change from linting updates>find ./examples -type f -iname \"*.go\" -not -path \".git\" -exec sed -i.bak -E 's/([a-zA-Z0-9]+[[:blank:]]+:=.*)([[:blank:]]+)([^\\&].+[a-zA-Z]+\\.ClientOptions\\{)(.*)/\\1\\2\\&\\3\\4/g' \"{}\" +;>find ./examples -type f -iname \"*.go\" -not -path \".git\" -exec sed -i.bak -E 's/([a-zA-Z0-9]+[[:blank:]]+:=.*)([[:blank:]]+)([^\\&].+[a-zA-Z]+\\.AnalyzeOptions\\{)(.*)/\\1\\2\\&\\3\\4/g' \"{}\" +;>find ./examples -type f -iname \"*.go\" -not -path \".git\" -exec sed -i.bak -E 's/([a-zA-Z0-9]+[[:blank:]]+:=.*)([[:blank:]]+)([^\\&].+[a-zA-Z]+\\.LiveTranscriptionOptions\\{)(.*)/\\1\\2\\&\\3\\4/g' \"{}\" +;>find ./examples -type f -iname \"*.go\" -not -path \".git\" -exec sed -i.bak -E 's/([a-zA-Z0-9]+[[:blank:]]+:=.*)([[:blank:]]+)([^\\&].+[a-zA-Z]+\\.PreRecordedTranscriptionOptions\\{)(.*)/\\1\\2\\&\\3\\4/g' \"{}\" +;>find ./examples -type f -iname \"*.go\" -not -path \".git\" -exec sed -i.bak -E 's/([a-zA-Z0-9]+[[:blank:]]+:=.*)([[:blank:]]+)([^\\&].+[a-zA-Z]+\\.SpeakOptions\\{)(.*)/\\1\\2\\&\\3\\4/g' \"{}\" +;>># clean up backup files. Run this ONLY after you have verified that the changes are correct># find ./ -type f -iname \"*.bak\" -not -path \"./.git\" -exec rm -rf \"{}\" +;\n\n```\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=unqm4m10szsi)",
    "metadata": {
      "language": "en",
      "ogTitle": "Go SDK v1.2 to v1.3 Interface Change | Deepgram's Docs",
      "og:title": "Go SDK v1.2 to v1.3 Interface Change | Deepgram's Docs",
      "og:description": "Migrating from Deepgram Go SDK v1.2 to v1.3.6",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:title": "Go SDK v1.2 to v1.3 Interface Change | Deepgram's Docs",
      "twitter:description": "Migrating from Deepgram Go SDK v1.2 to v1.3.6",
      "title": "Go SDK v1.2 to v1.3 Interface Change | Deepgram's Docs",
      "ogDescription": "Migrating from Deepgram Go SDK v1.2 to v1.3.6",
      "theme-color": "#f5f5f7",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "description": "Migrating from Deepgram Go SDK v1.2 to v1.3.6",
      "scrapeId": "9f7ac270-5362-43fd-a576-9cdb1bace436",
      "sourceURL": "https://developers.deepgram.com/sdks/go-sdk/v12-to-v13-migration",
      "url": "https://developers.deepgram.com/sdks/go-sdk/v12-to-v13-migration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide is for users with experience using the Deepgram Node SDK v2 who want to migrate to the Deepgram JavaScript SDK v3. This is not an end-to-end guide, but a reference for people using our existing Node SDK to migrate to our newest version.\n\n# Notable Changes\n\n- [ESM](https://developers.deepgram.com/sdks/javascript-sdk/v2-to-v3-migration#esm) and [UMD](https://developers.deepgram.com/sdks/javascript-sdk/v2-to-v3-migration#umd) support\n- WebVTT and SRT captions [published as a standalone package](https://github.com/deepgram/deepgram-js-captions)\n- **Separate async and sync transcription methods.**\n- JavaScript and Node.js friendly (isomorphic)\n- Improved live transcription events\n- Switch from `request` to `fetch`\n- Initialization by function instead of class\n- Scoped constructor config\n- Better errors\n- Support for future products\n- Support for self-hosted (formerly called on-prem) deployments\n\n## UMD\n\nYou can now use plain `<script>` s to import deepgram from CDNs, like:\n\nhtml\n\n```code-block text-sm\n\n1<script src=\"https://cdn.jsdelivr.net/npm/@deepgram/sdk\"></script>\n```\n\nor even:\n\nhtml\n\n```code-block text-sm\n\n1<script src=\"https://unpkg.com/@deepgram/sdk\"></script>\n```\n\nThen you can use it from a global deepgram variable:\n\nhtml\n\n```code-block text-sm\n\n1<script>2  const { createClient } = deepgram3  const _deepgram = createClient('deepgram-api-key');45  console.log('Deepgram Instance: ', _deepgram);  6  // ...  7</script>\n```\n\n## ESM\n\nYou can now use type=“module” `<script>` s to import deepgram from CDNs, like:\n\nhtml\n\n```code-block text-sm\n\n1<script type=\"module\">2  import { createClient } from 'https://cdn.jsdelivr.net/npm/@deepgram/sdk/+esm';3  const deepgram = createClient('deepgram-api-key');45  console.log('Deepgram Instance: ', deepgram);6  // ...7</script>\n```\n\n# Migration Guide\n\n## Installation\n\nTerminal\n\n```code-block text-sm\n\n1npm install @deepgram/sdk\n```\n\n## Initialization\n\nBeforeAfter\n\n```code-block text-sm\n\n1import { Deepgram } from \"@deepgram/sdk\";2// - or -3// const { Deepgram } = require(\"@deepgram/sdk\");45const deepgram = new Deepgram(DEEPGRAM_API_KEY);\n```\n\n## Scoped Configuration\n\nA new feature is scoped configuration. You’ll be able to configure various aspects of the SDK from the initialization.\n\nTypeScript\n\n```code-block text-sm\n\n1import { createClient } from \"@deepgram/sdk\";2// - or -3// const { createClient } = require(\"@deepgram/sdk\");45const deepgram = createClient(DEEPGRAM_API_KEY, { global: { url: \"http://localhost:8080\" }});\n```\n\n## Transcription Methods (Synchronous)\n\nWe have separated the `callback` feature into its own method. The functionality below is **not** valid with the callback feature.\n\n### Local File Transcription\n\nTranscribe a local file on the same filesystem as the app is running.\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    stream: fs.createReadStream(\"./examples/spacewalk.wav\"),4    mimetype: MIMETYPE_OF_FILE,5  },6  {7    model: \"nova-3\",8  }9);\n```\n\nor\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    stream: fs.readFileSync(\"./examples/spacewalk.wav\"),4    mimetype: MIMETYPE_OF_FILE,5  },6  {7    model: \"nova-3\",8  }9);\n```\n\n### URL File Transcription\n\nTranscribe a remote file by sending us a publicly accessible URL to it.\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    url: \"https://dpgr.am/spacewalk.wav\"4  },5  {6    model: \"nova-3\",7  }8);\n```\n\n## Transcription Methods (Asynchronous)\n\nThe below are examples of using a callback endpoint with our new SDK. You’ll need additionally need the `CallbackUrl` class from the Deepgram SDK.\n\nTypeScript\n\n```code-block text-sm\n\n1import { createClient, CallbackUrl } from \"@deepgram/sdk\";2// - or -3// const { createClient, CallbackUrl } = require(\"@deepgram/sdk\");\n```\n\n### Local File Transcription\n\nTranscribe a local file on the same filesystem as the app is running.\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    stream: fs.createReadStream(\"./examples/spacewalk.wav\"),4    mimetype: MIMETYPE_OF_FILE,5  },6  {7    model: \"nova-3\",8    callback: \"http://callback/endpoint\"9  }10);\n```\n\nor\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    stream: fs.readFileSync(\"./examples/spacewalk.wav\"),4    mimetype: MIMETYPE_OF_FILE,5  },6  {7    model: \"nova-3\",8    callback: \"http://callback/endpoint\"9  }10);\n```\n\n### URL File Transcription\n\nTranscribe a remote file by sending us a publicly accessible URL to it.\n\nBeforeAfter\n\n```code-block text-sm\n\n1const response = await deepgram.transcription.preRecorded(2  {3    url: \"https://dpgr.am/spacewalk.wav\"4  },5  {6    model: \"nova-3\",7    callback: \"http://callback/endpoint\"8  }9);\n```\n\n## Transcription Methods (Live)\n\nOur live transcription uses a WebSocket to receive audio data, and return results.\n\n### Live Transcription\n\nTranscribe live audio streams.\n\nBeforeAfter\n\n```code-block text-sm\n\n1const dgConnection = await deepgram.transcription.live({2  model: \"nova-3\",3});45source.addListener('got-some-audio', async (event) => {6  dgConnection.send(event.raw_audio_data);7})89dgConnection.addListener(\"transcriptReceived\", (transcription) => {10\tconsole.log(transcription.data);11});\n```\n\n## Management API\n\n### get all projects for a user\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.projects.list();\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-projects).\n\n### get a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.projects.get(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-project).\n\n### update a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.projects.update(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-project).\n\n### delete a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1await deepgram.projects.delete(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-project).\n\n### get all project key details\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.keys.list(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-keys).\n\n### get a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.keys.get(projectId, projectKeyId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-key).\n\n### create a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1let scopes = [\"member\", \"etc\"];2const result = await deepgram.keys.create(projectId, comment, scopes, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/create-key).\n\n### delete a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1await deepgram.keys.delete(projectId, projectKeyId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-key).\n\n### get all project members\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.members.listMembers(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-members).\n\n### remove a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.members.removeMember(projectId, projectMemberId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/remove-member).\n\n### get all scopes for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.scopes.get(projectId, projectMemberId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-member-scopes).\n\n### update a scope for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1let scope = \"member:read\";2const result = await deepgram.scopes.update(projectId, projectMemberId, scope);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-scope).\n\n### get all project invites\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.invitation.list(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-invites).\n\n### send a project invite\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.invitation.send(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/send-invites).\n\n### delete a project invite\n\nBeforeAfter\n\n```code-block text-sm\n\n1let email = \"[email protected]\";2const result = await deepgram.invitation.delete(projectId, email);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-invite).\n\n### leave a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.invitation.leave(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/leave-project).\n\n### get all usage requests for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.usage.listRequests(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-all-requests).\n\n### get a usage request for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.usage.getRequest(projectId, request_id);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-request).\n\n### get the project usage summary\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.usage.getUsage(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/summarize-usage).\n\n### get project usage fields\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.usage.getFields(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-fields).\n\n### get all project balances\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.billing.listBalances(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-all-balances).\n\n### get a project balance\n\nBeforeAfter\n\n```code-block text-sm\n\n1const result = await deepgram.billing.getBalance(projectId, balanceId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-balance).\n\n## Self-Hosted (on-prem) APIs (new)\n\n### list self-hosted credentials\n\nNewly available functionality.\n\nTypeScript\n\n```code-block text-sm\n\n1const { result, error } = await deepgram.onprem.listCredentials(projectId);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-credentials).\n\n### get self-hosted credentials\n\nNewly available functionality.\n\nTypeScript\n\n```code-block text-sm\n\n1const { result, error } = await deepgram.onprem.getCredentials(2  projectId,3  credentialId4);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-credentials).\n\n### create self-hosted credentials\n\nNewly available functionality.\n\nTypeScript\n\n```code-block text-sm\n\n1const { result, error } = await deepgram.onprem.createCredentials(projectId, options);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/create-credentials).\n\n### delete self-hosted credentials\n\nNewly available functionality.\n\nTypeScript\n\n```code-block text-sm\n\n1const { result, error } = await deepgram.onprem.deleteCredentials(2  projectId,3  credentialId4);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-credentials).\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=xyko7g9duf6o)",
    "metadata": {
      "ogTitle": "JavaScript SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "application-name": "Deepgram's Docs",
      "language": "en",
      "ogDescription": "Migrating from Deepgram Node SDK v2 to the Deepgram JavaScript SDK v3.",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "twitter:title": "JavaScript SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "og:description": "Migrating from Deepgram Node SDK v2 to the Deepgram JavaScript SDK v3.",
      "twitter:description": "Migrating from Deepgram Node SDK v2 to the Deepgram JavaScript SDK v3.",
      "description": "Migrating from Deepgram Node SDK v2 to the Deepgram JavaScript SDK v3.",
      "title": "JavaScript SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "og:title": "JavaScript SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "scrapeId": "7f2fe384-a9ed-424d-ae03-5288eaa1a625",
      "sourceURL": "https://developers.deepgram.com/sdks/javascript-sdk/v2-to-v3-migration",
      "url": "https://developers.deepgram.com/sdks/javascript-sdk/v2-to-v3-migration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Some users prefer the workflow of a Jupyter notebook. These Python starter notebooks can help those users get up and running quickly with Deepgram’s Python SDK without having to copy or paste any code.\n\n- [Prerecorded Audio Notebook](https://github.com/deepgram-devs/prerecorded-audio-notebook)\n- [Livestream Audio Notebook](https://github.com/deepgram-devs/livestream-audio-notebook)\n\n* * *\n\nWhat’s Next\n\n- [Deepgram API Overview](https://developers.deepgram.com/reference/deepgram-api-overview)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=oahkb4grl1i9)",
    "metadata": {
      "og:description": "Some useful Deepgram Notebooks for Python Developers.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "theme-color": "#f5f5f7",
      "description": "Some useful Deepgram Notebooks for Python Developers.",
      "application-name": "Deepgram's Docs",
      "ogTitle": "Python Notebooks | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Python Notebooks | Deepgram's Docs",
      "title": "Python Notebooks | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "ogDescription": "Some useful Deepgram Notebooks for Python Developers.",
      "twitter:description": "Some useful Deepgram Notebooks for Python Developers.",
      "og:title": "Python Notebooks | Deepgram's Docs",
      "twitter:card": "summary",
      "scrapeId": "d1285e46-b536-4f5b-ba4f-5b5e0fefb091",
      "sourceURL": "https://developers.deepgram.com/sdks/python-sdk/python-notebooks",
      "url": "https://developers.deepgram.com/sdks/python-sdk/python-notebooks",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Threaded and Async IO Task Support\n\nOur Python SDK supports the Threaded and Async IO Task API models, allowing developers to build efficient, non-blocking applications.\n\n### Threaded API\n\nThe SDK also supports a Threading API via its classes/functions, allowing concurrent task execution. This is particularly useful for CPU and IO-bound operations when performing background operations without blocking the main (or other) thread(s). Utilizing Python’s threading module, you can create and manage multiple threads, ensuring your application remains efficient and responsive.\n\nThese Threaded components will work with asynchronous code that utilizes the async/await classes and functions. Even if your code uses Async IO classes/functions, you can still use these Threaded API classes/functions.\n\nThe best use cases for using Threaded are:\n\n- Heavily Parallelized Applications, such as backend applications behind an API (ie a REST API service)\n- CPU-bound Operations, such as ML applications\n- IO-bound Operations, such as ML applications or Backup solutions\n\nPushing a lot of audio data (ie IO operations) over the internet, like performing live transcription of real-time audio, qualifies for using the Threaded API over Async IO Task. In other words, for the overwhleming majority of cases, you should be using this Threaded API over Async IO Tasks for real-time transcription.\n\n### Async IO Task API\n\nAsync IO Tasks can handle multiple tasks concurrently, making it ideal for high-level structured network code or when handling multiple I/O-bound tasks simultaneously. This is ideal for web-based applications that interact with a web browser. This functionality leverages Python’s asyncio library, enabling you to write asynchronous code using async and await keywords, ensuring smoother and more responsive applications.\n\nThe best use cases for using Async IO Tasks are:\n\n- Web-based Browser Applications\n- Non-Real-Time based Applications, see the previous item\n  - Over simplifying this, since an Async IO “Thread” or Task is run exclusively from other threads/tasks (ie other tasks are suspended), operations on other threads no longer are “real-time”. Please see [asyncio documentation](https://docs.python.org/3/library/asyncio-dev.html).\n- Willing to trade off performance for ease of programming\n\n## Accessing the API Types\n\n### Threaded API Classes\n\nYou can find the Threaded API classes through the convenience `dot notation` accessors below or by directly creating the `[Client]` contained brackets:\n\n- Real-Time/Live Transcription: `deepgram.listen.websocket.v(\"1\")` or [`LiveClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/listen/v1/websocket/client.py)\n- Text-to-Speech: `deepgram.speak.rest.v(\"1\")` or [`SpeakClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/speak/v1/rest/client.py)\n- Pre-Recorded Transcription: `deepgram.listen.rest.v(\"1\")` or [`PreRecordedClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/listen/v1/rest/client.py)\n- Text Intelligence: `deepgram.read.analyze.v(\"1\")` or [`AnalyzeClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/analyze/v1/client.py)\n- Management: `deepgram.manage.v(\"1\")` or [`ManageClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/manage/v1/client.py)\n\n### Async IO Task Classes\n\nYou can find the Async IO Task API (async/await) classes through the convenience `dot notation` accessors below or by directly creating the `[Client]` contained brackets:\n\n- Real-Time/Live Transcription: `deepgram.listen.asyncwebsocket.v(\"1\")` or [`AsyncLiveClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/listen/v1/websocket/async_client.py)\n- Text-to-Speech: `deepgram.asyncspeak.v(\"1\")` or [`AsyncSpeakClient`](https://github.com/deepgram/deepgram-python-sdk/blob/main/deepgram/clients/speak/v1/rest/async_client.py)\n- Pre-Recorded Transcription: `deepgram.listen.asyncrest.v(\"1\")` or [`AsyncPreRecordedClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/listen/v1/rest/async_client.py)\n- Text Intelligence: `deepgram.read.asyncanalyze.v(\"1\")` or [`AsyncAnalyzeClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/speak/v1/rest/async_client.py)\n- Management: `deepgram.asyncmanage.v(\"1\")` or [`AsyncManageClient`](https://github.com/dvonthenen/deepgram-python-sdk/blob/main/deepgram/clients/manage/v1/async_client.py)\n\n## Examples\n\nThe [GitHub repo](https://github.com/deepgram/deepgram-python-sdk?tab=readme-ov-file#examples) contains examples for the Threaded and Async IO Task APIs for the 5 majority category of APIs:\n\n- [Real-Time/Live Transcription Examples](https://github.com/dvonthenen/deepgram-python-sdk/tree/main/examples/speech-to-text/websocket)\n- [Text-to-Speech Examples](https://github.com/dvonthenen/deepgram-python-sdk/tree/main/examples/text-to-speech/rest)\n- [Pre-Recorded Transcription Examples](https://github.com/dvonthenen/deepgram-python-sdk/tree/main/examples/speech-to-text/rest)\n- [Text Intelligence Examples](https://github.com/deepgram/deepgram-python-sdk/tree/main/examples/analyze)\n- [Management Examples](https://github.com/deepgram/deepgram-python-sdk/tree/main/examples/manage)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=nvtqc5q0sowi)",
    "metadata": {
      "title": "Threaded and Async IO Task Support | Deepgram's Docs",
      "twitter:title": "Threaded and Async IO Task Support | Deepgram's Docs",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "language": "en",
      "application-name": "Deepgram's Docs",
      "og:title": "Threaded and Async IO Task Support | Deepgram's Docs",
      "ogTitle": "Threaded and Async IO Task Support | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "twitter:card": "summary",
      "theme-color": "#f5f5f7",
      "scrapeId": "022f1208-ffda-48a7-a906-928c9522407c",
      "sourceURL": "https://developers.deepgram.com/sdks/python-sdk/threaded-and-asyncio",
      "url": "https://developers.deepgram.com/sdks/python-sdk/threaded-and-asyncio",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "This guide is for users with experience using the Deepgram Python SDK v2 who want to migrate to the Deepgram Python SDK v3. This is not an end-to-end guide, but a reference for people using our existing Python SDK to migrate to our newest version.\n\n# Notable Changes\n\n- Significant Restructure of the Python SDK\n- Improved implementation for Live Client\n- Implements both Sync(/Threaded) and Async(/Await) Classes and Functions\n- Verbosity Logging Levels for Troubleshooting\n- WebVTT and SRT captions [published as a standalone package](https://github.com/deepgram/deepgram-python-captions)\n- Custom Header and Query Parameters for API calls\n- Support for future products (APIs)\n- Better error handling\n\n# Migration Guide\n\nThis migration guide focuses primarily on the Sync/Threaded classes and methods in this SDK. The Async/Await classes and methods are very similar, where the class name will be prepended with “Async” and properties prepended with “async”.\n\nFor example, the Prerecorded Client for Sync/Threaded would be `Prerecorded` and the Async/Await would be `AsyncPrerecorded`.\n\nIf accessing the Pre-recorded Client from the `deepgram.listen` properties, the Sync/Threaded property would be `deepgram.listen.prerecorded` and the Async/Await would be `deepgram.listen.asyncprerecorded`.\n\n## Installation\n\nTerminal\n\n```code-block text-sm\n\n1pip install deepgram-sdk==3.*\n```\n\n## Initialization\n\nBeforeAfter\n\n```code-block text-sm\n\n1from deepgram import Deepgram23# Your Deepgram API Key4DEEPGRAM_API_KEY = 'YOUR_DEEPGRAM_API_KEY'56# Initialize the Deepgram SDK7deepgram = Deepgram(DEEPGRAM_API_KEY)\n```\n\n## Transcription: Pre-recorded\n\nWe have separated the `callback` feature into its own method. The functionality below is **not** valid with the callback feature.\n\n### Local File Transcription\n\nTranscribe a local file on the same filesystem as the app is running.\n\nBeforeAfter\n\n```code-block text-sm\n\n1FILE = 'interview_speech-analytics.wav'23# file is local4# Open the audio file5audio = open(FILE, 'rb')67# Set the source8source = {9\t'buffer': audio,10}1112# Send the audio to Deepgram and get the response13response = await asyncio.create_task(14  deepgram.transcription.prerecorded(15    source,16    {17      'smart_format': \"true\",18      'summarize': \"v2\",19    }20  )21)2223# Write the response to the console24print(json.dumps(response, indent=4))\n\n```\n\n### URL File Transcription\n\nTranscribe a remote file by sending us a publicly accessible URL to it.\n\nBeforeAfter\n\n```code-block text-sm\n\n1URL = 'https://static.deepgram.com/examples/interview_speech-analytics.wav'23# Set the source4source = {5    'url': URL,6}78# Send the audio to Deepgram and get the response9response = await asyncio.create_task(10  deepgram.transcription.prerecorded(11    source,12    {13      'smart_format': \"true\",14      'summarize': \"v2\",15    }16  )17)1819# Write the response to the console20print(json.dumps(response, indent=4))\n```\n\n## Transcription: Live\n\nThe Live Client abstracts the underlying Websocket implementation from the user. This in turn only requires that you deal with higher level functions like `start()`, `write()`, `finish()` methods.\n\n### Live Transcription\n\nTranscribe live audio streams. Previously only Async/Await class and methods were available. As of this release, both Sync/Threaded and Await/Await classes and methods are provided, but the prefered method of performing live transcription is Sync/Threaded.\n\nBeforeAfter\n\n```code-block text-sm\n\n1try:2  deepgramLive = await deepgram.transcription.live({3    'smart_format': True,4    'interim_results': False,5    'language': 'en-US',6    'model': 'nova-3',7  })8except Exception as e:9  print(f'Could not open socket: {e}')10  return1112# Listen for the connection to close13deepgramLive.registerHandler(deepgramLive.event.CLOSE, lambda c: print(14                             f'Connection closed with code {c}.'))1516# Listen for any transcripts received from Deepgram and write them to the console17deepgramLive.registerHandler(deepgramLive.event.TRANSCRIPT_RECEIVED, print)1819# Listen for the connection to open and send streaming audio from the URL to Deepgram20# IMPORTANT: This is a blocking call with no way to exit except through a Cntl-C,21# IMPORTANT: disconnecting your internet, or killing the streaming (assuming you control that)22async with aiohttp.ClientSession() as session:23  async with session.get(URL) as audio:24  while True:25    data = await audio.content.readany()26    deepgramLive.send(data)2728# If no data is being sent from the live stream, then break out of the loop.29if not data:30\tbreak3132# Indicate that we've finished sending data by sending the customary zero-byte message to the Deepgram streaming endpoint, and wait until we get back the final summary metadata object33await deepgramLive.finish()\n\n```\n\n## Management API\n\nThis provides a transition guide from Async/Await to Sync/Threaded Manage APIs.\n\n### get all projects for a user\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.projects.list()\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-projects).\n\n### get a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.projects.get(PROJECT_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-project).\n\n### update a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.projects.update(object)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-project).\n\n### delete a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.projects.delete(PROJECT_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-project).\n\n### get all project key details\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.keys.list(PROJECT_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-keys).\n\n### get a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.keys.get(PROJECT_ID, KEY_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-key).\n\n### create a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.keys.create(PROJECT_ID, COMMENT_FOR_KEY, SCOPES)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/create-key).\n\n### delete a project key\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.keys.delete(PROJECT_ID, KEY_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-key).\n\n### get all project members\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.members.list_members(PROJECT_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-members).\n\n### remove a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.members.remove_member(PROJECT_ID, MEMBER_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/remove-member).\n\n### get all scopes for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.scopes.get_scope(PROJECT_ID, MEMBER_ID)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-member-scopes).\n\n### update a scope for a project member\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.scopes.update_scope(PROJECT_ID, MEMBER_ID, 'member')\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/update-scope).\n\n### get all project invites\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.invitations.list_invitations(PROJECT_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/list-invites).\n\n### send a project invite\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.invitations.send_invitation(PROJECT_ID, {2  email: '[email protected]',3  scope: 'member',4})\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/send-invites).\n\n### delete a project invite\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.invitations.remove_invitation(2  PROJECT_ID,3  '[email protected]'4)\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/delete-invite).\n\n### leave a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.invitation.leave_project(PROJECT_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/leave-project).\n\n### get all usage requests for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.usage.list_requests(PROJECT_ID, {2  'limit': 10,3  # other options are available4});\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-all-requests).\n\n### get a usage request for a project\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.usage.get_request(PROJECT_ID, REQUEST_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-request).\n\n### get the project usage summary\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.usage.get_usage(PROJECT_ID, {2  'start': '2020-01-01T00:00:00+00:00',3  # other options are available4});\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/summarize-usage).\n\n### get project usage fields\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.usage.get_fields(PROJECT_ID, {2  'start': '2020-01-01T00:00:00+00:00',3  # other options are available4});\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-fields).\n\n### get all project balances\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.billing.list_balance(PROJECT_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-all-balances).\n\n### get a project balance\n\nBeforeAfter\n\n```code-block text-sm\n\n1result = await deepgram.billing.get_balance(PROJECT_ID, BALANCE_ID);\n```\n\n[See our API reference for more info](https://developers.deepgram.com/reference/get-balance).\n\n## Self-Hosted API\n\n**\\[NOTICE\\]** The self-hosted API has not changed since the last release, but in `v4` these APIs will likely go through a breaking change. There was only so much we could do with this release and unfortunately, these APIs failed to make the cut off.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=j7m3q4970ez2)",
    "metadata": {
      "description": "Migrating from Deepgram Python SDK v2 to the Deepgram Python SDK v3",
      "theme-color": "#f5f5f7",
      "ogTitle": "Python SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogDescription": "Migrating from Deepgram Python SDK v2 to the Deepgram Python SDK v3",
      "twitter:title": "Python SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "twitter:description": "Migrating from Deepgram Python SDK v2 to the Deepgram Python SDK v3",
      "title": "Python SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "twitter:card": "summary",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "language": "en",
      "og:description": "Migrating from Deepgram Python SDK v2 to the Deepgram Python SDK v3",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "og:title": "Python SDK V2 to V3 Migration Guide | Deepgram's Docs",
      "scrapeId": "db2cafc8-5de3-4bf9-858b-8f207521e763",
      "sourceURL": "https://developers.deepgram.com/sdks/python-sdk/v2-to-v3-migration",
      "url": "https://developers.deepgram.com/sdks/python-sdk/v2-to-v3-migration",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Below is a list of all the features supported by our SDKs. For more details on any of these SDKs or features please refer to the corresponding documentation.\n\nIf an SDK doesn’t have support for an API feature please refer to our documentation for how to [use custom add on parameters with our SDKs](https://developers.deepgram.com/docs/using-custom-parameters-sdks).\n\n# Voice Agent\n\n| API Reference | Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Voice Agent](https://developers.deepgram.com/reference/voice-agent-api/agent) | All Available | `GA` | `JS`, `.NET`, `Python`, `Go` |\n\n# Transcription API : Pre-recorded\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | callback | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | callback\\_method | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | channels | `GA` | `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | diarize | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | diarize\\_version | `GA` | `JS`, `.NET`, `Python`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | detect\\_language | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | dictation | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | encoding | `GA` | `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | extra | `GA` | `JS`, `Python`, `Go`, . `NET`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | filler\\_words | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | keyterm | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | keywords | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | language | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | measurements | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | model | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | multichannel | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | numerals | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | paragraph | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | punctuate | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | profanity\\_filter | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | redact | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | replace | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | sample\\_rate | `GA` | `Python`, `Go` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | search | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | smart\\_format | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | tag | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | utterances | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | utt\\_split | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Pre-recorded Audio](https://developers.deepgram.com/reference/listen-remote) | version | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n\n# Intelligence API: Audio\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Intelligence Audio](https://developers.deepgram.com/reference/listen-remote) | detect\\_entities | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Intelligence Audio](https://developers.deepgram.com/reference/listen-remote) | intents | `GA` | `JS`, `.NET`, `Python` , `Go`, `Rust` |\n| [Intelligence Audio](https://developers.deepgram.com/reference/listen-remote) | sentiment | `GA` | `JS`, `.NET`, `Python` , `Go`, `Rust` |\n| [Intelligence Audio](https://developers.deepgram.com/reference/listen-remote) | summarize | `GA` | `JS`, `.NET`, `Python` , `Go`, `Rust` |\n| [Intelligence Audio](https://developers.deepgram.com/reference/listen-remote) | topics | `GA` | `JS`, `.NET`, `Python` , `Go`, `Rust` |\n\n# Transcription API : Streaming\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | callback | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | callback\\_method | `GA` | `JS`, `.NET`, `Python` , `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | channels | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | diarize | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | diarize\\_version | `GA` | `JS`, `.NET`, `Python`, `Go` `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | encoding | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | endpointing | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | extra | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | interim\\_results | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | keyterm | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | keywords | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | language | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | model | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | multichannel | `GA` | `JS`, `.NET`, `Python`, `Go` , `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | numerals | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | punctuate | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | profanity\\_filter | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | redact | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | replace | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | sample\\_rate | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | search | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | smart\\_format | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | smart\\_format: no\\_delay | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | tag | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | utterance\\_end\\_ms | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | vad\\_events | `Beta` | `JS`, ```.NET``Python```, `Go`, `Rust` |\n| [Streaming](https://developers.deepgram.com/reference/listen-live) | version | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n\n# Intelligence API: Text\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Intelligence Text](https://developers.deepgram.com/reference/text-intelligence-apis) | intents | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Intelligence Text](https://developers.deepgram.com/reference/text-intelligence-apis) | sentiment | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Intelligence Text](https://developers.deepgram.com/reference/text-intelligence-apis) | summarize | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Intelligence Text](https://developers.deepgram.com/reference/text-intelligence-apis) | topics | `GA` | `JS`, `.NET`, `Python`, `Go` |\n\n# Text to Speech REST API\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | bit\\_rate | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | callback | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | container | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | encoding | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | model | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Text to Speech](https://developers.deepgram.com/reference/text-to-speech-api) | sample\\_rate | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n\n# Text to Speech Streaming API\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Text to Speech](https://developers.deepgram.com/reference/transform-text-to-speech-websocket) | encoding | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Text to Speech](https://developers.deepgram.com/reference/transform-text-to-speech-websocket) | model | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Text to Speech](https://developers.deepgram.com/reference/transform-text-to-speech-websocket) | sample\\_rate | `GA` | `JS`, `.NET`, `Python`, `Go` |\n\n# Management API\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Create Key](https://developers.deepgram.com/reference/create-key) | comment, scopes, tags, expiration\\_date, time\\_to\\_live\\_in\\_seconds | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Delete Project](https://developers.deepgram.com/reference/delete-project) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Delete Invites](https://developers.deepgram.com/reference/delete-invite) | N/A | `GA` | `JS`, `Python`, `Go`, |\n| [Delete Key](https://developers.deepgram.com/reference/delete-key) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Balance](https://developers.deepgram.com/reference/get-balance) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get All Balances](https://developers.deepgram.com/reference/get-all-balances) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Key](https://developers.deepgram.com/reference/get-key) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Members](https://developers.deepgram.com/reference/get-members) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Member Scopes](https://developers.deepgram.com/reference/get-member-scopes) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Project](https://developers.deepgram.com/reference/get-project) | start, end, limit, page | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Projects](https://developers.deepgram.com/reference/get-projects) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Project Models](https://developers.deepgram.com/reference/get-project-models) | include\\_outdated | `GA` | `JS`, `Python`, `Go`, `.NET` |\n| [Get Project Model](https://developers.deepgram.com/reference/get-project-model) | N/A | `GA` | `JS`, `Python`, `Go`, `.NET` |\n| [Leave Project](https://developers.deepgram.com/reference/leave-project) | N/A | `GA` | `JS`, `Python`, `Go` , `Rust` , `.NET` |\n| [List Invites](https://developers.deepgram.com/reference/list-invites) | N/A | `GA` | `JS`, `Python`, `Go`, `.NET` |\n| [List Keys](https://developers.deepgram.com/reference/list-keys) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Get Models](https://developers.deepgram.com/reference/get-models) | include\\_outdated | `GA` | `JS`, `Python`, `Go`, `.NET` |\n| [Get Model](https://developers.deepgram.com/reference/get-model) | N/A | `GA` | `JS`, `Python`, `Go`, `.NET` |\n| [Remove Member](https://developers.deepgram.com/reference/remove-member) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Send Invites](https://developers.deepgram.com/reference/send-invites) | email, scope | `GA` | `JS`, `Python`, `Go`, `Rust` |\n| [Summarize Usage](https://developers.deepgram.com/reference/summarize-usage) | start, end, accessor, tag, method, model, multichannel, interim\\_results, punctuate, ner, utterances, replace, profanity\\_filter, keywords, detect\\_topics, diarize, search, redact, alternatives, numerals, smart\\_format | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Usage Get All Requests](https://developers.deepgram.com/reference/get-all-requests) | start, end, limit, status, page | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Usage Get Fields](https://developers.deepgram.com/reference/get-fields) | start, end | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Usage Get Request](https://developers.deepgram.com/reference/get-request) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Update Project](https://developers.deepgram.com/reference/update-project) | name | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n| [Update Scope](https://developers.deepgram.com/reference/update-scope) | scope | `GA` | `JS`, `.NET`, `Python`, `Go`, `Rust` |\n\n# Self-Hosted API\n\nIn certain cases, our SDKs can be used with Deepgram’s [self-hosted](https://developers.deepgram.com/docs/self-hosted-introduction)-specific endpoints.\n\nFor more details on sending inference requests to a self-hosted deploment, see the [Using SDKs with Self-Hosted](https://developers.deepgram.com/docs/using-sdks-with-self-hosted) guide.\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Create Credentials](https://developers.deepgram.com/reference/create-credentials) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Delete Credentials](https://developers.deepgram.com/reference/delete-credentials) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Get Credential](https://developers.deepgram.com/reference/get-credentials) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go` |\n| [Get Credentials](https://developers.deepgram.com/reference/list-credentials) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go` |\n\n# Token-Based Authentication\n\n| API Reference | Query Options | Status | SDK Availability |\n| --- | --- | --- | --- |\n| [Token-Based Authentication](https://developers.deepgram.com/reference/token-based-auth-api/grant-token) | N/A | `GA` | `JS`, `.NET`, `Python`, `Go` |\n\n* * *\n\nWhat’s Next\n\n- [Deepgram SDKs](https://developers.deepgram.com/docs/deepgram-sdks)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=eu7gd28f4zqf)",
    "metadata": {
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "generator": "https://buildwithfern.com",
      "og:description": "A matrix of all Deepgram API features supported by our different SDKs.",
      "twitter:title": "SDK Feature Matrix | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "ogDescription": "A matrix of all Deepgram API features supported by our different SDKs.",
      "twitter:description": "A matrix of all Deepgram API features supported by our different SDKs.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "language": "en",
      "theme-color": "#f5f5f7",
      "ogTitle": "SDK Feature Matrix | Deepgram's Docs",
      "og:title": "SDK Feature Matrix | Deepgram's Docs",
      "description": "A matrix of all Deepgram API features supported by our different SDKs.",
      "title": "SDK Feature Matrix | Deepgram's Docs",
      "scrapeId": "afbc587b-ef1c-4fa7-a819-d6de991be572",
      "sourceURL": "https://developers.deepgram.com/sdks/sdk-features",
      "url": "https://developers.deepgram.com/sdks/sdk-features",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "## Deepgram Community\n\n- [Deepgram Discord](https://dpgr.am/discord)\n- [Deepgram Discussions Forum](https://github.com/orgs/deepgram/discussions)\n- [Deepgram Code of Conduct](https://developers.deepgram.com/code-of-conduct)\n\n## Support Plans\n\nIf you have a Premium or VIP Support Plan with Deepgram you can find details and links to contact us for support on your [Console dashboard](https://console.deepgram.com/).\n\n![Deepgram Support](https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/images/529aca7-dg_support_image.svg)\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=41blkmio3vrk)",
    "metadata": {
      "description": "Join the Deepgram Developer Community to: connect, discuss challenges, and learn about using Deepgram",
      "twitter:description": "Join the Deepgram Developer Community to: connect, discuss challenges, and learn about using Deepgram",
      "language": "en",
      "title": "Support | Deepgram's Docs",
      "application-name": "Deepgram's Docs",
      "ogDescription": "Join the Deepgram Developer Community to: connect, discuss challenges, and learn about using Deepgram",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "twitter:card": "summary",
      "twitter:title": "Support | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Support | Deepgram's Docs",
      "og:title": "Support | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "theme-color": "#f5f5f7",
      "og:description": "Join the Deepgram Developer Community to: connect, discuss challenges, and learn about using Deepgram",
      "scrapeId": "70be9629-b2aa-4b0f-bb30-241bcf645c06",
      "sourceURL": "https://developers.deepgram.com/support",
      "url": "https://developers.deepgram.com/support",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram maintains and meets the requirements for multiple data privacy compliance frameworks and certifications. To request Deepgram compliance documentation, talk to your Account Executive.\n\n## SOC 2\n\nDeepgram has achieved SOC 2 Type 1 and Type 2 certification. An independent auditor has evaluated the security controls and procedures we use to protect the data we process in the cloud and has assessed the operational effectiveness of our systems.\n\n## SOC 2 Certificates\n\nFor access to SOC 2 certificates, please [contact us](https://deepgram.com/contact-us).\n\n## GDPR\n\nDeepgram is GDPR ready. We provide information to our customers to help them understand how features and functionality of our platform may affect their GDPR compliance obligations.\n\n## HIPAA\n\nDeepgram is considered a Business Associate as defined by the US [HIPAA](https://www.hhs.gov/hipaa/index.html) legislation.\n\nFor Deepgram customers who qualify as a Covered Entity under US HIPAA legislation and related legislation and regulations and who provide ePHI (electronic Protected Health Information) to us, Deepgram may qualify as a business associate. We can provide our Business Associate Agreement to such customers upon request.\n\n## Business Associate Agreement\n\nTo secure a BAA (Business Associate Agreement) with Deepgram, please [contact us](https://deepgram.com/contact-us).\n\n## CCPA\n\nWe are compliant with the California Consumer Privacy Act of 2018 (CCPA), which secures privacy rights for California consumers and gives them more control over the personal information that businesses collect about them. You can view [our privacy policy](https://deepgram.com/privacy/) on [our website](https://deepgram.com/).\n\n## PCI\n\nWe are PCI compliant, and perform a yearly review of our standing within the framework.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=59wzna28a7ho)",
    "metadata": {
      "language": "en",
      "application-name": "Deepgram's Docs",
      "twitter:card": "summary",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "title": "Data Privacy Compliance | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "og:title": "Data Privacy Compliance | Deepgram's Docs",
      "description": "Learn about Deepgram data privacy compliance frameworks and certifications.",
      "og:description": "Learn about Deepgram data privacy compliance frameworks and certifications.",
      "twitter:description": "Learn about Deepgram data privacy compliance frameworks and certifications.",
      "twitter:title": "Data Privacy Compliance | Deepgram's Docs",
      "ogTitle": "Data Privacy Compliance | Deepgram's Docs",
      "ogDescription": "Learn about Deepgram data privacy compliance frameworks and certifications.",
      "scrapeId": "26ed2ddf-2950-4819-8ab3-e582c81c6765",
      "sourceURL": "https://developers.deepgram.com/trust-security/data-privacy-compliance",
      "url": "https://developers.deepgram.com/trust-security/data-privacy-compliance",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "Deepgram is committed to protecting the confidentiality of information provided by its clients. We maintain an information security initiative that has implemented administrative, technical, and physical safeguards to reasonably and appropriately ensure confidentiality, integrity, and availability of our client information and intellectual property.\n\nWe are a software-based service; we understand that technology and risk change over time. Therefore, we request valid third-parties to conduct risk assessments and continually evaluate, modify, and adjust our security procedures, policies, and standards, along with ensuring that everything we do matches our documented compliance processes at least yearly.\n\nDeepgram retains a security advisor for Information Security, Risk Management, and Compliance who is responsible for guiding all security strategy, policy development, enforcement, training, and maintaining a security-minded culture. The advisor is also responsible for revisions of our incident response process and procedures.\n\nDeepgram retains an independent Data Protection Officer, who is responsible for all data privacy matters, oversight, and governance. You can find [our privacy policy](https://deepgram.com/privacy/), which defines our continuous commitment to upholding privacy to the utmost importance, on [our website](https://deepgram.com/). You can [reach our DPO via email](mailto:security@deepgram.com).\n\nAs part of our third-party vendor management program, we validate our third parties (supply chain) to ensure they meet or exceed our strict data privacy and compliance standards.\n\nDeepgram’s Information Security initiative has been designed using industry best practices and industry frameworks (such as PCI, HIPAA, GDPR, and CCPA), which enables our organization to comply with federal and state laws and regulations related to its business and services.\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=o68z5vhyps02)",
    "metadata": {
      "ogDescription": "Review Deepgram's information security and privacy statement.",
      "theme-color": "#f5f5f7",
      "twitter:title": "Information Security & Privacy Statement | Deepgram's Docs",
      "og:description": "Review Deepgram's information security and privacy statement.",
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "title": "Information Security & Privacy Statement | Deepgram's Docs",
      "generator": "https://buildwithfern.com",
      "ogTitle": "Information Security & Privacy Statement | Deepgram's Docs",
      "description": "Review Deepgram's information security and privacy statement.",
      "og:title": "Information Security & Privacy Statement | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "twitter:card": "summary",
      "twitter:description": "Review Deepgram's information security and privacy statement.",
      "language": "en",
      "scrapeId": "0ada2114-40bd-4f9d-aab1-e8f307764123",
      "sourceURL": "https://developers.deepgram.com/trust-security/information-security-privacy",
      "url": "https://developers.deepgram.com/trust-security/information-security-privacy",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  },
  {
    "markdown": "At Deepgram, our employees and contractors all recognize that protecting company and client information is everyone’s responsibility. One of the benefits of being a small organization is that new information, changes to policies or procedures, emerging potential external threats, and new tools can be communicated, implemented, and trained on quickly.\n\n## Physical Security Standards\n\nWe adhere to robust physical data security and environmental controls. We assess and test any environments where data may be transmitted or stored to ensure they meet our security standards.\n\n## Data Encryption\n\nWe securely encrypt any sensitive or confidential information (including PHI and PCI data) that we store or transmit over an electronic communications network to guard against unauthorized access. Encryption technology renders data unusable, unreadable, and indecipherable to unauthorized individuals.\n\n## Data Privacy\n\nWe only collect and process information that our customers provide us. Our customers own their data. We maintain a privacy policy that is accessible via our main website, which includes information regarding our information management practices, types of information we collect, and how that information is used.\n\n## Data Security\n\nWe use hardened systems, secured environments, and role-based access control to ensure that customer data is protected from unauthorized access. All access to our systems are tightly controlled, locked down, and we utilize two-factor authentication along with industry best practice encryption algorithms.\n\n## Application Security\n\nOur application servers are secured behind industry-standard firewalls with restricted ports. Passwords are encrypted in transit and stored hashed. We ensure that our internal network is maintained correctly with vulnerability and patch management. We scan our code for vulnerabilities before each release deployment into production.\n\n## Incident Response, Disaster Recovery & Business Continuity\n\nWe have well-defined incident response and disaster recovery policies. We perform daily backups. In the unlikely event that any unauthorized access is alerted through our monitoring tools, Deepgram staff will:\n\n- Activate the Incident Response Plan and assemble response team members\n- Immediately reset all relevant passwords and revoke relevant keys, if applicable to the situation.\n- Notify Deepgram’s Engineering, Product, and Customer Success teams\n- Notify affected customers (if impacted) of the intrusion and if/how their data was compromised, and provide timely updates on progress.\n- Conduct an assessment to identify the source of the breach and attain any necessary third-party to assist with forensics as required.\n- Define system or process improvement tasks to avoid incidents in the future.\n- Communicate affected customers (if impacted) of the improvement plan and update customers as improvements are deployed.\n\nWe maintain a business continuity plan that is tested and revised as necessary and at least annually.\n\n## Security, Privacy & Compliance\n\nWe provide on-going training for our employees for all information security policies and practices, and maintain disciplinary measures for violations of our policies and procedures. Additionally, our team maintains and follows a process for onboarding and offboarding, including providing only least-privilege access when deemed appropriate for job function, otherwise known as role-based access control.\n\nWe maintain HIPAA Compliance and are PCI Compliant; thus, we adhere to the requirements throughout the year, which includes a list of checks, obligations, and independent audits for verification.\n\n## Contact\n\nIf you have questions or comments regarding Deepgram’s Information Security initiative, [contact us](mailto:security@deepgram.com).\n\n[iframe](https://www.google.com/recaptcha/enterprise/anchor?ar=1&k=6Lck4YwlAAAAAEIE1hR--varWp0qu9F-8-emQn2v&co=aHR0cHM6Ly9kZXZlbG9wZXJzLmRlZXBncmFtLmNvbTo0NDM.&hl=en&v=jt8Oh2-Ue1u7nEbJQUIdocyd&size=invisible&cb=p2mjr63rxake)",
    "metadata": {
      "viewport": "width=device-width, height=device-height, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=yes",
      "application-name": "Deepgram's Docs",
      "theme-color": "#f5f5f7",
      "twitter:description": "Learn about Deepgram's commitment to maintaining a company culture that values information security and data privacy",
      "description": "Learn about Deepgram's commitment to maintaining a company culture that values information security and data privacy",
      "twitter:card": "summary",
      "og:description": "Learn about Deepgram's commitment to maintaining a company culture that values information security and data privacy",
      "language": "en",
      "title": "Security Policy | Deepgram's Docs",
      "favicon": "https://files.buildwithfern.com/https://deepgram.docs.buildwithfern.com/2025-05-23T23:08:50.550Z/assets/favicon.ico",
      "generator": "https://buildwithfern.com",
      "twitter:title": "Security Policy | Deepgram's Docs",
      "ogDescription": "Learn about Deepgram's commitment to maintaining a company culture that values information security and data privacy",
      "og:title": "Security Policy | Deepgram's Docs",
      "ogTitle": "Security Policy | Deepgram's Docs",
      "scrapeId": "7f6a2441-2331-4543-bebc-14e2574c3a0c",
      "sourceURL": "https://developers.deepgram.com/trust-security/security-policy",
      "url": "https://developers.deepgram.com/trust-security/security-policy",
      "statusCode": 200,
      "proxyUsed": "basic"
    }
  }
]
